{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 10:16:28.808144: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-25 10:16:28.840642: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 10:16:28.840668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 10:16:28.841517: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 10:16:28.846623: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-25 10:16:28.847134: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 10:16:29.647313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import larq_compute_engine as lce\n",
    "import tensorflow as tf\n",
    "import larq as lq\n",
    "import numpy as np\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "# from tensorflow_model_optimization.python.core.keras.compat import keras\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "tf.random.set_seed(3407)\n",
    "np.random.seed(3407)\n",
    "random.seed(3407)\n",
    "\n",
    "from create_spectrogram import (\n",
    "    create_spectrograms_from_audio_dataset, \n",
    ")\n",
    "from helper_functions import (\n",
    "    evaluate_prediction,\n",
    "    get_file_size, \n",
    "    convert_bytes, \n",
    "    convert_prefetchdataset_to_numpy_arrays,\n",
    "    predict_and_print_full_results,\n",
    "    evaluate_time_of_prediction,\n",
    "    full_int_model_predict,\n",
    "    get_f1_scores_of_non_overlapping_partitions_full_int_q,\n",
    "    get_f1_scores_of_bootstarping_partitions_full_int_q,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11292 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Found 1393 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Found 1380 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Classes:  ['non_target' 'target']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.audio_dataset_from_directory(\"dataset/training\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "test_dataset = tf.keras.utils.audio_dataset_from_directory(\"dataset/testing\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "val_dataset = tf.keras.utils.audio_dataset_from_directory(\"dataset/validation\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "\n",
    "label_names = np.array(train_dataset.class_names)\n",
    "print(\"Classes: \", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spectrogram_ds = create_spectrograms_from_audio_dataset(train_dataset, sample_rate = sample_rate).cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_spectrogram_ds = create_spectrograms_from_audio_dataset(test_dataset, sample_rate = sample_rate).cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_spectrogram_ds = create_spectrograms_from_audio_dataset(val_dataset, sample_rate = sample_rate).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "x_train_np, y_train_np = convert_prefetchdataset_to_numpy_arrays(train_spectrogram_ds)\n",
    "x_val_np, y_val_np = convert_prefetchdataset_to_numpy_arrays(val_spectrogram_ds)\n",
    "x_test_np, y_test_np = convert_prefetchdataset_to_numpy_arrays(test_spectrogram_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0], shape=(32,), dtype=int32)\n",
      "0\n",
      "tf.Tensor([0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0], shape=(32,), dtype=int32)\n",
      "0\n",
      "tf.Tensor([1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0], shape=(32,), dtype=int32)\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# non-target = 0, target = 1\n",
    "# Print spectrograms of target or non-target class from dataset\n",
    "class_number = 1\n",
    "\n",
    "for i in train_spectrogram_ds:\n",
    "    print(i[1])\n",
    "    print(i[1][0].numpy())\n",
    "    if i[1][0].numpy() == class_number:\n",
    "        spectrogram = i[0][0]\n",
    "        height = spectrogram.shape[0]\n",
    "        width = spectrogram.shape[1]\n",
    "        X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "        Y = range(height)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.pcolormesh(X, Y, spectrogram)\n",
    "        plt.title(i[1][0])\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Frequency (Hz)')\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 31s]\n",
      "val_accuracy: 0.7699275314807892\n",
      "\n",
      "Best val_accuracy So Far: 0.8612318933010101\n",
      "Total elapsed time: 00h 01m 07s\n"
     ]
    }
   ],
   "source": [
    "class BinaryCNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        num_conv_layers = hp.Int('num_conv_layers', min_value=1, max_value=3, step=1)\n",
    "        filters = [hp.Int(f'filters_{i}', min_value=2, max_value=8, step=2) for i in range(num_conv_layers)]\n",
    "        kernel_size = hp.Choice('kernel_size', values=[2, 3, 5])\n",
    "        learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "        \n",
    "        # Model architecture\n",
    "        model.add(lq.layers.QuantConv2D(\n",
    "            filters=filters[0], kernel_size=(kernel_size, kernel_size),\n",
    "            input_shape=self.input_shape,\n",
    "            kernel_quantizer=\"ste_sign\",\n",
    "            kernel_constraint=\"weight_clip\",\n",
    "            use_bias=False\n",
    "        ))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "        # Tune number of layers\n",
    "        for i in range(1, num_conv_layers):\n",
    "            model.add(lq.layers.QuantConv2D(\n",
    "                filters=filters[i], kernel_size=(kernel_size, kernel_size),\n",
    "                kernel_quantizer=\"ste_sign\",\n",
    "                input_quantizer=\"ste_sign\",\n",
    "                use_bias=False\n",
    "            ))\n",
    "            model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "            model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        model.add(lq.layers.QuantDense(\n",
    "            units=64,\n",
    "            kernel_quantizer=\"ste_sign\",\n",
    "            input_quantizer=\"ste_sign\",\n",
    "            kernel_constraint=\"weight_clip\",\n",
    "            use_bias=False\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "        model.add(lq.layers.QuantDense(\n",
    "            units=self.num_classes,\n",
    "            kernel_quantizer=\"ste_sign\",\n",
    "            input_quantizer=\"ste_sign\",\n",
    "            kernel_constraint=\"weight_clip\",\n",
    "            use_bias=False\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "        model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "        \n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "input_shape = (184, 80, 1)\n",
    "num_classes = 2\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    BinaryCNNHyperModel(input_shape, num_classes),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    executions_per_trial=2,\n",
    "    # directory='my_dir',\n",
    "    project_name='binary_cnn_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(train_spectrogram_ds, epochs=1, validation_data=val_spectrogram_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a binary weight quantizer without setting `kernel_constraint` may result in starved weights (where the gradient is always zero).\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "num_conv_layers: 2\n",
      "filters_0: 6\n",
      "kernel_size: 3\n",
      "learning_rate: 0.004424632678209153\n",
      "filters_1: 2\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 13ms/step - loss: 0.3317 - accuracy: 0.8981\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(x_test_np, y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Larq's documentation model depth and parameters\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model.add(lq.layers.QuantConv2D(4, (3, 3),\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=(184, 80, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# The second layer has both quantized weights and activations using the Straight-through-estimator sign activation technquie.\n",
    "# Using straight-through-estimator to overcome undifferentiability issues\n",
    "model.add(lq.layers.QuantConv2D(8, (3, 3), use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# The third layer following the second layer\n",
    "# model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "# model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# The fourth layer\n",
    "model.add(lq.layers.QuantDense(16, use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# The fifth layer\n",
    "model.add(lq.layers.QuantDense(2, use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "#Output layer, multi class classification\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "#Compile and train the network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+sequential_1 stats----------------------------------------------------------------------------------------+\n",
      "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs  32-bit MACs |\n",
      "|                              (bit)                        x 1       x 1    (kB)                          |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d_2                   -  (-1, 182, 78, 4)       36         0    0.00           0       511056 |\n",
      "| max_pooling2d_2                  -   (-1, 91, 39, 4)        0         0       0           0            0 |\n",
      "| batch_normalization_4            -   (-1, 91, 39, 4)        0         8    0.03           0            0 |\n",
      "| quant_conv2d_3                   1   (-1, 89, 37, 8)      288         0    0.04      948384            0 |\n",
      "| max_pooling2d_3                  -   (-1, 44, 18, 8)        0         0       0           0            0 |\n",
      "| batch_normalization_5            -   (-1, 44, 18, 8)        0        16    0.06           0            0 |\n",
      "| flatten_1                        -        (-1, 6336)        0         0       0           0            0 |\n",
      "| quant_dense_2                    1          (-1, 16)   101376         0   12.38      101376            0 |\n",
      "| batch_normalization_6            -          (-1, 16)        0        32    0.12           0            0 |\n",
      "| quant_dense_3                    1           (-1, 2)       32         0    0.00          32            0 |\n",
      "| batch_normalization_7            -           (-1, 2)        0         4    0.02           0            0 |\n",
      "| activation_1                     -           (-1, 2)        0         0       0           ?            ? |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                  101732        60   12.65     1049792       511056 |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "+sequential_1 summary--------------------------+\n",
      "| Total params                      102 k      |\n",
      "| Trainable params                  102 k      |\n",
      "| Non-trainable params              60         |\n",
      "| Model size                        12.65 KiB  |\n",
      "| Model size (8-bit FP weights)     12.48 KiB  |\n",
      "| Float-32 Equivalent               397.62 KiB |\n",
      "| Compression Ratio of Memory       0.03       |\n",
      "| Number of MACs                    1.56 M     |\n",
      "| Ratio of MACs that are binarized  0.6726     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network\n",
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 13s 35ms/step - loss: 0.4386 - accuracy: 0.8171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd4445f6b20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_spectrogram_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 15ms/step - loss: 0.4298 - accuracy: 0.8155\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test_np, y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: quant_conv2d_2\n",
      "Shape: (3, 3, 1, 4)\n",
      "Unique values: [-3.95377785e-01 -3.59072477e-01 -3.12955707e-01 -3.07287067e-01\n",
      " -3.03380311e-01 -2.58191824e-01 -2.33742028e-01 -2.09712073e-01\n",
      " -1.93024203e-01 -1.90692961e-01 -1.75967038e-01 -1.68013126e-01\n",
      " -1.24861211e-01 -1.11134268e-01 -9.09463167e-02 -8.10133591e-02\n",
      " -5.38455322e-02 -3.95821482e-02  1.44130492e-04  1.04729238e-03\n",
      "  2.59656832e-02  9.93682817e-02  1.04678929e-01  1.11645766e-01\n",
      "  1.12707481e-01  1.22400902e-01  1.61612168e-01  1.87013730e-01\n",
      "  1.93578169e-01  2.03757524e-01  2.65140951e-01  3.02911460e-01\n",
      "  3.08673501e-01  3.41712981e-01  3.48210782e-01  3.52318436e-01]\n",
      "\n",
      "First few weights: [ 0.09936828 -0.08101336 -0.12486121 -0.23374203 -0.3033803  -0.1930242\n",
      "  0.11270748 -0.03958215 -0.19069296 -0.05384553]\n",
      "\n",
      "Layer: quant_conv2d_3\n",
      "Shape: (3, 3, 4, 8)\n",
      "Unique values: [-2.99159944e-01 -2.91951805e-01 -2.71072805e-01 -2.62876660e-01\n",
      " -2.50106096e-01 -2.48902619e-01 -2.46322647e-01 -2.37134144e-01\n",
      " -2.35796541e-01 -2.33126387e-01 -2.29965180e-01 -2.26222605e-01\n",
      " -2.24672750e-01 -2.21792653e-01 -2.18959928e-01 -2.18956470e-01\n",
      " -2.17492983e-01 -2.16071516e-01 -2.15777069e-01 -2.13086933e-01\n",
      " -2.09222451e-01 -2.07970202e-01 -2.01945230e-01 -2.01442331e-01\n",
      " -2.01203525e-01 -1.98698387e-01 -1.96213603e-01 -1.95735961e-01\n",
      " -1.94225863e-01 -1.93836972e-01 -1.93731502e-01 -1.90647185e-01\n",
      " -1.90292954e-01 -1.90013707e-01 -1.89470828e-01 -1.88037083e-01\n",
      " -1.86818138e-01 -1.84647128e-01 -1.83514580e-01 -1.83376357e-01\n",
      " -1.78483248e-01 -1.75790980e-01 -1.74542263e-01 -1.73085734e-01\n",
      " -1.71494365e-01 -1.69349909e-01 -1.67707667e-01 -1.64294362e-01\n",
      " -1.63685903e-01 -1.63164139e-01 -1.61783487e-01 -1.57855004e-01\n",
      " -1.57492459e-01 -1.54897973e-01 -1.54046848e-01 -1.48942411e-01\n",
      " -1.45004436e-01 -1.43093139e-01 -1.40466928e-01 -1.37923807e-01\n",
      " -1.36432871e-01 -1.36412233e-01 -1.36378154e-01 -1.30904317e-01\n",
      " -1.26395881e-01 -1.26301378e-01 -1.25883266e-01 -1.25706390e-01\n",
      " -1.24604046e-01 -1.22609898e-01 -1.19112760e-01 -1.18708141e-01\n",
      " -1.17459841e-01 -1.17068231e-01 -1.15493648e-01 -1.13896847e-01\n",
      " -1.13446027e-01 -1.11651406e-01 -1.11077756e-01 -1.10251300e-01\n",
      " -1.09426640e-01 -1.07794195e-01 -1.07685514e-01 -1.06842563e-01\n",
      " -1.02357604e-01 -1.01907626e-01 -1.00688092e-01 -1.00630596e-01\n",
      " -9.95100960e-02 -9.80901644e-02 -9.68300849e-02 -9.42535773e-02\n",
      " -9.27764401e-02 -8.83879811e-02 -8.64488333e-02 -8.59328285e-02\n",
      " -8.42873678e-02 -8.05307254e-02 -7.92992413e-02 -7.88962245e-02\n",
      " -7.80707002e-02 -7.79392198e-02 -7.69785419e-02 -7.66087249e-02\n",
      " -7.31365681e-02 -7.29992315e-02 -7.00960085e-02 -6.71754256e-02\n",
      " -6.65403977e-02 -6.27253726e-02 -6.14598878e-02 -6.12190254e-02\n",
      " -6.04158901e-02 -5.78588322e-02 -5.57618849e-02 -5.48720025e-02\n",
      " -5.38299195e-02 -5.01902848e-02 -4.92663868e-02 -4.77302633e-02\n",
      " -4.55783792e-02 -4.32589240e-02 -4.14079279e-02 -3.93343605e-02\n",
      " -3.68942432e-02 -3.27244923e-02 -3.00452765e-02 -2.95067579e-02\n",
      " -2.57447772e-02 -2.49482282e-02 -2.44435556e-02 -2.39599682e-02\n",
      " -2.35412847e-02 -2.15647835e-02 -1.73133481e-02 -1.60032585e-02\n",
      " -1.55742262e-02 -1.48286922e-02 -1.46564199e-02 -1.38590373e-02\n",
      " -1.35036390e-02 -1.31239211e-02 -9.47904866e-03 -9.10294149e-03\n",
      " -8.05309135e-03 -6.65014284e-03 -6.30739843e-03 -5.57666644e-03\n",
      " -4.67830664e-03 -4.60001873e-03 -3.70118418e-03 -2.61203293e-03\n",
      " -2.09120568e-03 -1.81875320e-03  6.89251465e-06  4.59760980e-04\n",
      "  5.73645113e-04  2.70645879e-03  3.31155816e-03  3.35515896e-03\n",
      "  3.35735502e-03  5.14478376e-03  6.50247792e-03  7.29990378e-03\n",
      "  8.44289828e-03  1.30346734e-02  1.46707417e-02  1.62934568e-02\n",
      "  2.15363242e-02  2.22125463e-02  2.62787361e-02  3.00465953e-02\n",
      "  3.07251792e-02  3.34227085e-02  3.52829583e-02  3.60331796e-02\n",
      "  4.04850394e-02  4.08881791e-02  4.17941846e-02  4.49368246e-02\n",
      "  4.70481403e-02  4.77644652e-02  5.06741703e-02  5.14161251e-02\n",
      "  5.34682982e-02  5.34772016e-02  5.41050322e-02  5.45843989e-02\n",
      "  5.49528152e-02  5.54265156e-02  6.31727800e-02  6.37301430e-02\n",
      "  6.42442182e-02  6.45815507e-02  6.53639510e-02  6.61886707e-02\n",
      "  6.69967011e-02  7.28338808e-02  7.44802877e-02  7.53106102e-02\n",
      "  7.81623647e-02  8.06531683e-02  8.14475641e-02  8.50217119e-02\n",
      "  8.92096236e-02  9.38107818e-02  9.51201320e-02  9.67886224e-02\n",
      "  9.83055681e-02  1.00637861e-01  1.01228371e-01  1.03286296e-01\n",
      "  1.03969343e-01  1.06551640e-01  1.07136764e-01  1.08269982e-01\n",
      "  1.08337104e-01  1.08596854e-01  1.13269411e-01  1.14189178e-01\n",
      "  1.16471790e-01  1.16817847e-01  1.17753170e-01  1.20626874e-01\n",
      "  1.21405981e-01  1.23120718e-01  1.23284385e-01  1.23479746e-01\n",
      "  1.24643318e-01  1.26126170e-01  1.30558074e-01  1.30914271e-01\n",
      "  1.31939739e-01  1.34214401e-01  1.34778157e-01  1.35065705e-01\n",
      "  1.37667209e-01  1.37671947e-01  1.38651952e-01  1.41105324e-01\n",
      "  1.41720131e-01  1.43561780e-01  1.45100206e-01  1.46797791e-01\n",
      "  1.47128344e-01  1.49464384e-01  1.50349602e-01  1.52739510e-01\n",
      "  1.53652221e-01  1.54179230e-01  1.62327334e-01  1.67170972e-01\n",
      "  1.71943948e-01  1.73229054e-01  1.73405588e-01  1.75489023e-01\n",
      "  1.77468628e-01  1.82525218e-01  1.87246203e-01  1.90078124e-01\n",
      "  1.93759203e-01  1.93950772e-01  1.97872326e-01  1.98280677e-01\n",
      "  1.98633373e-01  1.99981466e-01  2.00391471e-01  2.00668335e-01\n",
      "  2.02930480e-01  2.05402493e-01  2.07274482e-01  2.08484694e-01\n",
      "  2.08642557e-01  2.13604614e-01  2.14400813e-01  2.17764318e-01\n",
      "  2.19786406e-01  2.21790090e-01  2.24976122e-01  2.27466911e-01\n",
      "  2.34375820e-01  2.36538589e-01  2.39731714e-01  2.45710820e-01\n",
      "  2.49537483e-01  2.54695565e-01  2.57727921e-01  2.61414617e-01]\n",
      "\n",
      "First few weights: [-0.23579654 -0.12570639 -0.12588327  0.13766721 -0.12639588  0.2054025\n",
      "  0.00335516 -0.23312639  0.02153632  0.25469556]\n",
      "\n",
      "Layer: quant_dense_2\n",
      "Shape: (6336, 16)\n",
      "Unique values: [-0.11850639 -0.11794596 -0.11346113 ...  0.11561719  0.12609243\n",
      "  0.1277125 ]\n",
      "\n",
      "First few weights: [ 0.01509105  0.01934173  0.02587703  0.02467762  0.01145988 -0.02317399\n",
      "  0.00722655  0.02121263  0.01325099 -0.0058179 ]\n",
      "\n",
      "Layer: quant_dense_3\n",
      "Shape: (16, 2)\n",
      "Unique values: [-5.01974225e-01 -4.70060647e-01 -4.48300719e-01 -3.89488250e-01\n",
      " -3.47197175e-01 -2.72963881e-01 -2.65053600e-01 -1.74885944e-01\n",
      " -1.66951954e-01 -1.46568179e-01 -1.20002121e-01 -8.46886821e-03\n",
      " -2.26792166e-04  4.07086834e-02  1.00302957e-01  1.02462083e-01\n",
      "  1.06052235e-01  1.49483576e-01  1.50169447e-01  2.24526137e-01\n",
      "  2.81750053e-01  3.35607886e-01  3.46777201e-01  3.47809166e-01\n",
      "  3.62613022e-01  3.80816042e-01  4.15792495e-01  4.40845758e-01\n",
      "  4.59348351e-01  4.74914610e-01  5.45685470e-01  5.60557246e-01]\n",
      "\n",
      "First few weights: [ 0.10246208  0.10030296  0.04070868  0.3467772  -0.17488594  0.44084576\n",
      "  0.15016945  0.45934835 -0.27296388  0.22452614]\n",
      "\n",
      "Layer: quant_conv2d_2, Weight shape: (3, 3, 1, 4), Size: 304 bytes\n",
      "Layer: quant_conv2d_3, Weight shape: (3, 3, 4, 8), Size: 1312 bytes\n",
      "Layer: quant_dense_2, Weight shape: (6336, 16), Size: 405632 bytes\n",
      "Layer: quant_dense_3, Weight shape: (16, 2), Size: 256 bytes\n",
      "Total memory usage: 407504 bytes\n"
     ]
    }
   ],
   "source": [
    "def display_weights(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, lq.layers.QuantConv2D) or isinstance(layer, lq.layers.QuantDense):\n",
    "            weights = layer.get_weights()\n",
    "            if weights:\n",
    "                print(f\"Layer: {layer.name}\")\n",
    "                for weight in weights:\n",
    "                    print(f\"Shape: {weight.shape}\")\n",
    "                    # Print the unique values to see if they are binarized\n",
    "                    unique_values = np.unique(weight)\n",
    "                    print(f\"Unique values: {unique_values}\\n\")\n",
    "                    # Print the first few weights for inspection\n",
    "                    print(f\"First few weights: {weight.flatten()[:10]}\\n\")\n",
    "\n",
    "# Display the weights of the binarized CNN model\n",
    "\n",
    "\n",
    "def model_memory_usage(model):\n",
    "    import sys\n",
    "    import larq as lq\n",
    "\n",
    "    total_size = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (lq.layers.QuantConv2D, lq.layers.QuantDense)):\n",
    "            weights = layer.get_weights()\n",
    "            for weight in weights:\n",
    "                size = sys.getsizeof(weight)\n",
    "                total_size += size\n",
    "                print(f\"Layer: {layer.name}, Weight shape: {weight.shape}, Size: {size} bytes\")\n",
    "\n",
    "    print(f\"Total memory usage: {total_size} bytes\")\n",
    "\n",
    "# Display the weights of the binarized CNN model\n",
    "display_weights(model)\n",
    "\n",
    "# Check the memory usage of the model\n",
    "model_memory_usage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  spectrogram_models_from_notebooks/bnn/bnn_latent_weights.keras\n",
      "File size: 1.23 Megabytes\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL_FILE_NAME = \"spectrogram_models_from_notebooks/bnn/bnn_latent_weights.keras\"\n",
    "model.save(BASE_MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", BASE_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(BASE_MODEL_FILE_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BNN binary weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with lq.context.quantized_scope(True):\n",
    "    model.save(\"spectrogram_models_from_notebooks/bnn/bnn_binary_weights.keras\")  # save binarized weights h5\n",
    "    weights = model.get_weights()  # get binarized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_weights_model = tf.keras.models.load_model(\"spectrogram_models_from_notebooks/bnn/bnn_binary_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Test dataset:\n",
      "Accuracy: 81.55%\n",
      "Recall: 94.98%\n",
      "Precision: 65.02%\n",
      "F1-score: 77.20%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.056 seconds\n",
      "Max: 0.488 seconds\n",
      "Min: 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"For Test dataset:\")\n",
    "evaluate_time_of_prediction(binarized_weights_model, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Display the weights of the binarized CNN model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdisplay_weights\u001b[49m(binarized_weights_model)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check the memory usage of the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_memory_usage(binarized_weights_model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'display_weights' is not defined"
     ]
    }
   ],
   "source": [
    "# Display the weights of the binarized CNN model\n",
    "display_weights(binarized_weights_model)\n",
    "\n",
    "# Check the memory usage of the model\n",
    "model_memory_usage(binarized_weights_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  spectrogram_models_from_notebooks/bnn/bnn_binary_weights.keras\n",
      "File size: 1.23 Megabytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Model file name: \", \"spectrogram_models_from_notebooks/bnn/bnn_binary_weights.keras\")\n",
    "convert_bytes(get_file_size(\"spectrogram_models_from_notebooks/bnn/bnn_binary_weights.keras\"), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### larq TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7wjkol6r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7wjkol6r/assets\n",
      "2024-07-24 23:44:55.680542: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp7wjkol6r\n",
      "2024-07-24 23:44:55.686482: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-07-24 23:44:55.686577: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp7wjkol6r\n",
      "2024-07-24 23:44:55.688590: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 23:44:55.700275: I external/org_tensorflow/tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-07-24 23:44:55.706022: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-07-24 23:44:55.806482: E external/org_tensorflow/tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute debug_name which is not in the op definition: Op<name=VarHandleOp; signature= -> resource:resource; attr=container:string,default=\"\"; attr=shared_name:string,default=\"\"; attr=dtype:type; attr=shape:shape; attr=allowed_devices:list(string),default=[]; is_stateful=true> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node Adam/m/batch_normalization_4/beta}}\n",
      "2024-07-24 23:44:55.826344: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp7wjkol6r\n",
      "2024-07-24 23:44:55.848794: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 168361 microseconds.\n",
      "2024-07-24 23:44:55.881205: I external/org_tensorflow/tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-24 23:44:55.984581: I external/org_tensorflow/tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 1.405 M  ops, equivalently 0.703 M  MACs\n"
     ]
    }
   ],
   "source": [
    "lce_model = lce.convert_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.04401787],\n",
       "         [ 0.39496595],\n",
       "         [ 0.30142406],\n",
       "         ...,\n",
       "         [-1.0023309 ],\n",
       "         [-1.6115078 ],\n",
       "         [-3.336908  ]],\n",
       "\n",
       "        [[ 0.06672598],\n",
       "         [ 0.21323448],\n",
       "         [ 0.49440995],\n",
       "         ...,\n",
       "         [-0.8302009 ],\n",
       "         [-1.563447  ],\n",
       "         [-3.236836  ]],\n",
       "\n",
       "        [[-0.45135427],\n",
       "         [-0.8405577 ],\n",
       "         [-0.4890718 ],\n",
       "         ...,\n",
       "         [-0.8152356 ],\n",
       "         [-1.5949649 ],\n",
       "         [-3.111853  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.26997286],\n",
       "         [ 0.5909237 ],\n",
       "         [ 0.24076724],\n",
       "         ...,\n",
       "         [-0.7262548 ],\n",
       "         [-1.5393718 ],\n",
       "         [-3.0070517 ]],\n",
       "\n",
       "        [[ 0.21380104],\n",
       "         [ 1.0678476 ],\n",
       "         [ 0.7340482 ],\n",
       "         ...,\n",
       "         [-0.6205487 ],\n",
       "         [-1.543257  ],\n",
       "         [-2.819945  ]],\n",
       "\n",
       "        [[-0.23545307],\n",
       "         [ 0.66171277],\n",
       "         [ 0.6606401 ],\n",
       "         ...,\n",
       "         [-0.79505193],\n",
       "         [-1.7219336 ],\n",
       "         [-2.9889755 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_point = x_test_np[:1]\n",
    "test_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034351348876953125\n",
      "0.005945444107055664\n",
      "0.004619121551513672\n",
      "0.004218578338623047\n",
      "0.004244089126586914\n",
      "0.003698110580444336\n",
      "0.002618074417114258\n",
      "0.0023539066314697266\n",
      "0.002858400344848633\n",
      "0.0025954246520996094\n",
      "0.0027244091033935547\n",
      "0.0025451183319091797\n",
      "0.0026807785034179688\n",
      "0.002638578414916992\n",
      "0.002500295639038086\n",
      "0.002559185028076172\n",
      "0.00244140625\n",
      "0.002485513687133789\n",
      "0.002691030502319336\n",
      "0.0024230480194091797\n",
      "0.002576589584350586\n",
      "0.0036363601684570312\n",
      "0.0035359859466552734\n",
      "0.004147529602050781\n",
      "0.003807544708251953\n",
      "0.003695964813232422\n",
      "0.0025975704193115234\n",
      "0.002474069595336914\n",
      "0.0024585723876953125\n",
      "0.002452373504638672\n",
      "0.0025551319122314453\n",
      "0.0024056434631347656\n",
      "0.002532958984375\n",
      "0.0024390220642089844\n",
      "0.0026416778564453125\n",
      "0.0026617050170898438\n",
      "0.003058910369873047\n",
      "0.002460956573486328\n",
      "0.002381563186645508\n",
      "0.002334117889404297\n",
      "0.0023021697998046875\n",
      "0.002269744873046875\n",
      "0.0022895336151123047\n",
      "0.003430604934692383\n",
      "0.002691507339477539\n",
      "0.002596616744995117\n",
      "0.002526998519897461\n",
      "0.0024352073669433594\n",
      "0.0025467872619628906\n",
      "0.002668142318725586\n",
      "0.0026628971099853516\n",
      "0.0024869441986083984\n",
      "0.0024895668029785156\n",
      "0.0026264190673828125\n",
      "0.002633810043334961\n",
      "0.0024902820587158203\n",
      "0.002537250518798828\n",
      "0.0026712417602539062\n",
      "0.0024476051330566406\n",
      "0.002630472183227539\n",
      "0.002596616744995117\n",
      "0.0025877952575683594\n",
      "0.002480030059814453\n",
      "0.002586841583251953\n",
      "0.0029315948486328125\n",
      "0.0024039745330810547\n",
      "0.0038962364196777344\n",
      "0.0039179325103759766\n",
      "0.002933502197265625\n",
      "0.002584218978881836\n",
      "0.0026006698608398438\n",
      "0.002743244171142578\n",
      "0.0028982162475585938\n",
      "0.003010988235473633\n",
      "0.0030231475830078125\n",
      "0.0023796558380126953\n",
      "0.003359556198120117\n",
      "0.0037415027618408203\n",
      "0.0035867691040039062\n",
      "0.0036606788635253906\n",
      "0.0033016204833984375\n",
      "0.0036935806274414062\n",
      "0.0025959014892578125\n",
      "0.002499103546142578\n",
      "0.0027289390563964844\n",
      "0.002268552780151367\n",
      "0.002529621124267578\n",
      "0.0023932456970214844\n",
      "0.0024776458740234375\n",
      "0.002393484115600586\n",
      "0.002628326416015625\n",
      "0.002546548843383789\n",
      "0.002748250961303711\n",
      "0.0023305416107177734\n",
      "0.0023403167724609375\n",
      "0.002717733383178711\n",
      "0.0025091171264648438\n",
      "0.002618074417114258\n",
      "0.002723217010498047\n",
      "0.0025911331176757812\n",
      "0.00252532958984375\n",
      "0.0025479793548583984\n",
      "0.0025115013122558594\n",
      "0.0026900768280029297\n",
      "0.002353191375732422\n",
      "0.0023882389068603516\n",
      "0.0024836063385009766\n",
      "0.0026564598083496094\n",
      "0.0025529861450195312\n",
      "0.002456188201904297\n",
      "0.0025708675384521484\n",
      "0.002693653106689453\n",
      "0.0025148391723632812\n",
      "0.0022623538970947266\n",
      "0.0023910999298095703\n",
      "0.002354860305786133\n",
      "0.002415895462036133\n",
      "0.0025010108947753906\n",
      "0.0022821426391601562\n",
      "0.0026159286499023438\n",
      "0.002493143081665039\n",
      "0.0025603771209716797\n",
      "0.0024263858795166016\n",
      "0.0025625228881835938\n",
      "0.002452850341796875\n",
      "0.0026221275329589844\n",
      "0.0038051605224609375\n",
      "0.0027666091918945312\n",
      "0.002463817596435547\n",
      "0.0024154186248779297\n",
      "0.0026950836181640625\n",
      "0.0026874542236328125\n",
      "0.0025298595428466797\n",
      "0.0024454593658447266\n",
      "0.0026102066040039062\n",
      "0.002559661865234375\n",
      "0.002327442169189453\n",
      "0.002454996109008789\n",
      "0.0026051998138427734\n",
      "0.0023708343505859375\n",
      "0.0024297237396240234\n",
      "0.00397801399230957\n",
      "0.00368499755859375\n",
      "0.003878355026245117\n",
      "0.003505706787109375\n",
      "0.0023038387298583984\n",
      "0.0023953914642333984\n",
      "0.0025250911712646484\n",
      "0.0030641555786132812\n",
      "0.0025970935821533203\n",
      "0.002542257308959961\n",
      "0.0037102699279785156\n",
      "0.00371551513671875\n",
      "0.003150463104248047\n",
      "0.002706289291381836\n",
      "0.002371549606323242\n",
      "0.0027730464935302734\n",
      "0.0025534629821777344\n",
      "0.0025043487548828125\n",
      "0.0025513172149658203\n",
      "0.0024347305297851562\n",
      "0.002539396286010742\n",
      "0.0023856163024902344\n",
      "0.0023758411407470703\n",
      "0.00260162353515625\n",
      "0.0023636817932128906\n",
      "0.0023331642150878906\n",
      "0.0023152828216552734\n",
      "0.0026912689208984375\n",
      "0.0038733482360839844\n",
      "0.002637147903442383\n",
      "0.0022165775299072266\n",
      "0.003545045852661133\n",
      "0.0027933120727539062\n",
      "0.002557039260864258\n",
      "0.002669095993041992\n",
      "0.0028023719787597656\n",
      "0.0028967857360839844\n",
      "0.002618074417114258\n",
      "0.0024955272674560547\n",
      "0.002390623092651367\n",
      "0.002344369888305664\n",
      "0.0023093223571777344\n",
      "0.002569913864135742\n",
      "0.0026602745056152344\n",
      "0.0040128231048583984\n",
      "0.0035893917083740234\n",
      "0.0037386417388916016\n",
      "0.0042192935943603516\n",
      "0.004023075103759766\n",
      "0.0037996768951416016\n",
      "0.0039038658142089844\n",
      "0.0027489662170410156\n",
      "0.0024404525756835938\n",
      "0.002475261688232422\n",
      "0.0025587081909179688\n",
      "0.0026433467864990234\n",
      "0.002577543258666992\n",
      "0.0024712085723876953\n",
      "0.0027942657470703125\n",
      "0.002651214599609375\n",
      "0.0023262500762939453\n",
      "0.0023658275604248047\n",
      "0.002360820770263672\n",
      "0.0023393630981445312\n",
      "0.0025551319122314453\n",
      "0.0025506019592285156\n",
      "0.0022661685943603516\n",
      "0.0024285316467285156\n",
      "0.0024123191833496094\n",
      "0.002501249313354492\n",
      "0.002608776092529297\n",
      "0.0024385452270507812\n",
      "0.002375364303588867\n",
      "0.0029921531677246094\n",
      "0.0024929046630859375\n",
      "0.0024673938751220703\n",
      "0.002943754196166992\n",
      "0.0028123855590820312\n",
      "0.0026464462280273438\n",
      "0.003648042678833008\n",
      "0.0028586387634277344\n",
      "0.002888917922973633\n",
      "0.0030181407928466797\n",
      "0.0024220943450927734\n",
      "0.0025322437286376953\n",
      "0.0026869773864746094\n",
      "0.002741098403930664\n",
      "0.003408670425415039\n",
      "0.0038576126098632812\n",
      "0.0035996437072753906\n",
      "0.0024793148040771484\n",
      "0.0026247501373291016\n",
      "0.0032193660736083984\n",
      "0.002603769302368164\n",
      "0.0028378963470458984\n",
      "0.0028672218322753906\n",
      "0.0028738975524902344\n",
      "0.0026330947875976562\n",
      "0.0028934478759765625\n",
      "0.0028815269470214844\n",
      "0.002759218215942383\n",
      "0.002883434295654297\n",
      "0.0027925968170166016\n",
      "0.0030672550201416016\n",
      "0.0025627613067626953\n",
      "0.0025391578674316406\n",
      "0.002752065658569336\n",
      "0.0025300979614257812\n",
      "0.0025467872619628906\n",
      "0.004006385803222656\n",
      "0.0035772323608398438\n",
      "0.0037016868591308594\n",
      "0.0037398338317871094\n",
      "0.00341033935546875\n",
      "0.002624034881591797\n",
      "0.0025818347930908203\n",
      "0.0024979114532470703\n",
      "0.0024352073669433594\n",
      "0.002624034881591797\n",
      "0.002572774887084961\n",
      "0.0028307437896728516\n",
      "0.002551555633544922\n",
      "0.002560853958129883\n",
      "0.0027577877044677734\n",
      "0.002560138702392578\n",
      "0.0025942325592041016\n",
      "0.0024657249450683594\n",
      "0.0024595260620117188\n",
      "0.003062009811401367\n",
      "0.0024280548095703125\n",
      "0.0027146339416503906\n",
      "0.0025358200073242188\n",
      "0.0025649070739746094\n",
      "0.0025103092193603516\n",
      "0.0023622512817382812\n",
      "0.0026204586029052734\n",
      "0.002460956573486328\n",
      "0.002454519271850586\n",
      "0.0025451183319091797\n",
      "0.002602815628051758\n",
      "0.0023980140686035156\n",
      "0.002329587936401367\n",
      "0.0025238990783691406\n",
      "0.0029935836791992188\n",
      "0.002769947052001953\n",
      "0.0027015209197998047\n",
      "0.0028896331787109375\n",
      "0.002410411834716797\n",
      "0.0025055408477783203\n",
      "0.0025985240936279297\n",
      "0.0032732486724853516\n",
      "0.0025577545166015625\n",
      "0.002614259719848633\n",
      "0.0023322105407714844\n",
      "0.0035371780395507812\n",
      "0.002903461456298828\n",
      "0.002747774124145508\n",
      "0.0024802684783935547\n",
      "0.002554655075073242\n",
      "0.003373861312866211\n",
      "0.0031347274780273438\n",
      "0.0032918453216552734\n",
      "0.0024271011352539062\n",
      "0.0026302337646484375\n",
      "0.0025751590728759766\n",
      "0.002739429473876953\n",
      "0.0028481483459472656\n",
      "0.002521991729736328\n",
      "0.002877950668334961\n",
      "0.002452850341796875\n",
      "0.0025124549865722656\n",
      "0.0033063888549804688\n",
      "0.002801179885864258\n",
      "0.0026535987854003906\n",
      "0.0025756359100341797\n",
      "0.0025713443756103516\n",
      "0.003261566162109375\n",
      "0.002560138702392578\n",
      "0.002542734146118164\n",
      "0.0024039745330810547\n",
      "0.0023534297943115234\n",
      "0.002776622772216797\n",
      "0.002531766891479492\n",
      "0.0024695396423339844\n",
      "0.002645730972290039\n",
      "0.002547740936279297\n",
      "0.0030188560485839844\n",
      "0.0024497509002685547\n",
      "0.0023658275604248047\n",
      "0.0026373863220214844\n",
      "0.002347707748413086\n",
      "0.0023050308227539062\n",
      "0.0024161338806152344\n",
      "0.002483367919921875\n",
      "0.0024335384368896484\n",
      "0.003110170364379883\n",
      "0.0026404857635498047\n",
      "0.002681255340576172\n",
      "0.0025932788848876953\n",
      "0.002612590789794922\n",
      "0.0027921199798583984\n",
      "0.0025184154510498047\n",
      "0.0025794506072998047\n",
      "0.0027341842651367188\n",
      "0.0025501251220703125\n",
      "0.0026671886444091797\n",
      "0.0029637813568115234\n",
      "0.0037970542907714844\n",
      "0.0035419464111328125\n",
      "0.003499746322631836\n",
      "0.0035843849182128906\n",
      "0.0034668445587158203\n",
      "0.0034132003784179688\n",
      "0.003495454788208008\n",
      "0.003184080123901367\n",
      "0.0029366016387939453\n",
      "0.002547740936279297\n",
      "0.002667665481567383\n",
      "0.002866029739379883\n",
      "0.0028786659240722656\n",
      "0.003052949905395508\n",
      "0.002404928207397461\n",
      "0.0025832653045654297\n",
      "0.0026509761810302734\n",
      "0.002575397491455078\n",
      "0.0026590824127197266\n",
      "0.002740621566772461\n",
      "0.003444194793701172\n",
      "0.0028274059295654297\n",
      "0.0036101341247558594\n",
      "0.0027146339416503906\n",
      "0.002709627151489258\n",
      "0.002539396286010742\n",
      "0.002544879913330078\n",
      "0.0027043819427490234\n",
      "0.0029053688049316406\n",
      "0.002887248992919922\n",
      "0.0031316280364990234\n",
      "0.0024497509002685547\n",
      "0.0024683475494384766\n",
      "0.0025479793548583984\n",
      "0.002577543258666992\n",
      "0.0028650760650634766\n",
      "0.0024957656860351562\n",
      "0.002475261688232422\n",
      "0.002536773681640625\n",
      "0.0024924278259277344\n",
      "0.0024290084838867188\n",
      "0.002557992935180664\n",
      "0.0026264190673828125\n",
      "0.0024156570434570312\n",
      "0.0023043155670166016\n",
      "0.002469301223754883\n",
      "0.0025458335876464844\n",
      "0.0024576187133789062\n",
      "0.0023682117462158203\n",
      "0.002433300018310547\n",
      "0.002500772476196289\n",
      "0.0024962425231933594\n",
      "0.0025556087493896484\n",
      "0.0025076866149902344\n",
      "0.002565145492553711\n",
      "0.002888202667236328\n",
      "0.002493619918823242\n",
      "0.0026862621307373047\n",
      "0.0024690628051757812\n",
      "0.0024733543395996094\n",
      "0.0025959014892578125\n",
      "0.0024902820587158203\n",
      "0.0025310516357421875\n",
      "0.0024499893188476562\n",
      "0.002439737319946289\n",
      "0.0025682449340820312\n",
      "0.0024018287658691406\n",
      "0.002407550811767578\n",
      "0.002652406692504883\n",
      "0.002562999725341797\n",
      "0.002554178237915039\n",
      "0.0024309158325195312\n",
      "0.0029222965240478516\n",
      "0.004146099090576172\n",
      "0.00412750244140625\n",
      "0.0024585723876953125\n",
      "0.0025506019592285156\n",
      "0.0034356117248535156\n",
      "0.0029680728912353516\n",
      "0.002462625503540039\n",
      "0.0025386810302734375\n",
      "0.002656698226928711\n",
      "0.002481698989868164\n",
      "0.0024383068084716797\n",
      "0.0025959014892578125\n",
      "0.002595663070678711\n",
      "0.0025959014892578125\n",
      "0.0024886131286621094\n",
      "0.0024094581604003906\n",
      "0.0024280548095703125\n",
      "0.0025184154510498047\n",
      "0.002507448196411133\n",
      "0.002410888671875\n",
      "0.002421855926513672\n",
      "0.002501249313354492\n",
      "0.0027365684509277344\n",
      "0.003775358200073242\n",
      "0.0046842098236083984\n",
      "0.0028600692749023438\n",
      "0.0026369094848632812\n",
      "0.0024404525756835938\n",
      "0.0023446083068847656\n",
      "0.0025634765625\n",
      "0.002688169479370117\n",
      "0.003026247024536133\n",
      "0.00323486328125\n",
      "0.0036385059356689453\n",
      "0.0035762786865234375\n",
      "0.003343820571899414\n",
      "0.0035791397094726562\n",
      "0.0037593841552734375\n",
      "0.0034193992614746094\n",
      "0.0034918785095214844\n",
      "0.0034570693969726562\n",
      "0.003387451171875\n",
      "0.0033617019653320312\n",
      "0.0034084320068359375\n",
      "0.003477334976196289\n",
      "0.0034062862396240234\n",
      "0.003465414047241211\n",
      "0.003487825393676758\n",
      "0.0033354759216308594\n",
      "0.0033960342407226562\n",
      "0.0036857128143310547\n",
      "0.004202127456665039\n",
      "0.003803730010986328\n",
      "0.0037016868591308594\n",
      "0.003927469253540039\n",
      "0.0034942626953125\n",
      "0.0024368762969970703\n",
      "0.0025267601013183594\n",
      "0.002507448196411133\n",
      "0.002377033233642578\n",
      "0.0024824142456054688\n",
      "0.002600431442260742\n",
      "0.0025527477264404297\n",
      "0.0025382041931152344\n",
      "0.0025141239166259766\n",
      "0.0024521350860595703\n",
      "0.002538919448852539\n",
      "0.0022385120391845703\n",
      "0.0025615692138671875\n",
      "0.002520322799682617\n",
      "0.0023360252380371094\n",
      "0.002391338348388672\n",
      "0.0024955272674560547\n",
      "0.002444744110107422\n",
      "0.0024633407592773438\n",
      "0.002573251724243164\n",
      "0.002302408218383789\n",
      "0.002409219741821289\n",
      "0.0024204254150390625\n",
      "0.0026633739471435547\n",
      "0.0024976730346679688\n",
      "0.002452373504638672\n",
      "0.0024576187133789062\n",
      "0.0025129318237304688\n",
      "0.002344846725463867\n",
      "0.002413034439086914\n",
      "0.0025320053100585938\n",
      "0.002674102783203125\n",
      "0.0025179386138916016\n",
      "0.0024852752685546875\n",
      "0.0023651123046875\n",
      "0.0025310516357421875\n",
      "0.002557992935180664\n",
      "0.0032372474670410156\n",
      "0.0035920143127441406\n",
      "0.004450798034667969\n",
      "0.0030307769775390625\n",
      "0.0025017261505126953\n",
      "0.002321004867553711\n",
      "0.0025904178619384766\n",
      "0.0027000904083251953\n",
      "0.002765655517578125\n",
      "0.002925872802734375\n",
      "0.0026235580444335938\n",
      "0.002595186233520508\n",
      "0.0025017261505126953\n",
      "0.002439737319946289\n",
      "0.0027501583099365234\n",
      "0.0025773048400878906\n",
      "0.002598285675048828\n",
      "0.0024847984313964844\n",
      "0.0024559497833251953\n",
      "0.0025289058685302734\n",
      "0.0031893253326416016\n",
      "0.002756357192993164\n",
      "0.002544879913330078\n",
      "0.0028183460235595703\n",
      "0.003101348876953125\n",
      "0.004128932952880859\n",
      "0.0028197765350341797\n",
      "0.0026252269744873047\n",
      "0.0025119781494140625\n",
      "0.002701282501220703\n",
      "0.0027685165405273438\n",
      "0.0032203197479248047\n",
      "0.002731800079345703\n",
      "0.0026826858520507812\n",
      "0.0029032230377197266\n",
      "0.0026657581329345703\n",
      "0.003774881362915039\n",
      "0.003818511962890625\n",
      "0.003542184829711914\n",
      "0.0032873153686523438\n",
      "0.003039836883544922\n",
      "0.0025844573974609375\n",
      "0.0030257701873779297\n",
      "0.002513408660888672\n",
      "0.002432584762573242\n",
      "0.003227710723876953\n",
      "0.0041806697845458984\n",
      "0.00423121452331543\n",
      "0.0041964054107666016\n",
      "0.003903627395629883\n",
      "0.004064083099365234\n",
      "0.004518985748291016\n",
      "0.004278898239135742\n",
      "0.0034818649291992188\n",
      "0.002697467803955078\n",
      "0.0026862621307373047\n",
      "0.002704620361328125\n",
      "0.002585172653198242\n",
      "0.003414630889892578\n",
      "0.004436016082763672\n",
      "0.0032358169555664062\n",
      "0.0025827884674072266\n",
      "0.0028295516967773438\n",
      "0.002446413040161133\n",
      "0.0026481151580810547\n",
      "0.003508329391479492\n",
      "0.004300355911254883\n",
      "0.0027933120727539062\n",
      "0.0030107498168945312\n",
      "0.002977609634399414\n",
      "0.0024874210357666016\n",
      "0.0023872852325439453\n",
      "0.002545595169067383\n",
      "0.002532482147216797\n",
      "0.0035991668701171875\n",
      "0.0031554698944091797\n",
      "0.0026407241821289062\n",
      "0.0024902820587158203\n",
      "0.0030558109283447266\n",
      "0.003986358642578125\n",
      "0.003395557403564453\n",
      "0.002810955047607422\n",
      "0.00247955322265625\n",
      "0.0025053024291992188\n",
      "0.002604961395263672\n",
      "0.003153085708618164\n",
      "0.003625154495239258\n",
      "0.0035257339477539062\n",
      "0.003650665283203125\n",
      "0.003687620162963867\n",
      "0.0035238265991210938\n",
      "0.003528594970703125\n",
      "0.0034847259521484375\n",
      "0.0034182071685791016\n",
      "0.0034165382385253906\n",
      "0.0034258365631103516\n",
      "0.003369569778442383\n",
      "0.003414630889892578\n",
      "0.0033545494079589844\n",
      "0.0034563541412353516\n",
      "0.0032265186309814453\n",
      "0.0024056434631347656\n",
      "0.0024716854095458984\n",
      "0.002424955368041992\n",
      "0.0022737979888916016\n",
      "0.0025856494903564453\n",
      "0.0024678707122802734\n",
      "0.0025589466094970703\n",
      "0.002382040023803711\n",
      "0.0023055076599121094\n",
      "0.0023980140686035156\n",
      "0.0024344921112060547\n",
      "0.0023720264434814453\n",
      "0.002531290054321289\n",
      "0.0022630691528320312\n",
      "0.002291440963745117\n",
      "0.0024352073669433594\n",
      "0.002371549606323242\n",
      "0.0025298595428466797\n",
      "0.0023345947265625\n",
      "0.0024123191833496094\n",
      "0.0023767948150634766\n",
      "0.0026030540466308594\n",
      "0.0024483203887939453\n",
      "0.00254058837890625\n",
      "0.002533435821533203\n",
      "0.0025947093963623047\n",
      "0.002585172653198242\n",
      "0.0024335384368896484\n",
      "0.0025568008422851562\n",
      "0.0024597644805908203\n",
      "0.0023245811462402344\n",
      "0.0024471282958984375\n",
      "0.0025124549865722656\n",
      "0.002288818359375\n",
      "0.002419710159301758\n",
      "0.002408266067504883\n",
      "0.002264738082885742\n",
      "0.002452373504638672\n",
      "0.0023827552795410156\n",
      "0.00229644775390625\n",
      "0.003096342086791992\n",
      "0.003007650375366211\n",
      "0.0025835037231445312\n",
      "0.003074169158935547\n",
      "0.0034220218658447266\n",
      "0.0037598609924316406\n",
      "0.0036182403564453125\n",
      "0.0034797191619873047\n",
      "0.003438711166381836\n",
      "0.0034241676330566406\n",
      "0.003487110137939453\n",
      "0.0034761428833007812\n",
      "0.0034804344177246094\n",
      "0.0035316944122314453\n",
      "0.003409147262573242\n",
      "0.002738475799560547\n",
      "0.0024330615997314453\n",
      "0.0025479793548583984\n",
      "0.0023794174194335938\n",
      "0.002363920211791992\n",
      "0.0026683807373046875\n",
      "0.002532482147216797\n",
      "0.0025670528411865234\n",
      "0.0032520294189453125\n",
      "0.0024857521057128906\n",
      "0.0026252269744873047\n",
      "0.002466440200805664\n",
      "0.0025272369384765625\n",
      "0.002602815628051758\n",
      "0.0024814605712890625\n",
      "0.002492189407348633\n",
      "0.0024590492248535156\n",
      "0.0024657249450683594\n",
      "0.0025649070739746094\n",
      "0.002353668212890625\n",
      "0.0024688243865966797\n",
      "0.0025472640991210938\n",
      "0.0024225711822509766\n",
      "0.0023627281188964844\n",
      "0.0024743080139160156\n",
      "0.0023882389068603516\n",
      "0.0025191307067871094\n",
      "0.0025751590728759766\n",
      "0.002363920211791992\n",
      "0.0023686885833740234\n",
      "0.0025177001953125\n",
      "0.0025184154510498047\n",
      "0.002404451370239258\n",
      "0.0023984909057617188\n",
      "0.0023794174194335938\n",
      "0.0025207996368408203\n",
      "0.0026350021362304688\n",
      "0.0023212432861328125\n",
      "0.002405881881713867\n",
      "0.0023148059844970703\n",
      "0.0024170875549316406\n",
      "0.0023946762084960938\n",
      "0.0024671554565429688\n",
      "0.0024750232696533203\n",
      "0.0025398731231689453\n",
      "0.002859830856323242\n",
      "0.0038645267486572266\n",
      "0.0035424232482910156\n",
      "0.002513408660888672\n",
      "0.0023627281188964844\n",
      "0.002429962158203125\n",
      "0.002603769302368164\n",
      "0.002480745315551758\n",
      "0.0025551319122314453\n",
      "0.002599954605102539\n",
      "0.0026841163635253906\n",
      "0.0025472640991210938\n",
      "0.0028333663940429688\n",
      "0.0035691261291503906\n",
      "0.004193782806396484\n",
      "0.0030736923217773438\n",
      "0.002591848373413086\n",
      "0.0024051666259765625\n",
      "0.002443075180053711\n",
      "0.0028345584869384766\n",
      "0.0040166378021240234\n",
      "0.002783060073852539\n",
      "0.0027954578399658203\n",
      "0.0023543834686279297\n",
      "0.0025038719177246094\n",
      "0.002665281295776367\n",
      "0.0025963783264160156\n",
      "0.0024678707122802734\n",
      "0.0025320053100585938\n",
      "0.002523660659790039\n",
      "0.0025336742401123047\n",
      "0.0022628307342529297\n",
      "0.002388477325439453\n",
      "0.002439260482788086\n",
      "0.0024390220642089844\n",
      "0.002450704574584961\n",
      "0.0025496482849121094\n",
      "0.002467632293701172\n",
      "0.0024292469024658203\n",
      "0.0022842884063720703\n",
      "0.002962827682495117\n",
      "0.0028913021087646484\n",
      "0.002646923065185547\n",
      "0.002529144287109375\n",
      "0.002435922622680664\n",
      "0.002361297607421875\n",
      "0.002626180648803711\n",
      "0.002560853958129883\n",
      "0.002617359161376953\n",
      "0.002694368362426758\n",
      "0.0024373531341552734\n",
      "0.0025093555450439453\n",
      "0.0026140213012695312\n",
      "0.0023093223571777344\n",
      "0.002480745315551758\n",
      "0.0024445056915283203\n",
      "0.0022993087768554688\n",
      "0.002440214157104492\n",
      "0.0024924278259277344\n",
      "0.0023469924926757812\n",
      "0.002481222152709961\n",
      "0.0026900768280029297\n",
      "0.0025103092193603516\n",
      "0.0024585723876953125\n",
      "0.002506256103515625\n",
      "0.0026874542236328125\n",
      "0.0024826526641845703\n",
      "0.0022776126861572266\n",
      "0.002410888671875\n",
      "0.002396821975708008\n",
      "0.0023975372314453125\n",
      "0.0029447078704833984\n",
      "0.0023882389068603516\n",
      "0.0024831295013427734\n",
      "0.002504587173461914\n",
      "0.0025501251220703125\n",
      "0.0026226043701171875\n",
      "0.0025060176849365234\n",
      "0.002577543258666992\n",
      "0.002610921859741211\n",
      "0.0023195743560791016\n",
      "0.0023567676544189453\n",
      "0.002432107925415039\n",
      "0.002489805221557617\n",
      "0.002432107925415039\n",
      "0.0028395652770996094\n",
      "0.002341747283935547\n",
      "0.0023946762084960938\n",
      "0.0025336742401123047\n",
      "0.0025916099548339844\n",
      "0.0026090145111083984\n",
      "0.0023910999298095703\n",
      "0.0025107860565185547\n",
      "0.003129720687866211\n",
      "0.0025701522827148438\n",
      "0.003039121627807617\n",
      "0.0024712085723876953\n",
      "0.002645254135131836\n",
      "0.002858400344848633\n",
      "0.0025322437286376953\n",
      "0.0028650760650634766\n",
      "0.0037746429443359375\n",
      "0.0038208961486816406\n",
      "0.0035483837127685547\n",
      "0.0037522315979003906\n",
      "0.002640962600708008\n",
      "0.0025606155395507812\n",
      "0.002279996871948242\n",
      "0.002291440963745117\n",
      "0.0023221969604492188\n",
      "0.002363443374633789\n",
      "0.0023033618927001953\n",
      "0.002373933792114258\n",
      "0.002450704574584961\n",
      "0.0027256011962890625\n",
      "0.0024225711822509766\n",
      "0.002501249313354492\n",
      "0.0026547908782958984\n",
      "0.0026416778564453125\n",
      "0.0023980140686035156\n",
      "0.002505779266357422\n",
      "0.0025322437286376953\n",
      "0.0025594234466552734\n",
      "0.002722501754760742\n",
      "0.0036973953247070312\n",
      "0.0039479732513427734\n",
      "0.0037126541137695312\n",
      "0.003213167190551758\n",
      "0.0032167434692382812\n",
      "0.0037424564361572266\n",
      "0.0037822723388671875\n",
      "0.0038661956787109375\n",
      "0.003908634185791016\n",
      "0.0037648677825927734\n",
      "0.003452301025390625\n",
      "0.0037055015563964844\n",
      "0.0029091835021972656\n",
      "0.0025298595428466797\n",
      "0.002499818801879883\n",
      "0.0024182796478271484\n",
      "0.0024461746215820312\n",
      "0.0023474693298339844\n",
      "0.002424478530883789\n",
      "0.0025787353515625\n",
      "0.00292205810546875\n",
      "0.0024919509887695312\n",
      "0.002382516860961914\n",
      "0.002513408660888672\n",
      "0.002460956573486328\n",
      "0.0025787353515625\n",
      "0.0025136470794677734\n",
      "0.0023937225341796875\n",
      "0.0023500919342041016\n",
      "0.0024993419647216797\n",
      "0.0024573802947998047\n",
      "0.0025060176849365234\n",
      "0.002616405487060547\n",
      "0.002550840377807617\n",
      "0.0025262832641601562\n",
      "0.0031180381774902344\n",
      "0.0038645267486572266\n",
      "0.003844738006591797\n",
      "0.0038170814514160156\n",
      "0.003844738006591797\n",
      "0.0043182373046875\n",
      "0.0030410289764404297\n",
      "0.002579927444458008\n",
      "0.0026121139526367188\n",
      "0.002638101577758789\n",
      "0.0026264190673828125\n",
      "0.002549409866333008\n",
      "0.002633810043334961\n",
      "0.0023894309997558594\n",
      "0.0023851394653320312\n",
      "0.002683877944946289\n",
      "0.0026416778564453125\n",
      "0.002742290496826172\n",
      "0.0032362937927246094\n",
      "0.0028526782989501953\n",
      "0.002573728561401367\n",
      "0.0023970603942871094\n",
      "0.002679586410522461\n",
      "0.0025794506072998047\n",
      "0.0027506351470947266\n",
      "0.002482175827026367\n",
      "0.002640962600708008\n",
      "0.002798318862915039\n",
      "0.002395153045654297\n",
      "0.003859281539916992\n",
      "0.003567934036254883\n",
      "0.003209829330444336\n",
      "0.003541707992553711\n",
      "0.0034258365631103516\n",
      "0.0025746822357177734\n",
      "0.002444744110107422\n",
      "0.002565145492553711\n",
      "0.0023674964904785156\n",
      "0.002337932586669922\n",
      "0.0028352737426757812\n",
      "0.002384185791015625\n",
      "0.0027332305908203125\n",
      "0.0036590099334716797\n",
      "0.002470731735229492\n",
      "0.0025093555450439453\n",
      "0.002496957778930664\n",
      "0.002355337142944336\n",
      "0.002244234085083008\n",
      "0.0022394657135009766\n",
      "0.002988100051879883\n",
      "0.0024840831756591797\n",
      "0.0024521350860595703\n",
      "0.002538919448852539\n",
      "0.002256155014038086\n",
      "0.002320528030395508\n",
      "0.0024602413177490234\n",
      "0.002401590347290039\n",
      "0.0025787353515625\n",
      "0.0027494430541992188\n",
      "0.0024025440216064453\n",
      "0.002321004867553711\n",
      "0.002405881881713867\n",
      "0.0023779869079589844\n",
      "0.0025017261505126953\n",
      "0.002528667449951172\n",
      "0.002267122268676758\n",
      "0.0023517608642578125\n",
      "0.002243518829345703\n",
      "0.0022690296173095703\n",
      "0.0023126602172851562\n",
      "0.0023005008697509766\n",
      "0.002095460891723633\n",
      "0.0028204917907714844\n",
      "0.0026216506958007812\n",
      "0.0023522377014160156\n",
      "0.0026929378509521484\n",
      "0.0022411346435546875\n",
      "0.0023069381713867188\n",
      "0.0024335384368896484\n",
      "0.0025637149810791016\n",
      "0.0024423599243164062\n",
      "0.0029685497283935547\n",
      "0.003072500228881836\n",
      "0.002780914306640625\n",
      "0.0024399757385253906\n",
      "0.002496004104614258\n",
      "0.002396106719970703\n",
      "0.002259492874145508\n",
      "0.002300262451171875\n",
      "0.0024056434631347656\n",
      "0.0021691322326660156\n",
      "0.0021626949310302734\n",
      "0.002241373062133789\n",
      "0.002357006072998047\n",
      "0.0029151439666748047\n",
      "0.0025353431701660156\n",
      "0.0024285316467285156\n",
      "0.00266265869140625\n",
      "0.002484560012817383\n",
      "0.0024433135986328125\n",
      "0.002382993698120117\n",
      "0.0023970603942871094\n",
      "0.0022017955780029297\n",
      "0.0023832321166992188\n",
      "0.0023005008697509766\n",
      "0.0022554397583007812\n",
      "0.002297639846801758\n",
      "0.002371072769165039\n",
      "0.002326488494873047\n",
      "0.002261638641357422\n",
      "0.002285003662109375\n",
      "0.002407550811767578\n",
      "0.002454996109008789\n",
      "0.0022258758544921875\n",
      "0.002327442169189453\n",
      "0.002241373062133789\n",
      "0.0022614002227783203\n",
      "0.0023446083068847656\n",
      "0.002330780029296875\n",
      "0.002145051956176758\n",
      "0.0024280548095703125\n",
      "0.0024461746215820312\n",
      "0.002526998519897461\n",
      "0.002409219741821289\n",
      "0.002327442169189453\n",
      "0.002380847930908203\n",
      "0.0023550987243652344\n",
      "0.0022208690643310547\n",
      "0.0022292137145996094\n",
      "0.002414703369140625\n",
      "0.002231121063232422\n",
      "0.002215862274169922\n",
      "0.0024178028106689453\n",
      "0.002371072769165039\n",
      "0.002652883529663086\n",
      "0.0028498172760009766\n",
      "0.003304719924926758\n",
      "0.0032079219818115234\n",
      "0.003723621368408203\n",
      "0.003944873809814453\n",
      "0.004107952117919922\n",
      "0.003984928131103516\n",
      "0.0029942989349365234\n",
      "0.0025916099548339844\n",
      "0.0023276805877685547\n",
      "0.0025348663330078125\n",
      "0.0024247169494628906\n",
      "0.002666950225830078\n",
      "0.002466440200805664\n",
      "0.002903461456298828\n",
      "0.0025856494903564453\n",
      "0.0025560855865478516\n",
      "0.002347707748413086\n",
      "0.002233266830444336\n",
      "0.002330780029296875\n",
      "0.002349853515625\n",
      "0.002290487289428711\n",
      "0.002344846725463867\n",
      "0.0022361278533935547\n",
      "0.002335071563720703\n",
      "0.002476215362548828\n",
      "0.0033063888549804688\n",
      "0.0028820037841796875\n",
      "0.0028429031372070312\n",
      "0.0023818016052246094\n",
      "0.002172231674194336\n",
      "0.002218008041381836\n",
      "0.0030159950256347656\n",
      "0.002759218215942383\n",
      "0.0025489330291748047\n",
      "0.0023331642150878906\n",
      "0.0022530555725097656\n",
      "0.0025038719177246094\n",
      "0.0025255680084228516\n",
      "0.002367258071899414\n",
      "0.002298116683959961\n",
      "0.0022590160369873047\n",
      "0.0023260116577148438\n",
      "0.0023949146270751953\n",
      "0.002268075942993164\n",
      "0.0023012161254882812\n",
      "0.0024263858795166016\n",
      "0.0024259090423583984\n",
      "0.002262592315673828\n",
      "0.002384185791015625\n",
      "0.0023102760314941406\n",
      "0.002241373062133789\n",
      "0.0024607181549072266\n",
      "0.0024275779724121094\n",
      "0.002434968948364258\n",
      "0.002359151840209961\n",
      "0.00222015380859375\n",
      "0.0024051666259765625\n",
      "0.0024330615997314453\n",
      "0.0022482872009277344\n",
      "0.0023038387298583984\n",
      "0.002323627471923828\n",
      "0.0022919178009033203\n",
      "0.002393484115600586\n",
      "0.003306865692138672\n",
      "0.0035123825073242188\n",
      "0.003626585006713867\n",
      "0.0035517215728759766\n",
      "0.003325223922729492\n",
      "0.0022726058959960938\n",
      "0.0023696422576904297\n",
      "0.0023899078369140625\n",
      "0.002353668212890625\n",
      "0.0022547245025634766\n",
      "0.0024766921997070312\n",
      "0.002460956573486328\n",
      "0.0022742748260498047\n",
      "0.0022640228271484375\n",
      "0.002492666244506836\n",
      "0.002359151840209961\n",
      "0.002315998077392578\n",
      "0.002649068832397461\n",
      "0.002227306365966797\n",
      "0.0023508071899414062\n",
      "0.002389669418334961\n",
      "0.0023834705352783203\n",
      "0.002164602279663086\n",
      "0.0025162696838378906\n",
      "0.0022454261779785156\n",
      "0.002149820327758789\n",
      "0.002263784408569336\n",
      "0.00235748291015625\n",
      "0.002317190170288086\n",
      "0.002170085906982422\n",
      "0.002344846725463867\n",
      "0.002401590347290039\n",
      "0.002246379852294922\n",
      "0.002168893814086914\n",
      "0.0022847652435302734\n",
      "0.002293109893798828\n",
      "0.0022144317626953125\n",
      "0.002278566360473633\n",
      "0.002373933792114258\n",
      "0.0021598339080810547\n",
      "0.002094745635986328\n",
      "0.002442598342895508\n",
      "0.0023415088653564453\n",
      "0.002410411834716797\n",
      "0.0023119449615478516\n",
      "0.002237558364868164\n",
      "0.002918243408203125\n",
      "0.0029935836791992188\n",
      "0.0023043155670166016\n",
      "0.002407550811767578\n",
      "0.0023615360260009766\n",
      "0.002246379852294922\n",
      "0.00251007080078125\n",
      "0.0027065277099609375\n",
      "0.002873659133911133\n",
      "0.00252532958984375\n",
      "0.0024585723876953125\n",
      "0.0025582313537597656\n",
      "0.0023343563079833984\n",
      "0.0023260116577148438\n",
      "0.00229644775390625\n",
      "0.0022585391998291016\n",
      "0.0029816627502441406\n",
      "0.004346370697021484\n",
      "0.003609180450439453\n",
      "0.00254058837890625\n",
      "0.002511739730834961\n",
      "0.003135204315185547\n",
      "0.0023889541625976562\n",
      "0.0022788047790527344\n",
      "0.0023055076599121094\n",
      "0.0024034976959228516\n",
      "0.0021407604217529297\n",
      "0.0024261474609375\n",
      "0.0023827552795410156\n",
      "0.002421855926513672\n",
      "0.0022230148315429688\n",
      "0.002283334732055664\n",
      "0.0022933483123779297\n",
      "0.002574443817138672\n",
      "0.0022940635681152344\n",
      "0.0023458003997802734\n",
      "0.002611398696899414\n",
      "0.002426624298095703\n",
      "0.0023980140686035156\n",
      "0.002207040786743164\n",
      "0.0022001266479492188\n",
      "0.002302408218383789\n",
      "0.002676725387573242\n",
      "0.003706693649291992\n",
      "0.0026247501373291016\n",
      "0.0023064613342285156\n",
      "0.002332448959350586\n",
      "0.002343893051147461\n",
      "0.002256631851196289\n",
      "0.0025382041931152344\n",
      "0.002212047576904297\n",
      "0.0022339820861816406\n",
      "0.002454996109008789\n",
      "0.002307415008544922\n",
      "0.0021657943725585938\n",
      "0.0023708343505859375\n",
      "0.0023224353790283203\n",
      "0.002381563186645508\n",
      "0.0024831295013427734\n",
      "0.0024366378784179688\n",
      "0.002323627471923828\n",
      "0.002468109130859375\n",
      "0.0024232864379882812\n",
      "0.002242565155029297\n",
      "0.0024521350860595703\n",
      "0.002530336380004883\n",
      "0.0022499561309814453\n",
      "0.002399444580078125\n",
      "0.0024852752685546875\n",
      "0.002457141876220703\n",
      "0.002353668212890625\n",
      "0.0022764205932617188\n",
      "0.0025262832641601562\n",
      "0.002412557601928711\n",
      "0.002306699752807617\n",
      "0.002298593521118164\n",
      "0.002286195755004883\n",
      "0.002260923385620117\n",
      "0.0024111270904541016\n",
      "0.002228975296020508\n",
      "0.0022165775299072266\n",
      "0.0023436546325683594\n",
      "0.0030896663665771484\n",
      "0.002560853958129883\n",
      "0.002941608428955078\n",
      "0.002290964126586914\n",
      "0.0022373199462890625\n",
      "0.0024247169494628906\n",
      "0.0026807785034179688\n",
      "0.0034246444702148438\n",
      "0.0030574798583984375\n",
      "0.0025315284729003906\n",
      "0.002450704574584961\n",
      "0.002280712127685547\n",
      "0.0023310184478759766\n",
      "0.002307891845703125\n",
      "0.0023839473724365234\n",
      "0.002424001693725586\n",
      "0.002265453338623047\n",
      "0.0021665096282958984\n",
      "0.002343416213989258\n",
      "0.002377033233642578\n",
      "0.0023849010467529297\n",
      "0.0023453235626220703\n",
      "0.00299835205078125\n",
      "0.002309560775756836\n",
      "0.0026557445526123047\n",
      "0.0025184154510498047\n",
      "0.0025238990783691406\n",
      "0.002368927001953125\n",
      "0.002465486526489258\n",
      "0.002253293991088867\n",
      "0.0023598670959472656\n",
      "0.0023403167724609375\n",
      "0.002231121063232422\n",
      "0.0024056434631347656\n",
      "0.002444028854370117\n",
      "0.0029413700103759766\n",
      "0.002346515655517578\n",
      "0.0021893978118896484\n",
      "0.0023021697998046875\n",
      "0.0023736953735351562\n",
      "0.0024662017822265625\n",
      "0.0025360584259033203\n",
      "0.002245664596557617\n",
      "0.0023851394653320312\n",
      "0.002629995346069336\n",
      "0.002410888671875\n",
      "0.00274658203125\n",
      "0.002384185791015625\n",
      "0.0023088455200195312\n",
      "0.0024042129516601562\n",
      "0.0024805068969726562\n",
      "0.002422809600830078\n",
      "0.0024175643920898438\n",
      "0.002446413040161133\n",
      "0.002388477325439453\n",
      "0.002537250518798828\n",
      "0.0025479793548583984\n",
      "0.002935647964477539\n",
      "0.0025682449340820312\n",
      "0.003936767578125\n",
      "0.003864765167236328\n",
      "0.0036330223083496094\n",
      "0.003759145736694336\n",
      "0.003892183303833008\n",
      "0.003885984420776367\n",
      "0.004010677337646484\n",
      "0.0034105777740478516\n",
      "0.0028429031372070312\n",
      "0.0024063587188720703\n",
      "0.0024073123931884766\n",
      "0.002372264862060547\n",
      "0.0022895336151123047\n",
      "0.002400636672973633\n",
      "0.0022783279418945312\n",
      "0.0024051666259765625\n",
      "0.0024673938751220703\n",
      "0.002574920654296875\n",
      "0.0024347305297851562\n",
      "0.0031654834747314453\n",
      "0.0024912357330322266\n",
      "0.002834796905517578\n",
      "0.0025522708892822266\n",
      "0.002556324005126953\n",
      "0.002805948257446289\n",
      "0.002591848373413086\n",
      "0.002557039260864258\n",
      "0.0029630661010742188\n",
      "0.002589702606201172\n",
      "0.002516031265258789\n",
      "0.002626657485961914\n",
      "0.0025115013122558594\n",
      "0.002415895462036133\n",
      "0.0022230148315429688\n",
      "0.002456188201904297\n",
      "0.0024423599243164062\n",
      "0.002371549606323242\n",
      "0.002218961715698242\n",
      "0.0023627281188964844\n",
      "0.002338409423828125\n",
      "0.002398967742919922\n",
      "0.0024192333221435547\n",
      "0.0022783279418945312\n",
      "0.002152681350708008\n",
      "0.002427816390991211\n",
      "0.003206491470336914\n",
      "0.0039708614349365234\n",
      "0.0036652088165283203\n",
      "0.0038590431213378906\n",
      "0.003414630889892578\n",
      "0.0036513805389404297\n",
      "0.003983974456787109\n",
      "0.0037679672241210938\n",
      "0.0037245750427246094\n",
      "0.002432584762573242\n",
      "0.002474069595336914\n",
      "0.0023987293243408203\n",
      "0.0022068023681640625\n",
      "0.0024518966674804688\n",
      "0.0025322437286376953\n",
      "0.002570629119873047\n",
      "0.0025615692138671875\n",
      "0.0023238658905029297\n",
      "0.0022754669189453125\n",
      "0.002428293228149414\n",
      "0.002603769302368164\n",
      "0.002499103546142578\n",
      "0.002699136734008789\n",
      "0.002427339553833008\n",
      "0.0024323463439941406\n",
      "0.0022864341735839844\n",
      "0.0021343231201171875\n",
      "0.002453327178955078\n",
      "0.002397775650024414\n",
      "0.002522706985473633\n",
      "0.0025038719177246094\n",
      "0.002370119094848633\n",
      "0.0023632049560546875\n",
      "0.002414703369140625\n",
      "0.0023698806762695312\n",
      "0.0022623538970947266\n",
      "0.002404928207397461\n",
      "0.002202272415161133\n",
      "0.0022563934326171875\n",
      "0.002310037612915039\n",
      "0.0023403167724609375\n",
      "0.002285003662109375\n",
      "0.0024099349975585938\n",
      "0.002382040023803711\n",
      "0.0023496150970458984\n",
      "0.002357006072998047\n",
      "0.0023033618927001953\n",
      "0.0023157596588134766\n",
      "0.0025238990783691406\n",
      "0.0026955604553222656\n",
      "0.002725362777709961\n",
      "0.0024945735931396484\n",
      "0.0034775733947753906\n",
      "0.004108905792236328\n",
      "0.0034477710723876953\n",
      "0.0026252269744873047\n",
      "0.002919912338256836\n",
      "0.0026826858520507812\n",
      "0.003321409225463867\n",
      "0.0024271011352539062\n",
      "0.002356290817260742\n",
      "0.002569913864135742\n",
      "0.0028312206268310547\n",
      "0.0029239654541015625\n",
      "0.0026149749755859375\n",
      "0.0025177001953125\n",
      "0.0025205612182617188\n",
      "0.0026633739471435547\n",
      "0.0033636093139648438\n",
      "0.002628803253173828\n",
      "0.0034148693084716797\n",
      "0.004087924957275391\n",
      "0.0038061141967773438\n",
      "0.002815723419189453\n",
      "0.0025949478149414062\n",
      "0.0025482177734375\n",
      "0.0025353431701660156\n",
      "0.0025663375854492188\n",
      "0.002645730972290039\n",
      "0.0028257369995117188\n",
      "0.002599477767944336\n",
      "0.002638578414916992\n",
      "0.0026960372924804688\n",
      "0.0035614967346191406\n",
      "0.002574443817138672\n",
      "0.002543210983276367\n",
      "0.002811908721923828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00269923556125027"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_time = []\n",
    "for i in range(1, len(x_test_np)):\n",
    "    # print(i)\n",
    "    start_time = time.time()\n",
    "    interpreter = lce.testing.Interpreter(lce_model)\n",
    "    y_pred_prob = interpreter.predict(x_test_np[i-1:i], verbose=0)\n",
    "    y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
    "    stop_time = time.time() - start_time\n",
    "    print(stop_time)\n",
    "    exec_time.append(stop_time)\n",
    "sum(exec_time) / len(exec_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9r6jhc1m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9r6jhc1m/assets\n",
      "2024-07-24 23:22:50.729140: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-07-24 23:22:50.729204: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-07-24 23:22:50.729435: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp9r6jhc1m\n",
      "2024-07-24 23:22:50.733470: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-24 23:22:50.733504: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp9r6jhc1m\n",
      "2024-07-24 23:22:50.745406: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-07-24 23:22:50.811442: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp9r6jhc1m\n",
      "2024-07-24 23:22:50.841190: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 111756 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 14, Total Ops 38, % non-converted = 36.84 %\n",
      " * 14 ARITH ops\n",
      "\n",
      "- arith.constant:   14 occurrences  (f32: 13, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 81.55%\n",
      "Recall: 94.98%\n",
      "Precision: 65.02%\n",
      "F1-score: 77.20%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7713843221729665\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7676866511385799\n",
      "\n",
      "Time for Test dataset:\n",
      "Accuracy: 81.55%\n",
      "Recall: 94.98%\n",
      "Precision: 65.02%\n",
      "F1-score: 77.20%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.001 seconds\n",
      "Max: 0.003 seconds\n",
      "Min: 0.001 seconds\n",
      "\n",
      "\n",
      "Model file name:  spectrogram_models_from_notebooks/bnn/bnn_mel_spec.tflite\n",
      "File size: 403.836 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    "    ) = predict_and_print_full_results(tflite_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "evaluate_time_of_prediction(tflite_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "TF_LITE_MODEL_FILE_NAME = \"spectrogram_models_from_notebooks/bnn/bnn_mel_spec.tflite\"\n",
    "open(TF_LITE_MODEL_FILE_NAME, \"wb\").write(tflite_model)\n",
    "print(\"\\n\")\n",
    "print(\"Model file name: \", TF_LITE_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: serving_default_quant_conv2d_2_input:0, Index: 0, Shape: [  1 184  80   1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_6/batchnorm/mul, Index: 1, Shape: [  16 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/batchnorm/mul, Index: 2, Shape: [ 2 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D, Index: 3, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D1, Index: 4, Shape: [4 3 3 1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D, Index: 5, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D1, Index: 6, Shape: [8 3 3 4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/batchnorm/sub, Index: 7, Shape: [2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_6/batchnorm/sub, Index: 8, Shape: [16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/flatten_1/Const, Index: 9, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D/ste_sign_7/add/y, Index: 10, Shape: [], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV3, Index: 11, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV31, Index: 12, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV3, Index: 13, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV31, Index: 14, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D2, Index: 15, Shape: [  1 182  78   4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/max_pooling2d_2/MaxPool, Index: 16, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV32, Index: 17, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV33, Index: 18, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/Sign, Index: 19, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/add, Index: 20, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/Sign_1, Index: 21, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D2, Index: 22, Shape: [ 1 89 37  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/max_pooling2d_3/MaxPool, Index: 23, Shape: [ 1 44 18  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV32, Index: 24, Shape: [ 1 44 18  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV33, Index: 25, Shape: [ 1 44 18  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/flatten_1/Reshape, Index: 26, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/Sign, Index: 27, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/add, Index: 28, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/Sign_1, Index: 29, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/MatMul;sequential_1/batch_normalization_6/batchnorm/mul;sequential_1/batch_normalization_6/batchnorm/add_1, Index: 30, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/Sign, Index: 31, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/add, Index: 32, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/Sign_1, Index: 33, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/MatMul;sequential_1/batch_normalization_7/batchnorm/mul;sequential_1/batch_normalization_7/batchnorm/add_1, Index: 34, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: StatefulPartitionedCall:0, Index: 35, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 48, Shape: [9 4], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 49, Shape: [36  8], dtype: <class 'numpy.float32'>\n",
      "Tensor serving_default_quant_conv2d_2_input:0 - Shape: (1, 184, 80, 1), Data: [[[[ 1.2386266e+13]\n",
      "   [ 0.0000000e+00]\n",
      "   [ 2.0582334e+10]\n",
      "   ...\n",
      "   [-2.8712130e+00]\n",
      "   [-3.8945668e+00]\n",
      "   [-5.7103419e+00]]\n",
      "\n",
      "  [[-1.0653405e+00]\n",
      "   [-8.6499822e-01]\n",
      "   [-1.4073898e+00]\n",
      "   ...\n",
      "   [-3.0824087e+00]\n",
      "   [-3.8587742e+00]\n",
      "   [-5.6270499e+00]]\n",
      "\n",
      "  [[-4.7574413e-01]\n",
      "   [-5.0857115e-01]\n",
      "   [-1.5153300e+00]\n",
      "   ...\n",
      "   [-3.0004165e+00]\n",
      "   [-3.7818110e+00]\n",
      "   [-5.3767481e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.6431216e+00]\n",
      "   [-1.2507148e+00]\n",
      "   [-7.2240549e-01]\n",
      "   ...\n",
      "   [-3.3817739e+00]\n",
      "   [-3.6054962e+00]\n",
      "   [-5.2346578e+00]]\n",
      "\n",
      "  [[-1.1810825e+00]\n",
      "   [-1.0512950e+00]\n",
      "   [-1.2631068e+00]\n",
      "   ...\n",
      "   [-3.2193780e+00]\n",
      "   [-3.9600673e+00]\n",
      "   [-5.6320443e+00]]\n",
      "\n",
      "  [[-7.0521295e-01]\n",
      "   [-5.5519056e-01]\n",
      "   [-1.4383278e+00]\n",
      "   ...\n",
      "   [-2.8993685e+00]\n",
      "   [-4.1683130e+00]\n",
      "   [-5.7703748e+00]]]]\n",
      "Tensor sequential_1/batch_normalization_6/batchnorm/mul - Shape: (16, 6336), Data: [[ 0.00219819  0.00219819 -0.00219819 ...  0.00219819 -0.00219819\n",
      "  -0.00219819]\n",
      " [ 0.00226552  0.00226552  0.00226552 ...  0.00226552 -0.00226552\n",
      "   0.00226552]\n",
      " [ 0.0036621   0.0036621  -0.0036621  ... -0.0036621  -0.0036621\n",
      "  -0.0036621 ]\n",
      " ...\n",
      " [-0.00232448  0.00232448 -0.00232448 ...  0.00232448 -0.00232448\n",
      "   0.00232448]\n",
      " [ 0.0021178   0.0021178  -0.0021178  ...  0.0021178   0.0021178\n",
      "  -0.0021178 ]\n",
      " [ 0.00173921  0.00173921 -0.00173921 ... -0.00173921 -0.00173921\n",
      "  -0.00173921]]\n",
      "Tensor sequential_1/batch_normalization_7/batchnorm/mul - Shape: (2, 16), Data: [[ 0.16134323  0.16134323 -0.16134323  0.16134323 -0.16134323 -0.16134323\n",
      "  -0.16134323  0.16134323 -0.16134323  0.16134323  0.16134323  0.16134323\n",
      "  -0.16134323  0.16134323 -0.16134323  0.16134323]\n",
      " [ 0.18315466  0.18315466  0.18315466  0.18315466  0.18315466 -0.18315466\n",
      "  -0.18315466 -0.18315466  0.18315466  0.18315466 -0.18315466 -0.18315466\n",
      "  -0.18315466  0.18315466  0.18315466  0.18315466]]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D - Shape: (4,), Data: [0. 0. 0. 0.]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D1 - Shape: (4, 3, 3, 1), Data: [[[[ 1.]\n",
      "   [-1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [-1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [-1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [-1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [-1.]]]]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D - Shape: (8,), Data: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D1 - Shape: (8, 3, 3, 4), Data: [[[[-1.  1.  1.  1.]\n",
      "   [-1.  1. -1. -1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1. -1.  1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [-1. -1. -1.  1.]]\n",
      "\n",
      "  [[-1.  1. -1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [-1.  1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1. -1.  1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [-1.  1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1.  1. -1.]\n",
      "   [-1.  1. -1. -1.]\n",
      "   [-1. -1. -1. -1.]]\n",
      "\n",
      "  [[ 1.  1. -1.  1.]\n",
      "   [ 1.  1.  1. -1.]\n",
      "   [ 1. -1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1. -1.]\n",
      "   [-1. -1.  1.  1.]\n",
      "   [-1. -1. -1. -1.]]\n",
      "\n",
      "  [[ 1.  1. -1.  1.]\n",
      "   [-1.  1.  1.  1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1.  1.  1. -1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [-1.  1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1. -1. -1.  1.]\n",
      "   [ 1. -1. -1. -1.]\n",
      "   [-1.  1.  1. -1.]]\n",
      "\n",
      "  [[ 1. -1.  1. -1.]\n",
      "   [-1.  1.  1.  1.]\n",
      "   [-1. -1.  1. -1.]]\n",
      "\n",
      "  [[-1.  1.  1.  1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [-1. -1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1.  1.]\n",
      "   [ 1.  1. -1. -1.]\n",
      "   [ 1. -1. -1.  1.]]\n",
      "\n",
      "  [[-1.  1. -1. -1.]\n",
      "   [-1. -1. -1. -1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[-1. -1.  1.  1.]\n",
      "   [ 1. -1. -1. -1.]\n",
      "   [ 1. -1. -1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  1.  1. -1.]\n",
      "   [-1.  1.  1. -1.]\n",
      "   [ 1.  1.  1.  1.]]\n",
      "\n",
      "  [[-1. -1. -1. -1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [ 1. -1. -1.  1.]]\n",
      "\n",
      "  [[-1.  1. -1. -1.]\n",
      "   [ 1.  1. -1. -1.]\n",
      "   [ 1. -1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1. -1.  1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [ 1. -1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1.  1.  1.]\n",
      "   [ 1. -1. -1.  1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1. -1.  1.  1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [ 1.  1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [-1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1. -1.  1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [ 1. -1.  1. -1.]]\n",
      "\n",
      "  [[ 1. -1. -1.  1.]\n",
      "   [ 1.  1.  1. -1.]\n",
      "   [-1.  1.  1.  1.]]]]\n",
      "Tensor sequential_1/batch_normalization_7/batchnorm/sub - Shape: (2,), Data: [ 0.15048203 -0.18784165]\n",
      "Tensor sequential_1/batch_normalization_6/batchnorm/sub - Shape: (16,), Data: [ 0.0684495   0.21373542  0.00509679 -0.18022566 -0.44325015  0.27266815\n",
      "  0.00624212  0.45205006 -0.18756041  0.22879818  0.21801871  0.5046498\n",
      " -0.26182082  0.20964634 -0.20661964  0.10286941]\n",
      "Tensor sequential_1/flatten_1/Const - Shape: (2,), Data: [  -1 6336]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D/ste_sign_7/add/y - Shape: (), Data: 0.10000000149011612\n",
      "Tensor sequential_1/batch_normalization_4/FusedBatchNormV3 - Shape: (4,), Data: [0.36113146 0.32689458 0.10472357 0.07731231]\n",
      "Tensor sequential_1/batch_normalization_4/FusedBatchNormV31 - Shape: (4,), Data: [-0.926156   -0.57881653  0.40140867 -0.6472521 ]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV3 - Shape: (8,), Data: [0.25254557 0.28072882 0.27856448 0.09429757 0.14266767 0.22288242\n",
      " 0.10855322 0.24953373]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV31 - Shape: (8,), Data: [-0.51499224 -0.39927748 -0.7235615  -0.04486027 -0.1764941  -0.30370513\n",
      "  0.01052637 -0.52059585]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detail \u001b[38;5;129;01min\u001b[39;00m tensor_details:\n\u001b[0;32m---> 12\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetail[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:926\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index):\n\u001b[1;32m    879\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"spectrogram_models_from_notebooks/bnn/bnn_mel_spec.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get tensor details\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "for detail in tensor_details:\n",
    "    print(f\"Name: {detail['name']}, Index: {detail['index']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "\n",
    "# Extract weights\n",
    "for detail in tensor_details:\n",
    "    tensor = interpreter.tensor(detail['index'])()\n",
    "    print(f\"Tensor {detail['name']} - Shape: {tensor.shape}, Data: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp40el20ai/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp40el20ai/assets\n",
      "2024-07-24 23:20:55.575793: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-07-24 23:20:55.575870: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-07-24 23:20:55.576047: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp40el20ai\n",
      "2024-07-24 23:20:55.578024: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-24 23:20:55.578048: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp40el20ai\n",
      "2024-07-24 23:20:55.583628: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-07-24 23:20:55.631920: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp40el20ai\n",
      "2024-07-24 23:20:55.652062: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 76015 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 38, % non-converted = 34.21 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 81.55%\n",
      "Recall: 94.98%\n",
      "Precision: 65.02%\n",
      "F1-score: 77.20%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7713843221729665\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7611104028344549\n",
      "\n",
      "Time for Test dataset:\n",
      "Accuracy: 81.55%\n",
      "Recall: 94.98%\n",
      "Precision: 65.02%\n",
      "F1-score: 77.20%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.001 seconds\n",
      "Max: 0.003 seconds\n",
      "Min: 0.001 seconds\n",
      "\n",
      "\n",
      "Model file name:  spectrogram_models_from_notebooks/bnn/bnn_mel_spec_drq.tflite\n",
      "File size: 106.914 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "dynamic_range_quant_converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "dynamic_range_quant_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dynamic_range_quant_model = dynamic_range_quant_converter.convert()\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    "    ) = predict_and_print_full_results(dynamic_range_quant_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "evaluate_time_of_prediction(dynamic_range_quant_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "DRQ_MODEL_FILE_NAME = \"spectrogram_models_from_notebooks/bnn/bnn_mel_spec_drq.tflite\"\n",
    "open(DRQ_MODEL_FILE_NAME, \"wb\").write(dynamic_range_quant_model)\n",
    "print(\"\\n\")\n",
    "print(\"Model file name: \", DRQ_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(DRQ_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: serving_default_quant_conv2d_2_input:0, Index: 0, Shape: [  1 184  80   1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV3, Index: 1, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV31, Index: 2, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV3, Index: 3, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV31, Index: 4, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D/ste_sign_7/add/y, Index: 5, Shape: [], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/flatten_1/Const, Index: 6, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/batch_normalization_6/batchnorm/sub, Index: 7, Shape: [16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/batchnorm/sub, Index: 8, Shape: [2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D, Index: 9, Shape: [8 3 3 4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D1, Index: 10, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D, Index: 11, Shape: [4 3 3 1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D1, Index: 12, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/batchnorm/mul, Index: 13, Shape: [ 2 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_6/batchnorm/mul, Index: 14, Shape: [  16 6336], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D2, Index: 15, Shape: [  1 182  78   4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/max_pooling2d_2/MaxPool, Index: 16, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV32, Index: 17, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV33, Index: 18, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/Sign, Index: 19, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/add, Index: 20, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/Sign_1, Index: 21, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D2, Index: 22, Shape: [ 1 89 37  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/max_pooling2d_3/MaxPool, Index: 23, Shape: [ 1 44 18  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV32, Index: 24, Shape: [ 1 44 18  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV33, Index: 25, Shape: [ 1 44 18  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/flatten_1/Reshape, Index: 26, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/Sign, Index: 27, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/add, Index: 28, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/Sign_1, Index: 29, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/MatMul;sequential_1/batch_normalization_6/batchnorm/mul;sequential_1/batch_normalization_6/batchnorm/add_1, Index: 30, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/Sign, Index: 31, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/add, Index: 32, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/Sign_1, Index: 33, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/MatMul;sequential_1/batch_normalization_7/batchnorm/mul;sequential_1/batch_normalization_7/batchnorm/add_1, Index: 34, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: StatefulPartitionedCall:0, Index: 35, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: , Index: 36, Shape: [   1 6336], dtype: <class 'numpy.int8'>\n",
      "Name: , Index: 37, Shape: [1], dtype: <class 'numpy.float32'>\n",
      "Name: , Index: 38, Shape: [16  1], dtype: <class 'numpy.int32'>\n",
      "Name: , Index: 39, Shape: [1], dtype: <class 'numpy.int32'>\n",
      "Name: , Index: 40, Shape: [16], dtype: <class 'numpy.int32'>\n",
      "Name: Conv_hwcn_weights, Index: 48, Shape: [9 4], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 49, Shape: [36  8], dtype: <class 'numpy.float32'>\n",
      "Tensor serving_default_quant_conv2d_2_input:0 - Shape: (1, 184, 80, 1), Data: [[[[ 2.6917994e+10]\n",
      "   [ 0.0000000e+00]\n",
      "   [ 1.2545385e+15]\n",
      "   ...\n",
      "   [-2.8712130e+00]\n",
      "   [-3.8945668e+00]\n",
      "   [-5.7103419e+00]]\n",
      "\n",
      "  [[-1.0653405e+00]\n",
      "   [-8.6499822e-01]\n",
      "   [-1.4073898e+00]\n",
      "   ...\n",
      "   [-3.0824087e+00]\n",
      "   [-3.8587742e+00]\n",
      "   [-5.6270499e+00]]\n",
      "\n",
      "  [[-4.7574413e-01]\n",
      "   [-5.0857115e-01]\n",
      "   [-1.5153300e+00]\n",
      "   ...\n",
      "   [-3.0004165e+00]\n",
      "   [-3.7818110e+00]\n",
      "   [-5.3767481e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.6431216e+00]\n",
      "   [-1.2507148e+00]\n",
      "   [-7.2240549e-01]\n",
      "   ...\n",
      "   [-3.3817739e+00]\n",
      "   [-3.6054962e+00]\n",
      "   [-5.2346578e+00]]\n",
      "\n",
      "  [[-1.1810825e+00]\n",
      "   [-1.0512950e+00]\n",
      "   [-1.2631068e+00]\n",
      "   ...\n",
      "   [-3.2193780e+00]\n",
      "   [-3.9600673e+00]\n",
      "   [-5.6320443e+00]]\n",
      "\n",
      "  [[-7.0521295e-01]\n",
      "   [-5.5519056e-01]\n",
      "   [-1.4383278e+00]\n",
      "   ...\n",
      "   [-2.8993685e+00]\n",
      "   [-4.1683130e+00]\n",
      "   [-5.7703748e+00]]]]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV3 - Shape: (8,), Data: [-0.51499224 -0.39927748 -0.7235615  -0.04486027 -0.1764941  -0.30370513\n",
      "  0.01052637 -0.52059585]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV31 - Shape: (8,), Data: [0.25254557 0.28072882 0.27856448 0.09429757 0.14266767 0.22288242\n",
      " 0.10855322 0.24953373]\n",
      "Tensor sequential_1/batch_normalization_4/FusedBatchNormV3 - Shape: (4,), Data: [-0.926156   -0.57881653  0.40140867 -0.6472521 ]\n",
      "Tensor sequential_1/batch_normalization_4/FusedBatchNormV31 - Shape: (4,), Data: [0.36113146 0.32689458 0.10472357 0.07731231]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D/ste_sign_7/add/y - Shape: (), Data: 0.10000000149011612\n",
      "Tensor sequential_1/flatten_1/Const - Shape: (2,), Data: [  -1 6336]\n",
      "Tensor sequential_1/batch_normalization_6/batchnorm/sub - Shape: (16,), Data: [ 0.0684495   0.21373542  0.00509679 -0.18022566 -0.44325015  0.27266815\n",
      "  0.00624212  0.45205006 -0.18756041  0.22879818  0.21801871  0.5046498\n",
      " -0.26182082  0.20964634 -0.20661964  0.10286941]\n",
      "Tensor sequential_1/batch_normalization_7/batchnorm/sub - Shape: (2,), Data: [ 0.15048203 -0.18784165]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D - Shape: (8, 3, 3, 4), Data: [[[[-1.  1.  1.  1.]\n",
      "   [-1.  1. -1. -1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1. -1.  1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [-1. -1. -1.  1.]]\n",
      "\n",
      "  [[-1.  1. -1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [-1.  1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1. -1.  1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [-1.  1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1.  1. -1.]\n",
      "   [-1.  1. -1. -1.]\n",
      "   [-1. -1. -1. -1.]]\n",
      "\n",
      "  [[ 1.  1. -1.  1.]\n",
      "   [ 1.  1.  1. -1.]\n",
      "   [ 1. -1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1. -1.]\n",
      "   [-1. -1.  1.  1.]\n",
      "   [-1. -1. -1. -1.]]\n",
      "\n",
      "  [[ 1.  1. -1.  1.]\n",
      "   [-1.  1.  1.  1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1.  1.  1. -1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [-1.  1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1. -1. -1.  1.]\n",
      "   [ 1. -1. -1. -1.]\n",
      "   [-1.  1.  1. -1.]]\n",
      "\n",
      "  [[ 1. -1.  1. -1.]\n",
      "   [-1.  1.  1.  1.]\n",
      "   [-1. -1.  1. -1.]]\n",
      "\n",
      "  [[-1.  1.  1.  1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [-1. -1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1.  1.]\n",
      "   [ 1.  1. -1. -1.]\n",
      "   [ 1. -1. -1.  1.]]\n",
      "\n",
      "  [[-1.  1. -1. -1.]\n",
      "   [-1. -1. -1. -1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[-1. -1.  1.  1.]\n",
      "   [ 1. -1. -1. -1.]\n",
      "   [ 1. -1. -1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  1.  1. -1.]\n",
      "   [-1.  1.  1. -1.]\n",
      "   [ 1.  1.  1.  1.]]\n",
      "\n",
      "  [[-1. -1. -1. -1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [ 1. -1. -1.  1.]]\n",
      "\n",
      "  [[-1.  1. -1. -1.]\n",
      "   [ 1.  1. -1. -1.]\n",
      "   [ 1. -1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1. -1.  1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [ 1. -1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1.  1.  1.]\n",
      "   [ 1. -1. -1.  1.]\n",
      "   [ 1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1. -1.  1.  1.]\n",
      "   [ 1. -1.  1. -1.]\n",
      "   [ 1.  1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [-1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1. -1.  1. -1.]\n",
      "   [-1. -1. -1.  1.]\n",
      "   [ 1. -1.  1. -1.]]\n",
      "\n",
      "  [[ 1. -1. -1.  1.]\n",
      "   [ 1.  1.  1. -1.]\n",
      "   [-1.  1.  1.  1.]]]]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D1 - Shape: (8,), Data: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D - Shape: (4, 3, 3, 1), Data: [[[[ 1.]\n",
      "   [-1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [-1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [-1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [-1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]\n",
      "   [-1.]]]]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D1 - Shape: (4,), Data: [0. 0. 0. 0.]\n",
      "Tensor sequential_1/batch_normalization_7/batchnorm/mul - Shape: (2, 16), Data: [[ 0.16134323  0.16134323 -0.16134323  0.16134323 -0.16134323 -0.16134323\n",
      "  -0.16134323  0.16134323 -0.16134323  0.16134323  0.16134323  0.16134323\n",
      "  -0.16134323  0.16134323 -0.16134323  0.16134323]\n",
      " [ 0.18315466  0.18315466  0.18315466  0.18315466  0.18315466 -0.18315466\n",
      "  -0.18315466 -0.18315466  0.18315466  0.18315466 -0.18315466 -0.18315466\n",
      "  -0.18315466  0.18315466  0.18315466  0.18315466]]\n",
      "Tensor sequential_1/batch_normalization_6/batchnorm/mul - Shape: (16, 6336), Data: [[  64   64  -64 ...   64  -64  -64]\n",
      " [  66   66   66 ...   66  -66   66]\n",
      " [ 107  107 -107 ... -107 -107 -107]\n",
      " ...\n",
      " [ -68   68  -68 ...   68  -68   68]\n",
      " [  62   62  -62 ...   62   62  -62]\n",
      " [  51   51  -51 ...  -51  -51  -51]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detail \u001b[38;5;129;01min\u001b[39;00m tensor_details:\n\u001b[0;32m---> 12\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetail[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:926\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index):\n\u001b[1;32m    879\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_content=dynamic_range_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get tensor details\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "for detail in tensor_details:\n",
    "    print(f\"Name: {detail['name']}, Index: {detail['index']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "\n",
    "# Extract weights\n",
    "for detail in tensor_details:\n",
    "    tensor = interpreter.tensor(detail['index'])()\n",
    "    print(f\"Tensor {detail['name']} - Shape: {tensor.shape}, Data: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwa6fnxxc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwa6fnxxc/assets\n",
      "/home/polina/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-07-24 23:27:24.040662: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-07-24 23:27:24.040728: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-07-24 23:27:24.040939: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpwa6fnxxc\n",
      "2024-07-24 23:27:24.043069: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-24 23:27:24.043128: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpwa6fnxxc\n",
      "2024-07-24 23:27:24.049133: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-07-24 23:27:24.101205: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpwa6fnxxc\n",
      "2024-07-24 23:27:24.121472: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 80533 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 14, Total Ops 38, % non-converted = 36.84 %\n",
      " * 14 ARITH ops\n",
      "\n",
      "- arith.constant:   14 occurrences  (f32: 13, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(x_val_np).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "full_int_converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "full_int_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "full_int_converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "full_int_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "full_int_converter.inference_input_type = tf.uint8\n",
    "full_int_converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = full_int_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: serving_default_quant_conv2d_2_input:0, Index: 0, Shape: [  1 184  80   1], dtype: <class 'numpy.uint8'>\n",
      "Name: sequential_1/flatten_1/Const, Index: 1, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/batch_normalization_7/batchnorm/sub, Index: 2, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/batch_normalization_7/batchnorm/mul, Index: 3, Shape: [ 2 16], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_6/batchnorm/sub, Index: 4, Shape: [16], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/batch_normalization_6/batchnorm/mul, Index: 5, Shape: [  16 6336], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV31, Index: 6, Shape: [8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV3, Index: 7, Shape: [8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D, Index: 8, Shape: [8], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D1, Index: 9, Shape: [8 3 3 4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D/ste_sign_7/add/y, Index: 10, Shape: [], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV31, Index: 11, Shape: [4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV3, Index: 12, Shape: [4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D, Index: 13, Shape: [4], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D1, Index: 14, Shape: [4 3 3 1], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.quantize, Index: 15, Shape: [  1 184  80   1], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_2/QuantConv2D2, Index: 16, Shape: [  1 182  78   4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/max_pooling2d_2/MaxPool, Index: 17, Shape: [ 1 91 39  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV32, Index: 18, Shape: [ 1 91 39  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_4/FusedBatchNormV33, Index: 19, Shape: [ 1 91 39  4], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize, Index: 20, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/Sign, Index: 21, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize1, Index: 22, Shape: [ 1 91 39  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/add, Index: 23, Shape: [ 1 91 39  4], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize1, Index: 24, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/ste_sign_9/Sign_1, Index: 25, Shape: [ 1 91 39  4], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize2, Index: 26, Shape: [ 1 91 39  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D2, Index: 27, Shape: [ 1 89 37  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/max_pooling2d_3/MaxPool, Index: 28, Shape: [ 1 44 18  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV32, Index: 29, Shape: [ 1 44 18  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV33, Index: 30, Shape: [ 1 44 18  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/flatten_1/Reshape, Index: 31, Shape: [   1 6336], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/flatten_1/Reshape1, Index: 32, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/Sign, Index: 33, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize3, Index: 34, Shape: [   1 6336], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/add, Index: 35, Shape: [   1 6336], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize2, Index: 36, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_11/Sign_1, Index: 37, Shape: [   1 6336], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize4, Index: 38, Shape: [   1 6336], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_2/MatMul;sequential_1/batch_normalization_6/batchnorm/mul;sequential_1/batch_normalization_6/batchnorm/add_1, Index: 39, Shape: [ 1 16], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize3, Index: 40, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/Sign, Index: 41, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize5, Index: 42, Shape: [ 1 16], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/add, Index: 43, Shape: [ 1 16], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize4, Index: 44, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_13/Sign_1, Index: 45, Shape: [ 1 16], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize6, Index: 46, Shape: [ 1 16], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_3/MatMul;sequential_1/batch_normalization_7/batchnorm/mul;sequential_1/batch_normalization_7/batchnorm/add_1, Index: 47, Shape: [1 2], dtype: <class 'numpy.int8'>\n",
      "Name: StatefulPartitionedCall:01, Index: 48, Shape: [1 2], dtype: <class 'numpy.int8'>\n",
      "Name: StatefulPartitionedCall:0, Index: 49, Shape: [1 2], dtype: <class 'numpy.uint8'>\n",
      "Name: , Index: 62, Shape: [  1 182  78   9], dtype: <class 'numpy.int8'>\n",
      "Name: , Index: 63, Shape: [ 1 89 37 36], dtype: <class 'numpy.int8'>\n",
      "Tensor serving_default_quant_conv2d_2_input:0 - Shape: (1, 184, 80, 1), Data: [[[[ 97]\n",
      "   [116]\n",
      "   [105]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[128]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [110]\n",
      "   [101]\n",
      "   [108]]\n",
      "\n",
      "  [[ 95]\n",
      "   [108]\n",
      "   [ 97]\n",
      "   ...\n",
      "   [ 45]\n",
      "   [112]\n",
      "   [ 97]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [115]\n",
      "   [114]\n",
      "   [ 99]]\n",
      "\n",
      "  [[ 47]\n",
      "   [115]\n",
      "   [ 97]\n",
      "   ...\n",
      "   [127]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [115]\n",
      "   [114]\n",
      "   [ 99]]]]\n",
      "Tensor sequential_1/flatten_1/Const - Shape: (2,), Data: [  -1 6336]\n",
      "Tensor sequential_1/batch_normalization_7/batchnorm/sub - Shape: (2,), Data: [ 13304 -16607]\n",
      "Tensor sequential_1/batch_normalization_7/batchnorm/mul - Shape: (2, 16), Data: [[ 112  112 -112  112 -112 -112 -112  112 -112  112  112  112 -112  112\n",
      "  -112  112]\n",
      " [ 127  127  127  127  127 -127 -127 -127  127  127 -127 -127 -127  127\n",
      "   127  127]]\n",
      "Tensor sequential_1/batch_normalization_6/batchnorm/sub - Shape: (16,), Data: [  254006   793142    18913  -668792 -1644839  1011833    23164  1677494\n",
      "  -696010   849038   809037  1872685  -971580   777968  -766736   381734]\n",
      "Tensor sequential_1/batch_normalization_6/batchnorm/mul - Shape: (16, 6336), Data: [[  64   64  -64 ...   64  -64  -64]\n",
      " [  66   66   66 ...   66  -66   66]\n",
      " [ 107  107 -107 ... -107 -107 -107]\n",
      " ...\n",
      " [ -68   68  -68 ...   68  -68   68]\n",
      " [  62   62  -62 ...   62   62  -62]\n",
      " [  51   51  -51 ...  -51  -51  -51]]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV31 - Shape: (8,), Data: [ -56  -16 -128  107   62   18  127  -58]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV3 - Shape: (8,), Data: [101 127 125 -42   2  74 -29  99]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D - Shape: (8,), Data: [0 0 0 0 0 0 0 0]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D1 - Shape: (8, 3, 3, 4), Data: [[[[-127  127  127  127]\n",
      "   [-127  127 -127 -127]\n",
      "   [ 127  127 -127  127]]\n",
      "\n",
      "  [[ 127 -127  127 -127]\n",
      "   [-127 -127 -127  127]\n",
      "   [-127 -127 -127  127]]\n",
      "\n",
      "  [[-127  127 -127 -127]\n",
      "   [-127 -127 -127  127]\n",
      "   [-127  127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127  127 -127  127]\n",
      "   [ 127 -127  127 -127]\n",
      "   [-127  127 -127 -127]]\n",
      "\n",
      "  [[-127 -127  127 -127]\n",
      "   [-127  127 -127 -127]\n",
      "   [-127 -127 -127 -127]]\n",
      "\n",
      "  [[ 127  127 -127  127]\n",
      "   [ 127  127  127 -127]\n",
      "   [ 127 -127 -127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127 -127 -127]\n",
      "   [-127 -127  127  127]\n",
      "   [-127 -127 -127 -127]]\n",
      "\n",
      "  [[ 127  127 -127  127]\n",
      "   [-127  127  127  127]\n",
      "   [ 127  127 -127  127]]\n",
      "\n",
      "  [[ 127  127  127 -127]\n",
      "   [ 127 -127  127 -127]\n",
      "   [-127  127  127  127]]]\n",
      "\n",
      "\n",
      " [[[ 127 -127 -127  127]\n",
      "   [ 127 -127 -127 -127]\n",
      "   [-127  127  127 -127]]\n",
      "\n",
      "  [[ 127 -127  127 -127]\n",
      "   [-127  127  127  127]\n",
      "   [-127 -127  127 -127]]\n",
      "\n",
      "  [[-127  127  127  127]\n",
      "   [ 127 -127  127 -127]\n",
      "   [-127 -127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127 -127  127]\n",
      "   [ 127  127 -127 -127]\n",
      "   [ 127 -127 -127  127]]\n",
      "\n",
      "  [[-127  127 -127 -127]\n",
      "   [-127 -127 -127 -127]\n",
      "   [ 127  127 -127  127]]\n",
      "\n",
      "  [[-127 -127  127  127]\n",
      "   [ 127 -127 -127 -127]\n",
      "   [ 127 -127 -127  127]]]\n",
      "\n",
      "\n",
      " [[[ 127  127  127 -127]\n",
      "   [-127  127  127 -127]\n",
      "   [ 127  127  127  127]]\n",
      "\n",
      "  [[-127 -127 -127 -127]\n",
      "   [ 127 -127  127 -127]\n",
      "   [ 127 -127 -127  127]]\n",
      "\n",
      "  [[-127  127 -127 -127]\n",
      "   [ 127  127 -127 -127]\n",
      "   [ 127 -127  127  127]]]\n",
      "\n",
      "\n",
      " [[[ 127 -127  127 -127]\n",
      "   [-127 -127 -127  127]\n",
      "   [ 127 -127 -127 -127]]\n",
      "\n",
      "  [[-127 -127  127  127]\n",
      "   [ 127 -127 -127  127]\n",
      "   [ 127  127 -127  127]]\n",
      "\n",
      "  [[ 127 -127  127  127]\n",
      "   [ 127 -127  127 -127]\n",
      "   [ 127  127  127  127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127 -127 -127]\n",
      "   [-127 -127 -127  127]\n",
      "   [-127  127 -127  127]]\n",
      "\n",
      "  [[ 127 -127  127 -127]\n",
      "   [-127 -127 -127  127]\n",
      "   [ 127 -127  127 -127]]\n",
      "\n",
      "  [[ 127 -127 -127  127]\n",
      "   [ 127  127  127 -127]\n",
      "   [-127  127  127  127]]]]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D/ste_sign_7/add/y - Shape: (), Data: 127\n",
      "Tensor sequential_1/batch_normalization_4/FusedBatchNormV31 - Shape: (4,), Data: [-128  -61  127  -74]\n",
      "Tensor sequential_1/batch_normalization_4/FusedBatchNormV3 - Shape: (4,), Data: [127 103 -54 -73]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D - Shape: (4,), Data: [0 0 0 0]\n",
      "Tensor sequential_1/quant_conv2d_2/QuantConv2D1 - Shape: (4, 3, 3, 1), Data: [[[[ 127]\n",
      "   [-127]\n",
      "   [-127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]\n",
      "   [-127]]\n",
      "\n",
      "  [[ 127]\n",
      "   [ 127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [-127]\n",
      "   [-127]]\n",
      "\n",
      "  [[ 127]\n",
      "   [ 127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [ 127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[ 127]\n",
      "   [-127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [-127]\n",
      "   [-127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]\n",
      "   [-127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]\n",
      "   [-127]]]]\n",
      "Tensor tfl.quantize - Shape: (1, 184, 80, 1), Data: [[[[110]\n",
      "   [ 97]\n",
      "   [109]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[ 80]\n",
      "   [-45]\n",
      "   [ 16]\n",
      "   ...\n",
      "   [118]\n",
      "   [101]\n",
      "   [115]]\n",
      "\n",
      "  [[104]\n",
      "   [101]\n",
      "   [108]\n",
      "   ...\n",
      "   [110]\n",
      "   [101]\n",
      "   [119]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 48]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [115]\n",
      "   [114]\n",
      "   [ 99]]\n",
      "\n",
      "  [[ 47]\n",
      "   [115]\n",
      "   [ 97]\n",
      "   ...\n",
      "   [127]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [ 45]\n",
      "   [112]\n",
      "   [ 97]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detail \u001b[38;5;129;01min\u001b[39;00m tensor_details:\n\u001b[0;32m---> 12\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetail[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:926\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index):\n\u001b[1;32m    879\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "# interpreter = tf.lite.Interpreter(model_content=dynamic_range_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get tensor details\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "for detail in tensor_details:\n",
    "    print(f\"Name: {detail['name']}, Index: {detail['index']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "\n",
    "# Extract weights\n",
    "for detail in tensor_details:\n",
    "    tensor = interpreter.tensor(detail['index'])()\n",
    "    print(f\"Tensor {detail['name']} - Shape: {tensor.shape}, Data: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111696"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import time\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"spectrogram_models_from_notebooks/bnn\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"bnn_mel_spec_16kHz_full_int_q.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset:\n",
      "Accuracy: 80.51%\n",
      "Recall: 95.55%\n",
      "Precision: 64.52%\n",
      "F1-score: 77.03%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.76903113936507\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7633565261827667\n",
      "\n",
      "Test dataset:\n",
      "Accuracy: 80.69%\n",
      "Recall: 95.85%\n",
      "Precision: 63.72%\n",
      "F1-score: 76.55%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7643452994165095\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7715132049712021\n",
      "\n",
      "Time for Test dataset:\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.002 seconds\n",
      "Max: 0.005 seconds\n",
      "Min: 0.001 seconds\n",
      "File size: 109.078 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset:\")\n",
    "predictions = full_int_model_predict(tflite_model_quant_file, x_val_np)\n",
    "evaluate_prediction(y_val_np, predictions)\n",
    "\n",
    "print(\"\\nDevide dataset into 10 non-overlapping patritions and get their mean F1-score\")\n",
    "non_overlap_patritions_f1_scores = get_f1_scores_of_non_overlapping_partitions_full_int_q(tflite_model_quant_file, x_val_np, y_val_np)\n",
    "print(\"Non-overlap mean F1-score: \", np.mean(non_overlap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nGet 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\")\n",
    "bootstrap_patritions_f1_scores = get_f1_scores_of_bootstarping_partitions_full_int_q(tflite_model_quant_file, x_val_np, y_val_np)\n",
    "print(\"Bootstrap mean F1-score: \", np.mean(bootstrap_patritions_f1_scores))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "predictions = full_int_model_predict(tflite_model_quant_file, x_test_np)\n",
    "evaluate_prediction(y_test_np, predictions)\n",
    "\n",
    "print(\"\\nDevide dataset into 10 non-overlapping patritions and get their mean F1-score\")\n",
    "non_overlap_patritions_f1_scores = get_f1_scores_of_non_overlapping_partitions_full_int_q(tflite_model_quant_file, x_test_np, y_test_np)\n",
    "print(\"Non-overlap mean F1-score: \", np.mean(non_overlap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nGet 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\")\n",
    "bootstrap_patritions_f1_scores = get_f1_scores_of_bootstarping_partitions_full_int_q(tflite_model_quant_file, x_test_np, y_test_np)\n",
    "print(\"Bootstrap mean F1-score: \", np.mean(bootstrap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "time_data = []\n",
    "for data_point in x_test_np:\n",
    "    start_time = time.time()\n",
    "    predictions = full_int_model_predict(tflite_model_quant_file, [data_point])\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_data.append(elapsed_time)\n",
    "print(\"\\nTime to make a prediction for a single data point\")\n",
    "print(f\"Mean: {round(np.mean(time_data), 3)} seconds\")\n",
    "print(f\"Max: {round(np.max(time_data), 3)} seconds\")\n",
    "print(f\"Min: {round(np.min(time_data), 3)} seconds\")\n",
    "\n",
    "convert_bytes(get_file_size(tflite_model_quant_file), \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
