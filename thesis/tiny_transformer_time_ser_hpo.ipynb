{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 17:38:01.240113: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-28 17:38:01.560935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-28 17:38:01.560991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-28 17:38:01.616217: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-28 17:38:01.730447: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-28 17:38:01.732306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-28 17:38:03.223947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband, BayesianOptimization\n",
    "\n",
    "import random\n",
    "tf.random.set_seed(3407)\n",
    "np.random.seed(3407)\n",
    "random.seed(3407)\n",
    "\n",
    "from helper_functions import (\n",
    "    get_file_size, \n",
    "    convert_bytes, \n",
    "    convert_prefetchdataset_to_numpy_arrays,\n",
    "    predict_and_print_full_results,\n",
    "    evaluate_time_of_prediction\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11292 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 17:39:04.745030: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-07-28 17:39:04.816988: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1393 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Found 1380 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Classes:  ['non_target' 'target']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.audio_dataset_from_directory(\"../dataset/training\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "test_dataset = tf.keras.utils.audio_dataset_from_directory(\"../dataset/testing\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "val_dataset = tf.keras.utils.audio_dataset_from_directory(\"../dataset/validation\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "\n",
    "label_names = np.array(train_dataset.class_names)\n",
    "print(\"Classes: \", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np, y_train_np = convert_prefetchdataset_to_numpy_arrays(train_dataset, data_type=\"time-series\")\n",
    "x_val_np, y_val_np = convert_prefetchdataset_to_numpy_arrays(val_dataset, data_type=\"time-series\")\n",
    "x_test_np, y_test_np = convert_prefetchdataset_to_numpy_arrays(test_dataset, data_type=\"time-series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes, num_blocks):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "    def transformer_encoder(self, inputs, head_size, num_heads, filters_conv, kernel_size, dropout=0):\n",
    "        # Normalization and Attention\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "        x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        res = x + inputs\n",
    "\n",
    "        # Feed Forward Part\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "        x = layers.Conv1D(filters=filters_conv, kernel_size=kernel_size, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "        return x + res\n",
    "\n",
    "    def build(self, hp, dropout=0):\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Parameters\n",
    "        filters_conv = hp.Int('filters', min_value=2, max_value=12, step=2)\n",
    "        # kernel_size = hp.Choice('kernel_size', values=[1, 3])\n",
    "        pool_size = hp.Int('pool_size', min_value=6, max_value=10, step=2)\n",
    "        num_heads = hp.Choice('num_heads', values=[1, 2, 3])\n",
    "        learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "        x = layers.Conv1D(filters=filters_conv, kernel_size=1, activation=\"relu\")(inputs)\n",
    "        x = layers.MaxPooling1D(pool_size=pool_size)(x)\n",
    "        x = layers.AveragePooling1D(pool_size=pool_size)(x)\n",
    "        for i in range(self.num_blocks):\n",
    "            head_size = hp.Int(f'head_size_{i}', min_value=4, max_value=16, step=4)\n",
    "            x = self.transformer_encoder(x, head_size, num_heads, filters_conv, 1, dropout)\n",
    "\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        outputs = layers.Dense(self.num_classes, activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 14s]\n",
      "val_accuracy: 0.8057971000671387\n",
      "\n",
      "Best val_accuracy So Far: 0.8405796885490417\n",
      "Total elapsed time: 00h 59m 03s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/tiny_transformer/tiny_transformer_time_series_1_block_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "pool_size: 6\n",
      "num_heads: 2\n",
      "learning_rate: 0.000767170096923145\n",
      "head_size_0: 12\n",
      "Score: 0.8405796885490417\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "filters: 6\n",
      "pool_size: 8\n",
      "num_heads: 1\n",
      "learning_rate: 0.000130573118342512\n",
      "head_size_0: 4\n",
      "Score: 0.8057971000671387\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "filters: 6\n",
      "pool_size: 10\n",
      "num_heads: 1\n",
      "learning_rate: 0.0026489221357360827\n",
      "head_size_0: 12\n",
      "Score: 0.7876811623573303\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "filters: 4\n",
      "pool_size: 6\n",
      "num_heads: 2\n",
      "learning_rate: 0.004179706358511756\n",
      "head_size_0: 16\n",
      "Score: 0.7623188495635986\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "filters: 2\n",
      "pool_size: 10\n",
      "num_heads: 2\n",
      "learning_rate: 0.0002581812504566695\n",
      "head_size_0: 12\n",
      "Score: 0.6579710245132446\n"
     ]
    }
   ],
   "source": [
    "input_shape = (48000,1)\n",
    "num_classes = 2\n",
    "num_blocks = 1\n",
    "\n",
    "num_of_conv_layers = 1\n",
    "tuner_1_block_transformer = RandomSearch(\n",
    "    TransformerHyperModel(input_shape, num_classes, num_blocks),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='../hpo_tuner/tiny_transformer',\n",
    "    project_name='tiny_transformer_time_series_1_block_tuning'\n",
    ")\n",
    "tuner_1_block_transformer.search(train_dataset, epochs=3, validation_data=val_dataset)\n",
    "tuner_1_block_transformer.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 10m 07s]\n",
      "val_accuracy: 0.8210144639015198\n",
      "\n",
      "Best val_accuracy So Far: 0.843478262424469\n",
      "Total elapsed time: 01h 02m 03s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/tiny_transformer/tiny_transformer_time_series_2_block_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "pool_size: 8\n",
      "num_heads: 2\n",
      "learning_rate: 0.0012440718000666692\n",
      "head_size_0: 8\n",
      "head_size_1: 8\n",
      "Score: 0.843478262424469\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "filters: 4\n",
      "pool_size: 10\n",
      "num_heads: 3\n",
      "learning_rate: 0.00019658478253735642\n",
      "head_size_0: 16\n",
      "head_size_1: 8\n",
      "Score: 0.8210144639015198\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "pool_size: 10\n",
      "num_heads: 1\n",
      "learning_rate: 0.001413751920126406\n",
      "head_size_0: 4\n",
      "head_size_1: 16\n",
      "Score: 0.7978261113166809\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "filters: 10\n",
      "pool_size: 8\n",
      "num_heads: 3\n",
      "learning_rate: 0.002291233691844905\n",
      "head_size_0: 16\n",
      "head_size_1: 8\n",
      "Score: 0.75\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "filters: 2\n",
      "pool_size: 10\n",
      "num_heads: 1\n",
      "learning_rate: 0.001810157689657075\n",
      "head_size_0: 12\n",
      "head_size_1: 4\n",
      "Score: 0.6579710245132446\n"
     ]
    }
   ],
   "source": [
    "input_shape = (48000,1)\n",
    "num_classes = 2\n",
    "num_blocks = 2\n",
    "\n",
    "num_of_conv_layers = 1\n",
    "tuner_2_block_transformer = RandomSearch(\n",
    "    TransformerHyperModel(input_shape, num_classes, num_blocks),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='../hpo_tuner/tiny_transformer',\n",
    "    project_name='tiny_transformer_time_series_2_block_tuning'\n",
    ")\n",
    "tuner_2_block_transformer.search(train_dataset, epochs=3, validation_data=val_dataset)\n",
    "tuner_2_block_transformer.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_2_block_transformer.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")\n",
    "\n",
    "\n",
    "# filters: 12\n",
    "# pool_size: 8\n",
    "# num_heads: 2\n",
    "# learning_rate: 0.0012440718000666692\n",
    "# head_size_0: 8\n",
    "# head_size_1: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 48000, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 48000, 12)            24        ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 6000, 12)             0         ['conv1d_3[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " average_pooling1d_1 (Avera  (None, 750, 12)              0         ['max_pooling1d_1[0][0]']     \n",
      " gePooling1D)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 750, 12)              24        ['average_pooling1d_1[0][0]'] \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 750, 12)              828       ['layer_normalization_2[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 750, 12)              0         ['multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 750, 12)              0         ['dropout_3[0][0]',           \n",
      " OpLambda)                                                           'average_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 750, 12)              24        ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 750, 12)              156       ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 750, 12)              0         ['conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 750, 12)              156       ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 750, 12)              0         ['conv1d_5[0][0]',            \n",
      " OpLambda)                                                           'tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 12)                   0         ['tf.__operators__.add_3[0][0]\n",
      "  (GlobalAveragePooling1D)                                          ']                            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 12)                   0         ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2)                    26        ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1238 (4.84 KB)\n",
      "Trainable params: 1238 (4.84 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 202s 566ms/step - loss: 0.4602 - accuracy: 0.7380\n",
      "Epoch 2/10\n",
      "353/353 [==============================] - 194s 547ms/step - loss: 0.4149 - accuracy: 0.7722\n",
      "Epoch 3/10\n",
      "353/353 [==============================] - 191s 540ms/step - loss: 0.3975 - accuracy: 0.7828\n",
      "Epoch 4/10\n",
      "353/353 [==============================] - 190s 538ms/step - loss: 0.3853 - accuracy: 0.7885\n",
      "Epoch 5/10\n",
      "353/353 [==============================] - 190s 537ms/step - loss: 0.3772 - accuracy: 0.7901\n",
      "Epoch 6/10\n",
      "353/353 [==============================] - 192s 541ms/step - loss: 0.3748 - accuracy: 0.7934\n",
      "Epoch 7/10\n",
      "353/353 [==============================] - 191s 539ms/step - loss: 0.3698 - accuracy: 0.7914\n",
      "Epoch 8/10\n",
      "353/353 [==============================] - 191s 539ms/step - loss: 0.3660 - accuracy: 0.7980\n",
      "Epoch 9/10\n",
      "353/353 [==============================] - 190s 537ms/step - loss: 0.3634 - accuracy: 0.7992\n",
      "Epoch 10/10\n",
      "353/353 [==============================] - 194s 548ms/step - loss: 0.3648 - accuracy: 0.7982\n"
     ]
    }
   ],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, filters, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=filters, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(input_shape, head_size, num_heads, filters, num_blocks, num_classes, dropout=0):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv1D(filters=filters, kernel_size=1, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=8)(x)\n",
    "    x = layers.AveragePooling1D(pool_size=8)(x)\n",
    "    for i in range(num_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, filters, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "# Parameters\n",
    "input_shape = (48000,1)\n",
    "num_classes = 2\n",
    "num_blocks = 1\n",
    "\n",
    "head_size = 8 # 16\n",
    "num_heads = 2\n",
    "filters = 12\n",
    "dropout = 0.1\n",
    "\n",
    "# Build the model\n",
    "model_2_10_epochs = build_model(input_shape, head_size, num_heads, filters, num_blocks, num_classes, dropout)\n",
    "model_2_10_epochs.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                          metrics=[\"accuracy\"])\n",
    "\n",
    "# Model summary\n",
    "model_2_10_epochs.summary()\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 10\n",
    "history = model_2_10_epochs.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 11s 247ms/step - loss: 0.3446 - accuracy: 0.8065\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 11s 245ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 80.65%\n",
      "Recall: 57.84%\n",
      "Precision: 80.06%\n",
      "F1-score: 67.16%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m model_2_10_epochs\u001b[38;5;241m.\u001b[39mevaluate(x_val_np, y_val_np)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m (\n\u001b[1;32m      6\u001b[0m     y_pred_val, \n\u001b[1;32m      7\u001b[0m     non_overlap_patritions_f1_scores_val, \n\u001b[1;32m      8\u001b[0m     bootstrap_patritions_f1_scores_val,\n\u001b[0;32m----> 9\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_and_print_full_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_2_10_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/newname/thesis/helper_functions.py:156\u001b[0m, in \u001b[0;36mpredict_and_print_full_results\u001b[0;34m(model, x_data, y_true, model_format, input_data_uint8_type)\u001b[0m\n\u001b[1;32m    153\u001b[0m evaluate_prediction(y_true, y_pred)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDevide dataset into 10 non-overlapping patritions and get their mean F1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m non_overlap_patritions_f1_scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_f1_scores_of_non_overlapping_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_uint8_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-overlap mean F1-score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(non_overlap_patritions_f1_scores))\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGet 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/thesis/helper_functions.py:114\u001b[0m, in \u001b[0;36mget_f1_scores_of_non_overlapping_partitions\u001b[0;34m(model, x_data, y_true, model_format, input_data_uint8_type, n_partitions)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m partitions:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m         y_pred_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(y_pred_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m model_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_lite\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/keras/src/engine/training.py:2655\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2654\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2655\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2657\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_2_10_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_2_10_epochs, x_val_np, y_val_np, model_format=\"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE_NAME = \"../time_series_models_from_notebooks/tiny_transformer/hpo/tiny_transformer_time_ser_2_block.keras\"\n",
    "model.save(MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)       [(None, 48000, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)          (None, 47996, 32)            192       ['input_31[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_30 (MaxPooli  (None, 2999, 32)             0         ['conv1d_88[0][0]']           \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)       (None, 2999, 32)             0         ['max_pooling1d_30[0][0]']    \n",
      "                                                                                                  \n",
      " average_pooling1d_29 (Aver  (None, 374, 32)              0         ['dropout_116[0][0]']         \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_58 (La  (None, 374, 32)              64        ['average_pooling1d_29[0][0]']\n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_29 (M  (None, 374, 32)              4224      ['layer_normalization_58[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_58[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)       (None, 374, 32)              0         ['multi_head_attention_29[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (T  (None, 374, 32)              0         ['dropout_117[0][0]',         \n",
      " FOpLambda)                                                          'average_pooling1d_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_59 (La  (None, 374, 32)              64        ['tf.__operators__.add_58[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)          (None, 374, 32)              1056      ['layer_normalization_59[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_118 (Dropout)       (None, 374, 32)              0         ['conv1d_89[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)          (None, 374, 32)              1056      ['dropout_118[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (T  (None, 374, 32)              0         ['conv1d_90[0][0]',           \n",
      " FOpLambda)                                                          'tf.__operators__.add_58[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 32)                   0         ['tf.__operators__.add_59[0][0\n",
      " 9 (GlobalAveragePooling1D)                                         ]']                           \n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)       (None, 32)                   0         ['global_average_pooling1d_29[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 2)                    66        ['dropout_119[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6722 (26.26 KB)\n",
      "Trainable params: 6722 (26.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(rate=0.25)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_blocks, num_classes, dropout=0):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=5, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=16)(x)\n",
    "    x = layers.Dropout(rate=0.25)(x)\n",
    "    x = layers.AveragePooling1D(pool_size=8)(x)\n",
    "    for _ in range(num_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Parameters\n",
    "input_shape = (48000,1)\n",
    "head_size = 32 \n",
    "num_heads = 1 # 2\n",
    "ff_dim = 32 # 32\n",
    "num_blocks = 1\n",
    "num_classes = 2\n",
    "dropout = 0.1\n",
    "\n",
    "# Build the model\n",
    "model_lr = build_model(input_shape, head_size, num_heads, ff_dim, num_blocks, num_classes, dropout)\n",
    "model_lr.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), metrics=[\"accuracy\"])\n",
    "\n",
    "# Model summary\n",
    "model_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 115s 318ms/step - loss: 0.3661 - accuracy: 0.8467 - val_loss: 0.2215 - val_accuracy: 0.9268\n",
      "Epoch 2/10\n",
      "353/353 [==============================] - 115s 323ms/step - loss: 0.2254 - accuracy: 0.9175 - val_loss: 0.1630 - val_accuracy: 0.9449\n",
      "Epoch 3/10\n",
      "353/353 [==============================] - 117s 329ms/step - loss: 0.1908 - accuracy: 0.9276 - val_loss: 0.1380 - val_accuracy: 0.9522\n",
      "Epoch 4/10\n",
      "353/353 [==============================] - 116s 327ms/step - loss: 0.1741 - accuracy: 0.9335 - val_loss: 0.1301 - val_accuracy: 0.9580\n",
      "Epoch 5/10\n",
      "353/353 [==============================] - 116s 326ms/step - loss: 0.1650 - accuracy: 0.9380 - val_loss: 0.1251 - val_accuracy: 0.9609\n",
      "Epoch 6/10\n",
      "353/353 [==============================] - 120s 337ms/step - loss: 0.1573 - accuracy: 0.9414 - val_loss: 0.1198 - val_accuracy: 0.9623\n",
      "Epoch 7/10\n",
      "353/353 [==============================] - 115s 325ms/step - loss: 0.1512 - accuracy: 0.9426 - val_loss: 0.1103 - val_accuracy: 0.9638\n",
      "Epoch 8/10\n",
      "353/353 [==============================] - 116s 325ms/step - loss: 0.1456 - accuracy: 0.9465 - val_loss: 0.1117 - val_accuracy: 0.9623\n",
      "Epoch 9/10\n",
      "353/353 [==============================] - 117s 330ms/step - loss: 0.1418 - accuracy: 0.9475 - val_loss: 0.1084 - val_accuracy: 0.9623\n",
      "Epoch 10/10\n",
      "353/353 [==============================] - 115s 324ms/step - loss: 0.1381 - accuracy: 0.9496 - val_loss: 0.1031 - val_accuracy: 0.9652\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 0.1031 - accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model_lr.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset)\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_lr.evaluate(x_val_np, y_val_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset:\n",
      "44/44 [==============================] - 4s 94ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 96.52%\n",
      "Recall: 95.34%\n",
      "Precision: 94.54%\n",
      "F1-score: 94.94%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9492733997046917\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9490214543072182\n",
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 4s 101ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 96.27%\n",
      "Recall: 94.98%\n",
      "Precision: 93.75%\n",
      "F1-score: 94.36%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.942986273519618\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9462869341505324\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 96.27%\n",
      "Recall: 94.98%\n",
      "Precision: 93.75%\n",
      "F1-score: 94.36%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.061 seconds\n",
      "Max: 0.6 seconds\n",
      "Min: 0.054 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_lr, x_val_np, y_val_np, model_format=\"keras\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_lr, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_lr, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../time_series_models_from_notebooks/tiny_transformer/hpo/tiny_transformer_time_ser_final.keras\n",
      "File size: 162.422 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILE_NAME = \"../time_series_models_from_notebooks/tiny_transformer/hpo/tiny_transformer_time_ser_final.keras\"\n",
    "# model_lr.save(MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 17:38:15.865066: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-28 17:38:15.865638: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model_loaded = tf.keras.models.load_model(MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 4s 90ms/step - loss: 0.1031 - accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model_loaded.evaluate(x_val_np, y_val_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested filters = 8, 16, 32\n",
    "\n",
    "num_blocks = 1, 2\n",
    "\n",
    "num_heads = 1, 2\n",
    "\n",
    "head_size = 8,16, 32\n",
    "\n",
    "Current implementation is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
