{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 23:01:14.544638: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 23:01:14.637865: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 23:01:14.637941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 23:01:14.648092: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 23:01:14.671405: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 23:01:14.672874: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 23:01:15.773386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import larq as lq\n",
    "import larq_compute_engine as lce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "import random\n",
    "tf.random.set_seed(3407)\n",
    "np.random.seed(3407)\n",
    "random.seed(3407)\n",
    "\n",
    "from helper_functions import (\n",
    "    evaluate_prediction,\n",
    "    get_file_size, \n",
    "    convert_bytes, \n",
    "    convert_prefetchdataset_to_numpy_arrays,\n",
    "    predict_and_print_full_results,\n",
    "    evaluate_time_of_prediction,\n",
    "    full_int_model_predict,\n",
    "    get_f1_scores_of_non_overlapping_partitions_full_int_q,\n",
    "    get_f1_scores_of_bootstarping_partitions_full_int_q,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11292 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 23:01:40.000208: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-26 23:01:40.000761: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 23:01:40.140966: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-07-26 23:01:40.215220: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1393 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Found 1380 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Classes:  ['non_target' 'target']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.audio_dataset_from_directory(\"../dataset/training\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "test_dataset = tf.keras.utils.audio_dataset_from_directory(\"../dataset/testing\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "val_dataset = tf.keras.utils.audio_dataset_from_directory(\"../dataset/validation\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "\n",
    "label_names = np.array(train_dataset.class_names)\n",
    "print(\"Classes: \", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np, y_train_np = convert_prefetchdataset_to_numpy_arrays(train_dataset, data_type=\"time-series\")\n",
    "x_val_np, y_val_np = convert_prefetchdataset_to_numpy_arrays(val_dataset, data_type=\"time-series\")\n",
    "x_test_np, y_test_np = convert_prefetchdataset_to_numpy_arrays(test_dataset, data_type=\"time-series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes, num_of_layers):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_of_conv_layers = num_of_layers\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        dense_units = hp.Int('1st_dense_units', min_value=4, max_value=32, step=4)\n",
    "        dense_activation = hp.Choice('2nd_dense_activation', values=['softmax', 'sigmoid'])\n",
    "        learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "        # Model architecture\n",
    "        # Tune number of layers\n",
    "        for i in range(self.num_of_conv_layers):\n",
    "            if i == 0:\n",
    "                model.add(lq.layers.QuantConv1D(\n",
    "                    filters=hp.Int(f'filters_{i}', min_value=2, max_value=8, step=2), \n",
    "                    kernel_size=hp.Choice(f'kernel_size_{i}', values=[2, 3, 5]),\n",
    "                    input_shape=self.input_shape,\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "            else:\n",
    "                model.add(lq.layers.QuantConv1D(\n",
    "                    filters=hp.Int(f'filters_{i}', min_value=2, max_value=8, step=2), \n",
    "                    kernel_size=hp.Choice(f'kernel_size_{i}', values=[2, 3, 5]),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "            model.add(tf.keras.layers.MaxPooling1D(pool_size=hp.Int(f'pull_size_{i}', min_value=4, max_value=10, step=2)))\n",
    "            model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        model.add(lq.layers.QuantDense(\n",
    "            units=dense_units,\n",
    "            kernel_quantizer=\"ste_sign\",\n",
    "            input_quantizer=\"ste_sign\",\n",
    "            kernel_constraint=\"weight_clip\",\n",
    "            use_bias=False\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "        model.add(lq.layers.QuantDense(\n",
    "            units=self.num_classes,\n",
    "            kernel_quantizer=\"ste_sign\",\n",
    "            input_quantizer=\"ste_sign\",\n",
    "            kernel_constraint=\"weight_clip\",\n",
    "            use_bias=False\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "        model.add(tf.keras.layers.Activation(dense_activation))\n",
    "       \n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune 1 conv2d layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 01m 13s]\n",
      "val_accuracy: 0.6739130616188049\n",
      "\n",
      "Best val_accuracy So Far: 0.6739130616188049\n",
      "Total elapsed time: 00h 01m 13s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/bnn/bnn_time_series_1_conv2d_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 24\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.005739801798904129\n",
      "filters_0: 4\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 8\n",
      "Score: 0.6739130616188049\n"
     ]
    }
   ],
   "source": [
    "input_shape = (48000,1)\n",
    "num_classes = 2\n",
    "\n",
    "num_of_conv_layers = 1\n",
    "tuner_1_layer_cnn = RandomSearch(\n",
    "    CNNHyperModel(input_shape, num_classes, num_of_conv_layers),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    directory='../hpo_tuner/bnn',\n",
    "    project_name='bnn_time_series_1_conv2d_tuning'\n",
    ")\n",
    "tuner_1_layer_cnn.search(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "tuner_1_layer_cnn.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune 2 conv2d layers CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 02m 25s]\n",
      "val_accuracy: 0.8949275612831116\n",
      "\n",
      "Best val_accuracy So Far: 0.9398550689220428\n",
      "Total elapsed time: 00h 53m 06s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/bnn/bnn_2_conv2d_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.0063881645876014866\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 4\n",
      "filters_1: 4\n",
      "Score: 0.9398550689220428\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 8\n",
      "learning_rate: 0.007515970819203388\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 8\n",
      "filters_1: 4\n",
      "Score: 0.9376811683177948\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 32\n",
      "learning_rate: 0.0037652861684021495\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 2\n",
      "filters_1: 8\n",
      "Score: 0.9329710006713867\n",
      "\n",
      "Trial 12 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.0013810908036985007\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 2\n",
      "filters_1: 2\n",
      "Score: 0.9322463870048523\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 24\n",
      "learning_rate: 0.00041615784427578373\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 8\n",
      "filters_1: 8\n",
      "Score: 0.9300724565982819\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 16\n",
      "learning_rate: 0.000331710264204527\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 8\n",
      "filters_1: 4\n",
      "Score: 0.9264492690563202\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 4\n",
      "learning_rate: 0.009335569435817186\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 4\n",
      "filters_1: 4\n",
      "Score: 0.9246376752853394\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 32\n",
      "learning_rate: 0.00022929216604337032\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 8\n",
      "filters_1: 4\n",
      "Score: 0.9202898442745209\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 3\n",
      "1st_dense_units: 24\n",
      "learning_rate: 0.00536658240702523\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 2\n",
      "filters_1: 4\n",
      "Score: 0.9130434691905975\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 32\n",
      "learning_rate: 0.0001522298574808984\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 2\n",
      "filters_1: 8\n",
      "Score: 0.9050724804401398\n"
     ]
    }
   ],
   "source": [
    "num_of_layers = 2\n",
    "tuner_2_layer_cnn = RandomSearch(\n",
    "    CNNHyperModel(input_shape, num_classes, num_of_layers),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='../hpo_tuner/bnn',\n",
    "    project_name='bnn_2_conv2d_tuning'\n",
    ")\n",
    "tuner_2_layer_cnn.search(train_spectrogram_ds, epochs=5, validation_data=val_spectrogram_ds)\n",
    "tuner_2_layer_cnn.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune 3 conv2d layers CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 02m 29s]\n",
      "val_accuracy: 0.9268116056919098\n",
      "\n",
      "Best val_accuracy So Far: 0.9485507309436798\n",
      "Total elapsed time: 00h 54m 30s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/bnn/bnn_3_conv2d_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 24\n",
      "learning_rate: 0.0019990629503147854\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 6\n",
      "filters_1: 4\n",
      "filters_2: 8\n",
      "Score: 0.9485507309436798\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 24\n",
      "learning_rate: 0.0030956184222862408\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 2\n",
      "filters_1: 6\n",
      "filters_2: 4\n",
      "Score: 0.9286231994628906\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 32\n",
      "learning_rate: 0.003499257561375248\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 8\n",
      "filters_1: 2\n",
      "filters_2: 4\n",
      "Score: 0.9286231696605682\n",
      "\n",
      "Trial 19 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.0007860854030984577\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 6\n",
      "filters_1: 8\n",
      "filters_2: 4\n",
      "Score: 0.9268116056919098\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.004122693745389103\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 2\n",
      "filters_1: 4\n",
      "filters_2: 8\n",
      "Score: 0.9217391312122345\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 3\n",
      "1st_dense_units: 24\n",
      "learning_rate: 0.00912470672476799\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 8\n",
      "filters_1: 8\n",
      "filters_2: 4\n",
      "Score: 0.9195652306079865\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 3\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.0031378187626006464\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 2\n",
      "filters_1: 4\n",
      "filters_2: 8\n",
      "Score: 0.9119565188884735\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.0007703289445934244\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 6\n",
      "filters_1: 6\n",
      "filters_2: 2\n",
      "Score: 0.8989130556583405\n",
      "\n",
      "Trial 16 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 3\n",
      "1st_dense_units: 12\n",
      "learning_rate: 0.001601348848498851\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 2\n",
      "filters_1: 2\n",
      "filters_2: 4\n",
      "Score: 0.8974637687206268\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "kernel_size: 3\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.0005572109949030198\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 2\n",
      "filters_1: 6\n",
      "filters_2: 4\n",
      "Score: 0.8873188197612762\n"
     ]
    }
   ],
   "source": [
    "num_of_layers = 3\n",
    "tuner_3_layer_cnn = RandomSearch(\n",
    "    CNNHyperModel(input_shape, num_classes, num_of_layers),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='../hpo_tuner/bnn',\n",
    "    project_name='bnn_3_conv2d_tuning'\n",
    ")\n",
    "tuner_3_layer_cnn.search(train_spectrogram_ds, epochs=5, validation_data=val_spectrogram_ds)\n",
    "tuner_3_layer_cnn.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "kernel_size (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "1st_dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': 'linear'}\n",
      "2nd_dense_activation (Choice)\n",
      "{'default': 'softmax', 'conditions': [], 'values': ['softmax', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "conv2d_activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner_1_layer_cnn.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "kernel_size (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "1st_dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': 'linear'}\n",
      "2nd_dense_activation (Choice)\n",
      "{'default': 'softmax', 'conditions': [], 'values': ['softmax', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "conv2d_activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner_2_layer_cnn.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "kernel_size (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "1st_dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': 'linear'}\n",
      "2nd_dense_activation (Choice)\n",
      "{'default': 'softmax', 'conditions': [], 'values': ['softmax', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "conv2d_activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "filters_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner_3_layer_cnn.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 28\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.0002630359449493652\n",
      "filters_0: 6\n",
      "conv2d_activation: relu\n",
      "filters_1: 6\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner_2_layer_cnn.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ... models, that showed good (or best) results in HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.001585943564699532\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 8\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner_1_layer_cnn.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quant_conv2d_3 (QuantConv2  (None, 180, 76, 8)        200       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 90, 38, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 90, 38, 8)         24        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 27360)             0         \n",
      "                                                                 \n",
      " quant_dense_6 (QuantDense)  (None, 28)                766080    \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 28)                84        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_7 (QuantDense)  (None, 2)                 56        \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 2)                 6         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 766450 (2.92 MB)\n",
      "Trainable params: 766374 (2.92 MB)\n",
      "Non-trainable params: 76 (304.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1_20_epochs = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model_1_20_epochs.add(lq.layers.QuantConv2D(filters=8, \n",
    "                                  kernel_size=(5, 5),\n",
    "                                  kernel_quantizer=\"ste_sign\",\n",
    "                                  kernel_constraint=\"weight_clip\",\n",
    "                                  use_bias=False,\n",
    "                                  input_shape=(184, 80, 1)))\n",
    "model_1_20_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_1_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_1_20_epochs.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_1_20_epochs.add(lq.layers.QuantDense(units=28, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_1_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_1_20_epochs.add(lq.layers.QuantDense(units=2, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_1_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_1_20_epochs.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "model_1_20_epochs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 15s 40ms/step - loss: 0.3995 - accuracy: 0.8344\n",
      "Epoch 2/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.2859 - accuracy: 0.8972\n",
      "Epoch 3/20\n",
      "353/353 [==============================] - 13s 38ms/step - loss: 0.2509 - accuracy: 0.9163\n",
      "Epoch 4/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.2139 - accuracy: 0.9384\n",
      "Epoch 5/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.1933 - accuracy: 0.9528\n",
      "Epoch 6/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.1943 - accuracy: 0.9532\n",
      "Epoch 7/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.1801 - accuracy: 0.9617\n",
      "Epoch 8/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.1801 - accuracy: 0.9632\n",
      "Epoch 9/20\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.1748 - accuracy: 0.9651\n",
      "Epoch 10/20\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.1681 - accuracy: 0.9677\n",
      "Epoch 11/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.1607 - accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.1614 - accuracy: 0.9770\n",
      "Epoch 13/20\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.1525 - accuracy: 0.9793\n",
      "Epoch 14/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.1516 - accuracy: 0.9806\n",
      "Epoch 15/20\n",
      "353/353 [==============================] - 15s 42ms/step - loss: 0.1571 - accuracy: 0.9779\n",
      "Epoch 16/20\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.1522 - accuracy: 0.9796\n",
      "Epoch 17/20\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.1510 - accuracy: 0.9826\n",
      "Epoch 18/20\n",
      "353/353 [==============================] - 16s 45ms/step - loss: 0.1442 - accuracy: 0.9868\n",
      "Epoch 19/20\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.1463 - accuracy: 0.9849\n",
      "Epoch 20/20\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.1442 - accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "model_1_20_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001585943564699532),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 20\n",
    "history = model_1_20_epochs.fit(\n",
    "    train_spectrogram_ds,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.2070 - accuracy: 0.9514\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_1_20_epochs.evaluate(x_val_np, y_val_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset:\n",
      "44/44 [==============================] - 1s 11ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 95.14%\n",
      "Recall: 89.62%\n",
      "Precision: 95.92%\n",
      "F1-score: 92.66%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9241776217225649\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.931604512015737\n",
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 0s 10ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 95.76%\n",
      "Recall: 90.83%\n",
      "Precision: 96.07%\n",
      "F1-score: 93.38%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9346979852835252\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9332818501990914\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 95.76%\n",
      "Recall: 90.83%\n",
      "Precision: 96.07%\n",
      "F1-score: 93.38%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.049 seconds\n",
      "Max: 0.119 seconds\n",
      "Min: 0.043 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_1_20_epochs, x_val_np, y_val_np, model_format=\"keras\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_1_20_epochs, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_1_20_epochs, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_1_conv_layer_model.keras\n",
      "File size: 8.822 Megabytes\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILE_NAME = \"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_1_conv_layer_model.keras\"\n",
    "model_1_20_epochs.save(MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(MODEL_FILE_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quant_conv2d (QuantConv2D)  (None, 180, 76, 8)        200       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 90, 38, 8)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 90, 38, 8)         24        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 27360)             0         \n",
      "                                                                 \n",
      " quant_dense (QuantDense)    (None, 28)                766080    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 28)                84        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " quant_dense_1 (QuantDense)  (None, 2)                 56        \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 2)                 6         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 766450 (2.92 MB)\n",
      "Trainable params: 766374 (2.92 MB)\n",
      "Non-trainable params: 76 (304.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 16s 43ms/step - loss: 0.4209 - accuracy: 0.8210\n",
      "Epoch 2/10\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2911 - accuracy: 0.8943\n",
      "Epoch 3/10\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2397 - accuracy: 0.9237\n",
      "Epoch 4/10\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2129 - accuracy: 0.9412\n",
      "Epoch 5/10\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.1902 - accuracy: 0.9538\n",
      "Epoch 6/10\n",
      "353/353 [==============================] - 16s 44ms/step - loss: 0.1821 - accuracy: 0.9600\n",
      "Epoch 7/10\n",
      "353/353 [==============================] - 16s 44ms/step - loss: 0.1780 - accuracy: 0.9631\n",
      "Epoch 8/10\n",
      "353/353 [==============================] - 15s 41ms/step - loss: 0.1726 - accuracy: 0.9666\n",
      "Epoch 9/10\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.1727 - accuracy: 0.9662\n",
      "Epoch 10/10\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.1648 - accuracy: 0.9722\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.1847 - accuracy: 0.9565\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 1s 11ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 95.65%\n",
      "Recall: 95.76%\n",
      "Precision: 91.87%\n",
      "F1-score: 93.78%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9363134992727249\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9392887725851077\n",
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 1s 12ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 95.05%\n",
      "Recall: 95.41%\n",
      "Precision: 90.10%\n",
      "F1-score: 92.68%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9280263182234367\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9240014758441233\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 95.05%\n",
      "Recall: 95.41%\n",
      "Precision: 90.10%\n",
      "F1-score: 92.68%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.05 seconds\n",
      "Max: 0.199 seconds\n",
      "Min: 0.044 seconds\n"
     ]
    }
   ],
   "source": [
    "model_1_10_epochs = tf.keras.models.Sequential()\n",
    "model_1_10_epochs.add(lq.layers.QuantConv2D(filters=8, \n",
    "                                  kernel_size=(5, 5),\n",
    "                                  kernel_quantizer=\"ste_sign\",\n",
    "                                  kernel_constraint=\"weight_clip\",\n",
    "                                  use_bias=False,\n",
    "                                  input_shape=(184, 80, 1)))\n",
    "model_1_10_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_1_10_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_1_10_epochs.add(tf.keras.layers.Flatten())\n",
    "model_1_10_epochs.add(lq.layers.QuantDense(units=28, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_1_10_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_1_10_epochs.add(lq.layers.QuantDense(units=2, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_1_10_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_1_10_epochs.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "model_1_10_epochs.summary()\n",
    "\n",
    "model_1_10_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001585943564699532),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 10\n",
    "history = model_1_10_epochs.fit(\n",
    "    train_spectrogram_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_1_10_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_1_10_epochs, x_val_np, y_val_np, model_format=\"keras\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_1_10_epochs, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_1_10_epochs, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 layer CNN is too big. We dont have second MaxPooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "kernel_size: 5\n",
      "1st_dense_units: 28\n",
      "learning_rate: 0.0063881645876014866\n",
      "2nd_dense_activation: softmax\n",
      "filters_0: 4\n",
      "filters_1: 4\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner_2_layer_cnn.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quant_conv2d_12 (QuantConv  (None, 180, 76, 4)        100       \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 90, 38, 4)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 90, 38, 4)         12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_conv2d_13 (QuantConv  (None, 86, 34, 4)         400       \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 43, 17, 4)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 43, 17, 4)         12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2924)              0         \n",
      "                                                                 \n",
      " quant_dense_12 (QuantDense  (None, 28)                81872     \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 28)                84        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_13 (QuantDense  (None, 2)                 56        \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 2)                 6         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82542 (322.43 KB)\n",
      "Trainable params: 82466 (322.13 KB)\n",
      "Non-trainable params: 76 (304.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 19s 50ms/step - loss: 0.4088 - accuracy: 0.8237\n",
      "Epoch 2/20\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.2720 - accuracy: 0.9007\n",
      "Epoch 3/20\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.2514 - accuracy: 0.9120\n",
      "Epoch 4/20\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2443 - accuracy: 0.9154\n",
      "Epoch 5/20\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2331 - accuracy: 0.9205\n",
      "Epoch 6/20\n",
      "353/353 [==============================] - 16s 47ms/step - loss: 0.2323 - accuracy: 0.9191\n",
      "Epoch 7/20\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2278 - accuracy: 0.9228\n",
      "Epoch 8/20\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.2181 - accuracy: 0.9302\n",
      "Epoch 9/20\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2262 - accuracy: 0.9243\n",
      "Epoch 10/20\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2134 - accuracy: 0.9343\n",
      "Epoch 11/20\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2112 - accuracy: 0.9397\n",
      "Epoch 12/20\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2081 - accuracy: 0.9410\n",
      "Epoch 13/20\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.2087 - accuracy: 0.9405\n",
      "Epoch 14/20\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.2062 - accuracy: 0.9424\n",
      "Epoch 15/20\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.2030 - accuracy: 0.9447\n",
      "Epoch 16/20\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.2038 - accuracy: 0.9463\n",
      "Epoch 17/20\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.2032 - accuracy: 0.9442\n",
      "Epoch 18/20\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.1951 - accuracy: 0.9492\n",
      "Epoch 19/20\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.1918 - accuracy: 0.9537\n",
      "Epoch 20/20\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.1915 - accuracy: 0.9553\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.2141 - accuracy: 0.9370\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 1s 13ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 93.70%\n",
      "Recall: 91.31%\n",
      "Precision: 90.36%\n",
      "F1-score: 90.83%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9076405943526753\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9122990467710346\n",
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 1s 13ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 93.83%\n",
      "Recall: 89.08%\n",
      "Precision: 91.89%\n",
      "F1-score: 90.47%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9048857134038025\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9079555492010022\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 93.83%\n",
      "Recall: 89.08%\n",
      "Precision: 91.89%\n",
      "F1-score: 90.47%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.052 seconds\n",
      "Max: 0.145 seconds\n",
      "Min: 0.046 seconds\n"
     ]
    }
   ],
   "source": [
    "model_2_20_epochs = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model_2_20_epochs.add(lq.layers.QuantConv2D(filters=4, \n",
    "                                  kernel_size=(5, 5),\n",
    "                                  kernel_quantizer=\"ste_sign\",\n",
    "                                  kernel_constraint=\"weight_clip\",\n",
    "                                  use_bias=False,\n",
    "                                  input_shape=(184, 80, 1)))\n",
    "model_2_20_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_2_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_2_20_epochs.add(lq.layers.QuantConv2D(\n",
    "                    filters=4, \n",
    "                    kernel_size=(5, 5),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_2_20_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_2_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_2_20_epochs.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_2_20_epochs.add(lq.layers.QuantDense(units=28, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_2_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_2_20_epochs.add(lq.layers.QuantDense(units=2, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_2_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_2_20_epochs.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model_2_20_epochs.summary()\n",
    "\n",
    "\n",
    "model_2_20_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0063881645876014866),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 20\n",
    "history = model_2_20_epochs.fit(\n",
    "    train_spectrogram_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_2_20_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_2_20_epochs, x_val_np, y_val_np, model_format=\"keras\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_2_20_epochs, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_2_20_epochs, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_2_conv_layer_model.keras\n",
      "File size: 1.009 Megabytes\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILE_NAME = \"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_2_conv_layer_model.keras\"\n",
    "model_2_20_epochs.save(MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(MODEL_FILE_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quant_conv2d_8 (QuantConv2  (None, 180, 76, 4)        100       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 90, 38, 4)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 90, 38, 4)         12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_conv2d_9 (QuantConv2  (None, 86, 34, 4)         400       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 43, 17, 4)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 43, 17, 4)         12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 2924)              0         \n",
      "                                                                 \n",
      " quant_dense_8 (QuantDense)  (None, 28)                81872     \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 28)                84        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_9 (QuantDense)  (None, 2)                 56        \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 2)                 6         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82542 (322.43 KB)\n",
      "Trainable params: 82466 (322.13 KB)\n",
      "Non-trainable params: 76 (304.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 18s 49ms/step - loss: 0.3924 - accuracy: 0.8350\n",
      "Epoch 2/10\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.2628 - accuracy: 0.9054\n",
      "Epoch 3/10\n",
      "353/353 [==============================] - 16s 47ms/step - loss: 0.2339 - accuracy: 0.9237\n",
      "Epoch 4/10\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2198 - accuracy: 0.9312\n",
      "Epoch 5/10\n",
      "353/353 [==============================] - 16s 47ms/step - loss: 0.2087 - accuracy: 0.9369\n",
      "Epoch 6/10\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.2084 - accuracy: 0.9392\n",
      "Epoch 7/10\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2029 - accuracy: 0.9437\n",
      "Epoch 8/10\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.2124 - accuracy: 0.9373\n",
      "Epoch 9/10\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.2061 - accuracy: 0.9416\n",
      "Epoch 10/10\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.1991 - accuracy: 0.9476\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.3003 - accuracy: 0.8362\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 1s 14ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 83.62%\n",
      "Recall: 52.97%\n",
      "Precision: 98.43%\n",
      "F1-score: 68.87%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.6777018901494355\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.6849706597532347\n",
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 1s 13ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 86.36%\n",
      "Recall: 58.73%\n",
      "Precision: 99.63%\n",
      "F1-score: 73.90%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7393501675475327\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7374487550303647\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 86.36%\n",
      "Recall: 58.73%\n",
      "Precision: 99.63%\n",
      "F1-score: 73.90%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.051 seconds\n",
      "Max: 0.132 seconds\n",
      "Min: 0.045 seconds\n"
     ]
    }
   ],
   "source": [
    "model_2_10_epochs = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model_2_10_epochs.add(lq.layers.QuantConv2D(filters=4, \n",
    "                                  kernel_size=(5, 5),\n",
    "                                  kernel_quantizer=\"ste_sign\",\n",
    "                                  kernel_constraint=\"weight_clip\",\n",
    "                                  use_bias=False,\n",
    "                                  input_shape=(184, 80, 1)))\n",
    "model_2_10_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_2_10_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_2_10_epochs.add(lq.layers.QuantConv2D(\n",
    "                    filters=4, \n",
    "                    kernel_size=(5, 5),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_2_10_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_2_10_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_2_10_epochs.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_2_10_epochs.add(lq.layers.QuantDense(units=28, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_2_10_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_2_10_epochs.add(lq.layers.QuantDense(units=2, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_2_10_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_2_10_epochs.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model_2_10_epochs.summary()\n",
    "\n",
    "\n",
    "model_2_10_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0063881645876014866),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 10\n",
    "history = model_2_10_epochs.fit(\n",
    "    train_spectrogram_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_2_10_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_2_10_epochs, x_val_np, y_val_np, model_format=\"keras\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_2_10_epochs, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_2_10_epochs, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "kernel_size: 2\n",
      "1st_dense_units: 24\n",
      "learning_rate: 0.0019990629503147854\n",
      "2nd_dense_activation: sigmoid\n",
      "filters_0: 6\n",
      "filters_1: 4\n",
      "filters_2: 8\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner_3_layer_cnn.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quant_conv2d_3 (QuantConv2  (None, 183, 79, 6)        24        \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 91, 39, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 91, 39, 6)         18        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " quant_conv2d_4 (QuantConv2  (None, 90, 38, 4)         96        \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 45, 19, 4)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 45, 19, 4)         12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " quant_conv2d_5 (QuantConv2  (None, 44, 18, 8)         128       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 22, 9, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 22, 9, 8)          24        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1584)              0         \n",
      "                                                                 \n",
      " quant_dense_2 (QuantDense)  (None, 24)                38016     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 24)                72        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " quant_dense_3 (QuantDense)  (None, 2)                 48        \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 2)                 6         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38444 (150.17 KB)\n",
      "Trainable params: 38356 (149.83 KB)\n",
      "Non-trainable params: 88 (352.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "353/353 [==============================] - 18s 48ms/step - loss: 0.3706 - accuracy: 0.8468\n",
      "Epoch 2/10\n",
      "353/353 [==============================] - 16s 46ms/step - loss: 0.2797 - accuracy: 0.8966\n",
      "Epoch 3/10\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.2607 - accuracy: 0.9057\n",
      "Epoch 4/10\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2739 - accuracy: 0.8967\n",
      "Epoch 5/10\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.2508 - accuracy: 0.9117\n",
      "Epoch 6/10\n",
      "353/353 [==============================] - 16s 46ms/step - loss: 0.2251 - accuracy: 0.9303\n",
      "Epoch 7/10\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.2250 - accuracy: 0.9242\n",
      "Epoch 8/10\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.2161 - accuracy: 0.9335\n",
      "Epoch 9/10\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2074 - accuracy: 0.9401\n",
      "Epoch 10/10\n",
      "353/353 [==============================] - 16s 46ms/step - loss: 0.2062 - accuracy: 0.9404\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.1805 - accuracy: 0.9594\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 1s 13ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 95.94%\n",
      "Recall: 90.68%\n",
      "Precision: 97.27%\n",
      "F1-score: 93.86%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9374112727516213\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9397700049149073\n",
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 1s 17ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 94.97%\n",
      "Recall: 87.12%\n",
      "Precision: 97.32%\n",
      "F1-score: 91.94%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9197318103358368\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9138569856995001\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 94.97%\n",
      "Recall: 87.12%\n",
      "Precision: 97.32%\n",
      "F1-score: 91.94%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.069 seconds\n",
      "Max: 0.244 seconds\n",
      "Min: 0.052 seconds\n"
     ]
    }
   ],
   "source": [
    "model_3_20_epochs = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model_3_20_epochs.add(lq.layers.QuantConv2D(filters=6, \n",
    "                                  kernel_size=(2, 2),\n",
    "                                  kernel_quantizer=\"ste_sign\",\n",
    "                                  kernel_constraint=\"weight_clip\",\n",
    "                                  use_bias=False,\n",
    "                                  input_shape=(184, 80, 1)))\n",
    "model_3_20_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_3_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_20_epochs.add(lq.layers.QuantConv2D(\n",
    "                    filters=4, \n",
    "                    kernel_size=(2, 2),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_3_20_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_3_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_20_epochs.add(lq.layers.QuantConv2D(\n",
    "                    filters=8, \n",
    "                    kernel_size=(2, 2),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_3_20_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_3_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_20_epochs.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_3_20_epochs.add(lq.layers.QuantDense(units=24, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_3_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_20_epochs.add(lq.layers.QuantDense(units=2, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_3_20_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_3_20_epochs.add(tf.keras.layers.Activation(\"sigmoid\"))\n",
    "\n",
    "model_3_20_epochs.summary()\n",
    "\n",
    "\n",
    "model_3_20_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0019990629503147854),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 10\n",
    "history = model_3_20_epochs.fit(\n",
    "    train_spectrogram_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_3_20_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_3_20_epochs, x_val_np, y_val_np, model_format=\"keras\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_3_20_epochs, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_3_20_epochs, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quant_conv2d_6 (QuantConv2  (None, 183, 79, 6)        24        \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 91, 39, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 91, 39, 6)         18        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_conv2d_7 (QuantConv2  (None, 90, 38, 4)         96        \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 45, 19, 4)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 45, 19, 4)         12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_conv2d_8 (QuantConv2  (None, 44, 18, 8)         128       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 22, 9, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 22, 9, 8)          24        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1584)              0         \n",
      "                                                                 \n",
      " quant_dense_4 (QuantDense)  (None, 24)                38016     \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 24)                72        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_5 (QuantDense)  (None, 2)                 48        \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 2)                 6         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38444 (150.17 KB)\n",
      "Trainable params: 38356 (149.83 KB)\n",
      "Non-trainable params: 88 (352.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 19s 48ms/step - loss: 0.4202 - accuracy: 0.8204\n",
      "Epoch 2/5\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.3154 - accuracy: 0.8752\n",
      "Epoch 3/5\n",
      "353/353 [==============================] - 18s 52ms/step - loss: 0.2624 - accuracy: 0.9083\n",
      "Epoch 4/5\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2295 - accuracy: 0.9261\n",
      "Epoch 5/5\n",
      "353/353 [==============================] - 17s 50ms/step - loss: 0.2326 - accuracy: 0.9293\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 1s 17ms/step - loss: 0.2107 - accuracy: 0.9420\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 1s 15ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 94.20%\n",
      "Recall: 84.11%\n",
      "Precision: 98.76%\n",
      "F1-score: 90.85%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9074523758568377\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9050684415677962\n",
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 1s 16ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 93.75%\n",
      "Recall: 84.28%\n",
      "Precision: 96.26%\n",
      "F1-score: 89.87%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.8998623711485187\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.8956799222631681\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 93.75%\n",
      "Recall: 84.28%\n",
      "Precision: 96.26%\n",
      "F1-score: 89.87%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.069 seconds\n",
      "Max: 0.215 seconds\n",
      "Min: 0.049 seconds\n"
     ]
    }
   ],
   "source": [
    "model_3_5_epochs = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model_3_5_epochs.add(lq.layers.QuantConv2D(filters=6, \n",
    "                                  kernel_size=(2, 2),\n",
    "                                  kernel_quantizer=\"ste_sign\",\n",
    "                                  kernel_constraint=\"weight_clip\",\n",
    "                                  use_bias=False,\n",
    "                                  input_shape=(184, 80, 1)))\n",
    "model_3_5_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_3_5_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_5_epochs.add(lq.layers.QuantConv2D(\n",
    "                    filters=4, \n",
    "                    kernel_size=(2, 2),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_3_5_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_3_5_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_5_epochs.add(lq.layers.QuantConv2D(\n",
    "                    filters=8, \n",
    "                    kernel_size=(2, 2),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_3_5_epochs.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model_3_5_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_5_epochs.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_3_5_epochs.add(lq.layers.QuantDense(units=24, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_3_5_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3_5_epochs.add(lq.layers.QuantDense(units=2, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_3_5_epochs.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_3_5_epochs.add(tf.keras.layers.Activation(\"sigmoid\"))\n",
    "\n",
    "model_3_5_epochs.summary()\n",
    "\n",
    "\n",
    "model_3_5_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0019990629503147854),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 5\n",
    "history = model_3_5_epochs.fit(\n",
    "    train_spectrogram_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_3_5_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_3_5_epochs, x_val_np, y_val_np, model_format=\"keras\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_3_5_epochs, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_3_5_epochs, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_3_conv_layer_model.keras\n",
      "File size: 0.519 Megabytes\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILE_NAME = \"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_3_conv_layer_model.keras\"\n",
    "model_3_20_epochs.save(MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(MODEL_FILE_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third model has good f1-score and was the smallest (519 Kb)\n",
    "\n",
    "I will try to make it smaller and keep this level of f1-score\n",
    "\n",
    "It was hard to make it smaller without loss in f1-score so I decided to use this model as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 18ms/step - loss: 0.1929 - accuracy: 0.9497\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_3_20_epochs.evaluate(x_test_np, y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show latent weights of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: quant_conv2d_3\n",
      "Shape: (2, 2, 1, 6)\n",
      "Unique values: [-0.58556724 -0.4760366  -0.42140493 -0.33268762 -0.3153949  -0.10318995\n",
      " -0.08034132 -0.07063703 -0.0541437   0.00247525  0.02785805  0.02840374\n",
      "  0.09357753  0.12507509  0.12645264  0.16857198  0.18586649  0.1963162\n",
      "  0.37236747  0.4506057   0.4587317   0.6247901   0.65256023  0.93908894]\n",
      "\n",
      "First few weights: [-0.07063703  0.12507509  0.4506057   0.00247525 -0.33268762  0.02840374\n",
      "  0.93908894 -0.3153949   0.02785805  0.4587317 ]\n",
      "\n",
      "Layer: quant_conv2d_4\n",
      "Shape: (2, 2, 6, 4)\n",
      "Unique values: [-8.1961292e-01 -6.6805083e-01 -5.6972295e-01 -5.5980152e-01\n",
      " -5.2410978e-01 -5.0751966e-01 -5.0569969e-01 -4.5249176e-01\n",
      " -4.0741798e-01 -3.9473873e-01 -3.9230612e-01 -3.7853619e-01\n",
      " -3.5750267e-01 -3.3168477e-01 -3.2919437e-01 -3.2322365e-01\n",
      " -3.1101790e-01 -2.9838705e-01 -2.7472708e-01 -2.6714271e-01\n",
      " -2.1595439e-01 -2.0875093e-01 -1.8329845e-01 -1.6528052e-01\n",
      " -1.1749125e-01 -1.1125868e-01 -9.5753163e-02 -8.2675077e-02\n",
      " -7.7510871e-02 -6.9486335e-02 -4.8846729e-02 -3.3317454e-02\n",
      " -3.0765299e-02 -3.0731391e-02 -2.5495527e-02 -2.0132234e-02\n",
      " -1.3434852e-02 -1.2379314e-02 -7.6035741e-03 -2.1116261e-03\n",
      " -1.4678717e-03  3.4713044e-04  5.9323740e-04  3.2189093e-03\n",
      "  5.9082317e-03  8.4980316e-03  1.4397042e-02  2.9672047e-02\n",
      "  3.7269417e-02  3.8092647e-02  4.0847678e-02  5.3430263e-02\n",
      "  7.0249878e-02  8.6214200e-02  8.7210149e-02  9.7883679e-02\n",
      "  1.2908950e-01  1.4326578e-01  1.4437254e-01  1.5223742e-01\n",
      "  1.6151640e-01  1.8081577e-01  1.8362467e-01  1.8745135e-01\n",
      "  2.0674779e-01  2.1438327e-01  2.1536398e-01  2.1644096e-01\n",
      "  2.3279171e-01  2.3995052e-01  2.5476837e-01  2.5636956e-01\n",
      "  2.6996818e-01  2.7806726e-01  2.8247458e-01  3.0825683e-01\n",
      "  3.1907934e-01  3.4235436e-01  3.5103476e-01  3.5785577e-01\n",
      "  4.2567360e-01  4.7064817e-01  5.0213271e-01  5.0975883e-01\n",
      "  5.5193681e-01  5.5231446e-01  6.1367959e-01  6.3518494e-01\n",
      "  6.9995606e-01  7.3406607e-01  7.6592070e-01  8.1284392e-01\n",
      "  9.0601259e-01  1.0000000e+00]\n",
      "\n",
      "First few weights: [ 0.09788368 -0.3785362   0.25636956 -0.45249176 -0.2671427   0.02967205\n",
      " -0.01237931 -0.07751087 -0.18329845  0.03809265]\n",
      "\n",
      "Layer: quant_conv2d_5\n",
      "Shape: (2, 2, 4, 8)\n",
      "Unique values: [-1.00000000e+00 -9.96920347e-01 -9.74100292e-01 -9.44008172e-01\n",
      " -8.92601490e-01 -8.86865795e-01 -8.78188431e-01 -7.70685911e-01\n",
      " -6.32828832e-01 -6.25605941e-01 -6.03549123e-01 -5.36036074e-01\n",
      " -5.01961708e-01 -4.99622911e-01 -4.59786713e-01 -4.31483507e-01\n",
      " -4.20513481e-01 -4.19339418e-01 -4.06459898e-01 -4.02540773e-01\n",
      " -3.98727864e-01 -3.43291819e-01 -3.38746548e-01 -3.07058126e-01\n",
      " -3.05803508e-01 -2.81348944e-01 -2.77865797e-01 -2.74599165e-01\n",
      " -2.68444121e-01 -2.63408899e-01 -2.62413293e-01 -2.36591280e-01\n",
      " -2.17092425e-01 -1.89801961e-01 -1.84268981e-01 -1.83878258e-01\n",
      " -1.60587594e-01 -1.51314601e-01 -1.46688879e-01 -1.30672619e-01\n",
      " -1.11819416e-01 -8.31886306e-02 -7.18596727e-02 -6.26675338e-02\n",
      " -6.23294190e-02 -5.31072989e-02 -4.74243164e-02 -3.72539274e-02\n",
      " -3.68829258e-02 -1.73169412e-02 -1.66148581e-02 -1.65255144e-02\n",
      " -1.16787115e-02 -1.14557892e-02 -5.54251205e-03 -3.45679070e-03\n",
      " -3.03492486e-03 -2.91861035e-03 -2.63873395e-03 -2.35247961e-03\n",
      " -1.44895411e-03 -1.08815904e-03 -9.64348961e-04 -6.15394907e-04\n",
      "  3.75368109e-05  5.78078325e-05  2.99662910e-03  3.03762755e-03\n",
      "  7.40729179e-03  9.93177202e-03  1.44947190e-02  1.50966896e-02\n",
      "  1.57202110e-02  2.55527310e-02  2.64207684e-02  4.10818867e-02\n",
      "  4.90572751e-02  5.71144074e-02  6.13408163e-02  6.26456514e-02\n",
      "  6.50896803e-02  7.22439289e-02  8.42319578e-02  8.97034705e-02\n",
      "  1.04682744e-01  1.19683988e-01  1.29427254e-01  1.29512757e-01\n",
      "  1.33542463e-01  1.43607095e-01  1.45512626e-01  1.45663574e-01\n",
      "  1.45790443e-01  1.90165848e-01  2.11418360e-01  2.17280105e-01\n",
      "  2.19802007e-01  2.32091054e-01  2.38482922e-01  2.47113615e-01\n",
      "  2.57564753e-01  2.82845795e-01  3.30866635e-01  3.58297825e-01\n",
      "  3.75529587e-01  3.91874105e-01  4.19304013e-01  4.22120988e-01\n",
      "  4.40614730e-01  4.74665344e-01  4.94580209e-01  5.24264574e-01\n",
      "  5.50463438e-01  5.54246664e-01  5.65031111e-01  5.68780601e-01\n",
      "  5.83628476e-01  5.89285016e-01  5.90670228e-01  6.08659327e-01\n",
      "  6.36182964e-01  6.63578749e-01  7.58315444e-01  7.61482060e-01\n",
      "  8.41762245e-01  1.00000000e+00]\n",
      "\n",
      "First few weights: [-0.2634089   0.219802   -0.4314835  -0.04742432 -0.00108816 -0.00303492\n",
      "  0.3918741  -0.28134894  0.11968399  0.33086663]\n",
      "\n",
      "Layer: quant_dense_2\n",
      "Shape: (1584, 24)\n",
      "Unique values: [-1.         -0.9949671  -0.9906221  ...  0.87707144  0.91965646\n",
      "  1.        ]\n",
      "\n",
      "First few weights: [ 0.0370524   0.06456068  0.02911065  0.020255    0.00137389 -0.0473805\n",
      " -0.00710181  0.0857726  -0.01976208 -0.13536301]\n",
      "\n",
      "Layer: quant_dense_3\n",
      "Shape: (24, 2)\n",
      "Unique values: [-7.4778354e-01 -7.4481171e-01 -6.6980577e-01 -6.1217695e-01\n",
      " -5.7736456e-01 -5.7269287e-01 -5.6762195e-01 -5.6652993e-01\n",
      " -5.6507009e-01 -5.2667886e-01 -4.9182498e-01 -4.7494432e-01\n",
      " -4.7409800e-01 -3.9295542e-01 -3.1159246e-01 -2.5039360e-01\n",
      " -2.4898832e-01 -1.4023753e-01 -8.1119649e-02 -6.2134523e-02\n",
      " -1.2550218e-03 -3.9678538e-04  1.9716497e-03  2.3040262e-03\n",
      "  3.7082434e-03  3.3313107e-02  4.9663808e-02  5.8584411e-02\n",
      "  6.4232394e-02  8.3540998e-02  1.2116299e-01  1.2440450e-01\n",
      "  1.5035811e-01  1.5638089e-01  2.3471943e-01  2.8484502e-01\n",
      "  3.0650625e-01  3.2876059e-01  3.3418477e-01  4.1253796e-01\n",
      "  4.7651157e-01  5.3438598e-01  5.7897133e-01  5.8447027e-01\n",
      "  6.7160791e-01  6.8456614e-01  7.9130352e-01  9.3726510e-01]\n",
      "\n",
      "First few weights: [ 3.3313107e-02 -1.2550218e-03 -3.9678538e-04  1.5638089e-01\n",
      " -7.4778354e-01  4.7651157e-01 -5.7269287e-01  3.3418477e-01\n",
      " -4.7409800e-01  1.2440450e-01]\n",
      "\n",
      "Layer: quant_conv2d_3, Weight shape: (2, 2, 1, 6), Size: 256 bytes\n",
      "Layer: quant_conv2d_4, Weight shape: (2, 2, 6, 4), Size: 544 bytes\n",
      "Layer: quant_conv2d_5, Weight shape: (2, 2, 4, 8), Size: 672 bytes\n",
      "Layer: quant_dense_2, Weight shape: (1584, 24), Size: 152192 bytes\n",
      "Layer: quant_dense_3, Weight shape: (24, 2), Size: 320 bytes\n",
      "Total memory usage: 153984 bytes\n"
     ]
    }
   ],
   "source": [
    "def display_weights(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, lq.layers.QuantConv2D) or isinstance(layer, lq.layers.QuantDense):\n",
    "            weights = layer.get_weights()\n",
    "            if weights:\n",
    "                print(f\"Layer: {layer.name}\")\n",
    "                for weight in weights:\n",
    "                    print(f\"Shape: {weight.shape}\")\n",
    "                    # Print the unique values to see if they are binarized\n",
    "                    unique_values = np.unique(weight)\n",
    "                    print(f\"Unique values: {unique_values}\\n\")\n",
    "                    # Print the first few weights for inspection\n",
    "                    print(f\"First few weights: {weight.flatten()[:10]}\\n\")\n",
    "\n",
    "# Display the weights of the binarized CNN model\n",
    "\n",
    "\n",
    "def model_memory_usage(model):\n",
    "    total_size = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (lq.layers.QuantConv2D, lq.layers.QuantDense)):\n",
    "            weights = layer.get_weights()\n",
    "            for weight in weights:\n",
    "                size = sys.getsizeof(weight)\n",
    "                total_size += size\n",
    "                print(f\"Layer: {layer.name}, Weight shape: {weight.shape}, Size: {size} bytes\")\n",
    "\n",
    "    print(f\"Total memory usage: {total_size} bytes\")\n",
    "\n",
    "# Display the weights of the binarized CNN model\n",
    "display_weights(model_3_20_epochs)\n",
    "\n",
    "# Check the memory usage of the model\n",
    "model_memory_usage(model_3_20_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show binary weights of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with lq.context.quantized_scope(True):\n",
    "    model_3_20_epochs.save(\"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_3_conv_layer_model_binary_weights.keras\")  # save binarized weights h5\n",
    "    weights = model_3_20_epochs.get_weights()  # get binarized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_weights_model = tf.keras.models.load_model(\"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_3_conv_layer_model_binary_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: quant_conv2d_3\n",
      "Shape: (2, 2, 1, 6)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1.  1.  1.  1. -1.  1.  1. -1.  1.  1.]\n",
      "\n",
      "Layer: quant_conv2d_4\n",
      "Shape: (2, 2, 6, 4)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [ 1. -1.  1. -1. -1.  1. -1. -1. -1.  1.]\n",
      "\n",
      "Layer: quant_conv2d_5\n",
      "Shape: (2, 2, 4, 8)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1.  1. -1. -1. -1. -1.  1. -1.  1.  1.]\n",
      "\n",
      "Layer: quant_dense_2\n",
      "Shape: (1584, 24)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [ 1.  1.  1.  1.  1. -1. -1.  1. -1. -1.]\n",
      "\n",
      "Layer: quant_dense_3\n",
      "Shape: (24, 2)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [ 1. -1. -1.  1. -1.  1. -1.  1. -1.  1.]\n",
      "\n",
      "Layer: quant_conv2d_3, Weight shape: (2, 2, 1, 6), Size: 256 bytes\n",
      "Layer: quant_conv2d_4, Weight shape: (2, 2, 6, 4), Size: 544 bytes\n",
      "Layer: quant_conv2d_5, Weight shape: (2, 2, 4, 8), Size: 672 bytes\n",
      "Layer: quant_dense_2, Weight shape: (1584, 24), Size: 152192 bytes\n",
      "Layer: quant_dense_3, Weight shape: (24, 2), Size: 320 bytes\n",
      "Total memory usage: 153984 bytes\n"
     ]
    }
   ],
   "source": [
    "# Display the weights of the binarized CNN model\n",
    "display_weights(binarized_weights_model)\n",
    "\n",
    "# Check the memory usage of the model\n",
    "model_memory_usage(binarized_weights_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_3_conv_layer_model_binary_weights.keras\n",
      "File size: 0.519 Megabytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Model file name: \", \"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_3_conv_layer_model_binary_weights.keras\")\n",
    "convert_bytes(get_file_size(\"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_3_conv_layer_model_binary_weights.keras\"), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### larq TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmposuvsexo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmposuvsexo/assets\n",
      "2024-07-26 20:54:52.588535: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmposuvsexo\n",
      "2024-07-26 20:54:52.597099: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-07-26 20:54:52.597183: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmposuvsexo\n",
      "2024-07-26 20:54:52.620085: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-07-26 20:54:52.749427: E external/org_tensorflow/tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute debug_name which is not in the op definition: Op<name=VarHandleOp; signature= -> resource:resource; attr=container:string,default=\"\"; attr=shared_name:string,default=\"\"; attr=dtype:type; attr=shape:shape; attr=allowed_devices:list(string),default=[]; is_stateful=true> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node Adam/m/batch_normalization_5/beta}}\n",
      "2024-07-26 20:54:52.758368: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmposuvsexo\n",
      "2024-07-26 20:54:52.804191: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 215770 microseconds.\n",
      "2024-07-26 20:54:52.964512: I external/org_tensorflow/tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 1.015 M  ops, equivalently 0.507 M  MACs\n"
     ]
    }
   ],
   "source": [
    "lce_model = lce.convert_keras_model(model_3_20_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check time of prdiction by bnn tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_time of one prediction, s:  0.00257986424298122\n"
     ]
    }
   ],
   "source": [
    "exec_time = []\n",
    "y_pred_all = []\n",
    "for i in range(1, len(x_test_np)):\n",
    "    # print(i)\n",
    "    start_time = time.time()\n",
    "    interpreter = lce.testing.Interpreter(lce_model)\n",
    "    y_pred_prob = interpreter.predict(x_test_np[i-1:i], verbose=0)\n",
    "    y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
    "    y_pred_all.extend(y_pred)\n",
    "    stop_time = time.time() - start_time\n",
    "    # print(stop_time)\n",
    "    exec_time.append(stop_time)\n",
    "print(\"mean_time of one prediction, s: \", sum(exec_time) / len(exec_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.04%\n",
      "Recall: 97.32%\n",
      "Precision: 87.31%\n",
      "F1-score: 92.04%\n"
     ]
    }
   ],
   "source": [
    "evaluate_prediction(y_pred_all, y_test_np[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write model in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159780"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_LITE_LARQ_MODEL_FILE_NAME = \"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_lq.tflite\"\n",
    "open(TF_LITE_LARQ_MODEL_FILE_NAME, \"wb\").write(lce_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=TF_LITE_LARQ_MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dont know how to read this model from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpklmkwoke/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpklmkwoke/assets\n",
      "2024-07-26 20:38:56.250224: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-07-26 20:38:56.250294: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-07-26 20:38:56.250459: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpklmkwoke\n",
      "2024-07-26 20:38:56.252873: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-26 20:38:56.252910: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpklmkwoke\n",
      "2024-07-26 20:38:56.260456: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-07-26 20:38:56.321188: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpklmkwoke\n",
      "2024-07-26 20:38:56.344950: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 94491 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 18, Total Ops 49, % non-converted = 36.73 %\n",
      " * 18 ARITH ops\n",
      "\n",
      "- arith.constant:   18 occurrences  (f32: 17, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 7)\n",
      "  (f32: 3)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 94.97%\n",
      "Recall: 87.12%\n",
      "Precision: 97.32%\n",
      "F1-score: 91.94%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9197318103358368\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9120115881644462\n",
      "\n",
      "Time for Test dataset:\n",
      "Accuracy: 94.97%\n",
      "Recall: 87.12%\n",
      "Precision: 97.32%\n",
      "F1-score: 91.94%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.001 seconds\n",
      "Max: 0.002 seconds\n",
      "Min: 0.001 seconds\n",
      "\n",
      "\n",
      "Model file name:  ../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_tf_lite.tflite\n",
      "File size: 157.906 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    "    ) = predict_and_print_full_results(tflite_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "evaluate_time_of_prediction(tflite_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "TF_LITE_MODEL_FILE_NAME = \"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_tf_lite.tflite\"\n",
    "open(TF_LITE_MODEL_FILE_NAME, \"wb\").write(tflite_model)\n",
    "print(\"\\n\")\n",
    "print(\"Model file name: \", TF_LITE_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See tflite.tflite model weights and size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: serving_default_quant_conv2d_3_input:0, Index: 0, Shape: [  1 184  80   1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_8/batchnorm/mul, Index: 1, Shape: [  24 1584], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_9/batchnorm/mul, Index: 2, Shape: [ 2 24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D, Index: 3, Shape: [6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D1, Index: 4, Shape: [6 2 2 1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/QuantConv2D, Index: 5, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/QuantConv2D1, Index: 6, Shape: [4 2 2 6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/QuantConv2D, Index: 7, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/QuantConv2D1, Index: 8, Shape: [8 2 2 4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_9/batchnorm/sub, Index: 9, Shape: [2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_8/batchnorm/sub, Index: 10, Shape: [24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/flatten_1/Const, Index: 11, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D/ste_sign_9/add/y, Index: 12, Shape: [], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV3, Index: 13, Shape: [6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV31, Index: 14, Shape: [6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV3, Index: 15, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV31, Index: 16, Shape: [4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV3, Index: 17, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV31, Index: 18, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D2, Index: 19, Shape: [  1 183  79   6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/max_pooling2d_3/MaxPool, Index: 20, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV32, Index: 21, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV33, Index: 22, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/ste_sign_11/Sign, Index: 23, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/ste_sign_11/add, Index: 24, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/ste_sign_11/Sign_1, Index: 25, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/QuantConv2D2, Index: 26, Shape: [ 1 90 38  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/max_pooling2d_4/MaxPool, Index: 27, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV32, Index: 28, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV33, Index: 29, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/ste_sign_13/Sign, Index: 30, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/ste_sign_13/add, Index: 31, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/ste_sign_13/Sign_1, Index: 32, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/QuantConv2D2, Index: 33, Shape: [ 1 44 18  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/max_pooling2d_5/MaxPool, Index: 34, Shape: [ 1 22  9  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV32, Index: 35, Shape: [ 1 22  9  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV33, Index: 36, Shape: [ 1 22  9  8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/flatten_1/Reshape, Index: 37, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_15/Sign, Index: 38, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_15/add, Index: 39, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_15/Sign_1, Index: 40, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/MatMul;sequential_1/batch_normalization_8/batchnorm/mul;sequential_1/batch_normalization_8/batchnorm/add_1, Index: 41, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_17/Sign, Index: 42, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_17/add, Index: 43, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_17/Sign_1, Index: 44, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/MatMul;sequential_1/batch_normalization_9/batchnorm/mul;sequential_1/batch_normalization_9/batchnorm/add_1, Index: 45, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: StatefulPartitionedCall:0, Index: 46, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 59, Shape: [4 6], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 60, Shape: [24  4], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 61, Shape: [16  8], dtype: <class 'numpy.float32'>\n",
      "Tensor serving_default_quant_conv2d_3_input:0 - Shape: (1, 184, 80, 1), Data: [[[[-0.9373283 ]\n",
      "   [-1.8462163 ]\n",
      "   [-1.6846098 ]\n",
      "   ...\n",
      "   [-2.871213  ]\n",
      "   [-3.8945668 ]\n",
      "   [-5.710342  ]]\n",
      "\n",
      "  [[-1.0653405 ]\n",
      "   [-0.8649982 ]\n",
      "   [-1.4073898 ]\n",
      "   ...\n",
      "   [-3.0824087 ]\n",
      "   [-3.8587742 ]\n",
      "   [-5.62705   ]]\n",
      "\n",
      "  [[-0.47574413]\n",
      "   [-0.50857115]\n",
      "   [-1.51533   ]\n",
      "   ...\n",
      "   [-3.0004165 ]\n",
      "   [-3.781811  ]\n",
      "   [-5.376748  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.6431216 ]\n",
      "   [-1.2507148 ]\n",
      "   [-0.7224055 ]\n",
      "   ...\n",
      "   [-3.381774  ]\n",
      "   [-3.6054962 ]\n",
      "   [-5.234658  ]]\n",
      "\n",
      "  [[-1.1810825 ]\n",
      "   [-1.051295  ]\n",
      "   [-1.2631068 ]\n",
      "   ...\n",
      "   [-3.219378  ]\n",
      "   [-3.9600673 ]\n",
      "   [-5.6320443 ]]\n",
      "\n",
      "  [[-0.70521295]\n",
      "   [-0.55519056]\n",
      "   [-1.4383278 ]\n",
      "   ...\n",
      "   [-2.8993685 ]\n",
      "   [-4.168313  ]\n",
      "   [-5.770375  ]]]]\n",
      "Tensor sequential_1/batch_normalization_8/batchnorm/mul - Shape: (24, 1584), Data: [[ 0.00354157  0.00354157 -0.00354157 ... -0.00354157  0.00354157\n",
      "  -0.00354157]\n",
      " [ 0.00800448  0.00800448  0.00800448 ...  0.00800448 -0.00800448\n",
      "   0.00800448]\n",
      " [ 0.00873648  0.00873648 -0.00873648 ...  0.00873648 -0.00873648\n",
      "  -0.00873648]\n",
      " ...\n",
      " [-0.00331745 -0.00331745 -0.00331745 ... -0.00331745 -0.00331745\n",
      "  -0.00331745]\n",
      " [ 0.01147186 -0.01147186  0.01147186 ... -0.01147186 -0.01147186\n",
      "   0.01147186]\n",
      " [-0.0089049   0.0089049  -0.0089049  ...  0.0089049  -0.0089049\n",
      "   0.0089049 ]]\n",
      "Tensor sequential_1/batch_normalization_9/batchnorm/mul - Shape: (2, 24), Data: [[ 0.08980736 -0.08980736 -0.08980736 -0.08980736 -0.08980736  0.08980736\n",
      "  -0.08980736  0.08980736  0.08980736 -0.08980736  0.08980736  0.08980736\n",
      "   0.08980736 -0.08980736 -0.08980736  0.08980736  0.08980736 -0.08980736\n",
      "   0.08980736 -0.08980736  0.08980736 -0.08980736 -0.08980736 -0.08980736]\n",
      " [-0.08745821  0.08745821  0.08745821  0.08745821  0.08745821 -0.08745821\n",
      "   0.08745821 -0.08745821  0.08745821  0.08745821  0.08745821 -0.08745821\n",
      "   0.08745821  0.08745821  0.08745821 -0.08745821 -0.08745821  0.08745821\n",
      "  -0.08745821  0.08745821 -0.08745821 -0.08745821  0.08745821  0.08745821]]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D - Shape: (6,), Data: [0. 0. 0. 0. 0. 0.]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D1 - Shape: (6, 2, 2, 1), Data: [[[[-1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.]\n",
      "   [-1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [-1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [-1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 1.]]]]\n",
      "Tensor sequential_1/quant_conv2d_4/QuantConv2D - Shape: (4,), Data: [0. 0. 0. 0.]\n",
      "Tensor sequential_1/quant_conv2d_4/QuantConv2D1 - Shape: (4, 2, 2, 6), Data: [[[[ 1. -1. -1.  1. -1.  1.]\n",
      "   [-1.  1.  1. -1. -1. -1.]]\n",
      "\n",
      "  [[-1.  1.  1. -1. -1. -1.]\n",
      "   [-1.  1. -1. -1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1.  1.  1.  1.  1.]\n",
      "   [-1. -1.  1. -1.  1.  1.]]\n",
      "\n",
      "  [[ 1.  1.  1. -1. -1.  1.]\n",
      "   [ 1. -1. -1.  1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1. -1. -1.  1.  1.  1.]\n",
      "   [ 1.  1. -1. -1.  1. -1.]]\n",
      "\n",
      "  [[ 1.  1. -1.  1.  1.  1.]\n",
      "   [ 1.  1. -1. -1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1. -1.  1.  1.]\n",
      "   [ 1.  1. -1. -1.  1.  1.]]\n",
      "\n",
      "  [[-1.  1.  1. -1.  1.  1.]\n",
      "   [ 1.  1.  1.  1.  1.  1.]]]]\n",
      "Tensor sequential_1/quant_conv2d_5/QuantConv2D - Shape: (8,), Data: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Tensor sequential_1/quant_conv2d_5/QuantConv2D1 - Shape: (8, 2, 2, 4), Data: [[[[-1.  1. -1. -1.]\n",
      "   [ 1. -1.  1. -1.]]\n",
      "\n",
      "  [[-1. -1.  1. -1.]\n",
      "   [ 1. -1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  1. -1.  1.]\n",
      "   [ 1. -1.  1. -1.]]\n",
      "\n",
      "  [[ 1.  1. -1. -1.]\n",
      "   [ 1. -1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1.  1.  1.]\n",
      "   [ 1.  1.  1.  1.]]\n",
      "\n",
      "  [[-1.  1.  1.  1.]\n",
      "   [ 1.  1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1. -1.]\n",
      "   [-1.  1. -1.  1.]]\n",
      "\n",
      "  [[ 1.  1. -1. -1.]\n",
      "   [-1.  1. -1.  1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1.  1.  1.]\n",
      "   [ 1.  1.  1.  1.]]\n",
      "\n",
      "  [[ 1. -1.  1.  1.]\n",
      "   [ 1. -1.  1.  1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1. -1.  1.]\n",
      "   [-1. -1. -1. -1.]]\n",
      "\n",
      "  [[-1.  1.  1.  1.]\n",
      "   [-1.  1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[ 1. -1. -1.  1.]\n",
      "   [ 1. -1. -1. -1.]]\n",
      "\n",
      "  [[-1.  1. -1. -1.]\n",
      "   [ 1. -1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1. -1.]\n",
      "   [-1. -1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1. -1.]\n",
      "   [ 1.  1.  1.  1.]]]]\n",
      "Tensor sequential_1/batch_normalization_9/batchnorm/sub - Shape: (2,), Data: [ 0.08902183 -0.05441982]\n",
      "Tensor sequential_1/batch_normalization_8/batchnorm/sub - Shape: (24,), Data: [-1.0700091   0.5799124  -0.744154   -0.74155945 -1.1468663   0.972546\n",
      " -0.7318057   0.89624804  1.1183951  -0.8465897  -0.69563204  1.3483243\n",
      " -1.7116337  -1.0150051  -0.7908413   0.6676947   0.888582   -0.0271609\n",
      "  1.0740863   0.1314838   0.27894354 -0.9693073  -0.84099734 -0.98748267]\n",
      "Tensor sequential_1/flatten_1/Const - Shape: (2,), Data: [  -1 1584]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D/ste_sign_9/add/y - Shape: (), Data: 0.10000000149011612\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV3 - Shape: (6,), Data: [0.18362285 0.18916714 0.18326458 0.18380241 1.1453308  0.18380241]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV31 - Shape: (6,), Data: [ 0.4076755  -0.6083193   1.3900635   0.42609882 -1.1537237  -0.1966489 ]\n",
      "Tensor sequential_1/batch_normalization_6/FusedBatchNormV3 - Shape: (4,), Data: [0.18471202 0.21667424 0.26398584 0.27221507]\n",
      "Tensor sequential_1/batch_normalization_6/FusedBatchNormV31 - Shape: (4,), Data: [-0.53293633 -0.13558313  0.2457928  -0.28320175]\n",
      "Tensor sequential_1/batch_normalization_7/FusedBatchNormV3 - Shape: (8,), Data: [0.26202005 0.23281957 0.15210299 0.21800128 0.2209664  0.1917535\n",
      " 0.21043523 0.27318588]\n",
      "Tensor sequential_1/batch_normalization_7/FusedBatchNormV31 - Shape: (8,), Data: [-0.28088677 -0.30893022 -0.5812032  -1.0656488   0.11313617  0.18977976\n",
      "  0.00789011 -0.42487222]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detail \u001b[38;5;129;01min\u001b[39;00m tensor_details:\n\u001b[0;32m---> 12\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetail[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:926\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index):\n\u001b[1;32m    879\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../spectrogram_models_from_notebooks/bnn/hpo/bnn_mel_spec_tf_lite.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get tensor details\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "for detail in tensor_details:\n",
    "    print(f\"Name: {detail['name']}, Index: {detail['index']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "\n",
    "# Extract weights\n",
    "for detail in tensor_details:\n",
    "    tensor = interpreter.tensor(detail['index'])()\n",
    "    print(f\"Tensor {detail['name']} - Shape: {tensor.shape}, Data: {tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make full int quantization of tflite.tflite model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptz1_mhcj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptz1_mhcj/assets\n",
      "/home/polina/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-07-26 20:41:42.414186: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-07-26 20:41:42.414244: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-07-26 20:41:42.414455: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmptz1_mhcj\n",
      "2024-07-26 20:41:42.424287: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-26 20:41:42.424323: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmptz1_mhcj\n",
      "2024-07-26 20:41:42.434023: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-07-26 20:41:42.501602: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmptz1_mhcj\n",
      "2024-07-26 20:41:42.526481: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 112026 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 18, Total Ops 49, % non-converted = 36.73 %\n",
      " * 18 ARITH ops\n",
      "\n",
      "- arith.constant:   18 occurrences  (f32: 17, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 7)\n",
      "  (f32: 3)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 8)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(x_val_np).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "full_int_converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "full_int_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "full_int_converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "full_int_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "full_int_converter.inference_input_type = tf.uint8\n",
    "full_int_converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = full_int_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: serving_default_quant_conv2d_3_input:0, Index: 0, Shape: [  1 184  80   1], dtype: <class 'numpy.uint8'>\n",
      "Name: sequential_1/flatten_1/Const, Index: 1, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/batch_normalization_9/batchnorm/sub, Index: 2, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/batch_normalization_9/batchnorm/mul, Index: 3, Shape: [ 2 24], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_8/batchnorm/sub, Index: 4, Shape: [24], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/batch_normalization_8/batchnorm/mul, Index: 5, Shape: [  24 1584], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV31, Index: 6, Shape: [8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV3, Index: 7, Shape: [8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_5/QuantConv2D, Index: 8, Shape: [8], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/quant_conv2d_5/QuantConv2D1, Index: 9, Shape: [8 2 2 4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV31, Index: 10, Shape: [4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV3, Index: 11, Shape: [4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_4/QuantConv2D, Index: 12, Shape: [4], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/quant_conv2d_4/QuantConv2D1, Index: 13, Shape: [4 2 2 6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D/ste_sign_9/add/y, Index: 14, Shape: [], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV31, Index: 15, Shape: [6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV3, Index: 16, Shape: [6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D, Index: 17, Shape: [6], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D1, Index: 18, Shape: [6 2 2 1], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.quantize, Index: 19, Shape: [  1 184  80   1], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_3/QuantConv2D2, Index: 20, Shape: [  1 183  79   6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/max_pooling2d_3/MaxPool, Index: 21, Shape: [ 1 91 39  6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV32, Index: 22, Shape: [ 1 91 39  6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_5/FusedBatchNormV33, Index: 23, Shape: [ 1 91 39  6], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize, Index: 24, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/ste_sign_11/Sign, Index: 25, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize1, Index: 26, Shape: [ 1 91 39  6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_4/ste_sign_11/add, Index: 27, Shape: [ 1 91 39  6], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize1, Index: 28, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_4/ste_sign_11/Sign_1, Index: 29, Shape: [ 1 91 39  6], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize2, Index: 30, Shape: [ 1 91 39  6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_4/QuantConv2D2, Index: 31, Shape: [ 1 90 38  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/max_pooling2d_4/MaxPool, Index: 32, Shape: [ 1 45 19  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV32, Index: 33, Shape: [ 1 45 19  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_6/FusedBatchNormV33, Index: 34, Shape: [ 1 45 19  4], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize2, Index: 35, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/ste_sign_13/Sign, Index: 36, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize3, Index: 37, Shape: [ 1 45 19  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_5/ste_sign_13/add, Index: 38, Shape: [ 1 45 19  4], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize3, Index: 39, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_conv2d_5/ste_sign_13/Sign_1, Index: 40, Shape: [ 1 45 19  4], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize4, Index: 41, Shape: [ 1 45 19  4], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_conv2d_5/QuantConv2D2, Index: 42, Shape: [ 1 44 18  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/max_pooling2d_5/MaxPool, Index: 43, Shape: [ 1 22  9  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV32, Index: 44, Shape: [ 1 22  9  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/batch_normalization_7/FusedBatchNormV33, Index: 45, Shape: [ 1 22  9  8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/flatten_1/Reshape, Index: 46, Shape: [   1 1584], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/flatten_1/Reshape1, Index: 47, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_15/Sign, Index: 48, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize5, Index: 49, Shape: [   1 1584], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_15/add, Index: 50, Shape: [   1 1584], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize4, Index: 51, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_2/ste_sign_15/Sign_1, Index: 52, Shape: [   1 1584], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize6, Index: 53, Shape: [   1 1584], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_2/MatMul;sequential_1/batch_normalization_8/batchnorm/mul;sequential_1/batch_normalization_8/batchnorm/add_1, Index: 54, Shape: [ 1 24], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize5, Index: 55, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_17/Sign, Index: 56, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize7, Index: 57, Shape: [ 1 24], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_17/add, Index: 58, Shape: [ 1 24], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize6, Index: 59, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_1/quant_dense_3/ste_sign_17/Sign_1, Index: 60, Shape: [ 1 24], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize8, Index: 61, Shape: [ 1 24], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_1/quant_dense_3/MatMul;sequential_1/batch_normalization_9/batchnorm/mul;sequential_1/batch_normalization_9/batchnorm/add_1, Index: 62, Shape: [1 2], dtype: <class 'numpy.int8'>\n",
      "Name: StatefulPartitionedCall:01, Index: 63, Shape: [1 2], dtype: <class 'numpy.int8'>\n",
      "Name: StatefulPartitionedCall:0, Index: 64, Shape: [1 2], dtype: <class 'numpy.uint8'>\n",
      "Name: , Index: 77, Shape: [  1 183  79   4], dtype: <class 'numpy.int8'>\n",
      "Name: , Index: 78, Shape: [ 1 90 38 24], dtype: <class 'numpy.int8'>\n",
      "Name: , Index: 79, Shape: [ 1 44 18 16], dtype: <class 'numpy.int8'>\n",
      "Tensor serving_default_quant_conv2d_3_input:0 - Shape: (1, 184, 80, 1), Data: [[[[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[ 15]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[113]\n",
      "   [117]\n",
      "   [ 97]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 58]\n",
      "   [ 37]\n",
      "   [  3]\n",
      "   ...\n",
      "   [ 37]\n",
      "   [  3]\n",
      "   [188]]\n",
      "\n",
      "  [[ 58]\n",
      "   [ 37]\n",
      "   [  3]\n",
      "   ...\n",
      "   [ 37]\n",
      "   [  3]\n",
      "   [ 60]]\n",
      "\n",
      "  [[ 58]\n",
      "   [ 37]\n",
      "   [  3]\n",
      "   ...\n",
      "   [ 37]\n",
      "   [  3]\n",
      "   [188]]]]\n",
      "Tensor sequential_1/flatten_1/Const - Shape: (2,), Data: [  -1 1584]\n",
      "Tensor sequential_1/batch_normalization_9/batchnorm/sub - Shape: (2,), Data: [16051 -9812]\n",
      "Tensor sequential_1/batch_normalization_9/batchnorm/mul - Shape: (2, 24), Data: [[ 127 -127 -127 -127 -127  127 -127  127  127 -127  127  127  127 -127\n",
      "  -127  127  127 -127  127 -127  127 -127 -127 -127]\n",
      " [-124  124  124  124  124 -124  124 -124  124  124  124 -124  124  124\n",
      "   124 -124 -124  124 -124  124 -124 -124  124  124]]\n",
      "Tensor sequential_1/batch_normalization_8/batchnorm/sub - Shape: (24,), Data: [-1354999   734368  -942354  -939069 -1452326  1231577  -926717  1134958\n",
      "  1416272 -1072073  -880909  1707441 -2167516 -1285345 -1001477   845531\n",
      "  1125250   -34395  1360162   166504   353238 -1227476 -1064991 -1250492]\n",
      "Tensor sequential_1/batch_normalization_8/batchnorm/mul - Shape: (24, 1584), Data: [[  35   35  -35 ...  -35   35  -35]\n",
      " [  80   80   80 ...   80  -80   80]\n",
      " [  87   87  -87 ...   87  -87  -87]\n",
      " ...\n",
      " [ -33  -33  -33 ...  -33  -33  -33]\n",
      " [ 114 -114  114 ... -114 -114  114]\n",
      " [ -88   88  -88 ...   88  -88   88]]\n",
      "Tensor sequential_1/batch_normalization_7/FusedBatchNormV31 - Shape: (8,), Data: [  31   25  -30 -128  111  127   90    2]\n",
      "Tensor sequential_1/batch_normalization_7/FusedBatchNormV3 - Shape: (8,), Data: [117  89  14  75  78  51  68 127]\n",
      "Tensor sequential_1/quant_conv2d_5/QuantConv2D - Shape: (8,), Data: [0 0 0 0 0 0 0 0]\n",
      "Tensor sequential_1/quant_conv2d_5/QuantConv2D1 - Shape: (8, 2, 2, 4), Data: [[[[-127  127 -127 -127]\n",
      "   [ 127 -127  127 -127]]\n",
      "\n",
      "  [[-127 -127  127 -127]\n",
      "   [ 127 -127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[ 127  127 -127  127]\n",
      "   [ 127 -127  127 -127]]\n",
      "\n",
      "  [[ 127  127 -127 -127]\n",
      "   [ 127 -127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127  127  127  127]\n",
      "   [ 127  127  127  127]]\n",
      "\n",
      "  [[-127  127  127  127]\n",
      "   [ 127  127  127  127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127 -127 -127]\n",
      "   [-127  127 -127  127]]\n",
      "\n",
      "  [[ 127  127 -127 -127]\n",
      "   [-127  127 -127  127]]]\n",
      "\n",
      "\n",
      " [[[-127  127  127  127]\n",
      "   [ 127  127  127  127]]\n",
      "\n",
      "  [[ 127 -127  127  127]\n",
      "   [ 127 -127  127  127]]]\n",
      "\n",
      "\n",
      " [[[-127  127 -127  127]\n",
      "   [-127 -127 -127 -127]]\n",
      "\n",
      "  [[-127  127  127  127]\n",
      "   [-127  127 -127 -127]]]\n",
      "\n",
      "\n",
      " [[[ 127 -127 -127  127]\n",
      "   [ 127 -127 -127 -127]]\n",
      "\n",
      "  [[-127  127 -127 -127]\n",
      "   [ 127 -127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127 -127 -127]\n",
      "   [-127 -127 -127 -127]]\n",
      "\n",
      "  [[-127 -127 -127 -127]\n",
      "   [ 127  127  127  127]]]]\n",
      "Tensor sequential_1/batch_normalization_6/FusedBatchNormV31 - Shape: (4,), Data: [-128    3  127  -46]\n",
      "Tensor sequential_1/batch_normalization_6/FusedBatchNormV3 - Shape: (4,), Data: [ 45  75 119 127]\n",
      "Tensor sequential_1/quant_conv2d_4/QuantConv2D - Shape: (4,), Data: [0 0 0 0]\n",
      "Tensor sequential_1/quant_conv2d_4/QuantConv2D1 - Shape: (4, 2, 2, 6), Data: [[[[ 127 -127 -127  127 -127  127]\n",
      "   [-127  127  127 -127 -127 -127]]\n",
      "\n",
      "  [[-127  127  127 -127 -127 -127]\n",
      "   [-127  127 -127 -127 -127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127  127  127  127  127  127]\n",
      "   [-127 -127  127 -127  127  127]]\n",
      "\n",
      "  [[ 127  127  127 -127 -127  127]\n",
      "   [ 127 -127 -127  127  127  127]]]\n",
      "\n",
      "\n",
      " [[[ 127 -127 -127  127  127  127]\n",
      "   [ 127  127 -127 -127  127 -127]]\n",
      "\n",
      "  [[ 127  127 -127  127  127  127]\n",
      "   [ 127  127 -127 -127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127 -127 -127  127  127]\n",
      "   [ 127  127 -127 -127  127  127]]\n",
      "\n",
      "  [[-127  127  127 -127  127  127]\n",
      "   [ 127  127  127  127  127  127]]]]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D/ste_sign_9/add/y - Shape: (), Data: 127\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV31 - Shape: (6,), Data: [  29  -73  127   31 -128  -32]\n",
      "Tensor sequential_1/batch_normalization_5/FusedBatchNormV3 - Shape: (6,), Data: [-87 -86 -87 -87 127 -87]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D - Shape: (6,), Data: [0 0 0 0 0 0]\n",
      "Tensor sequential_1/quant_conv2d_3/QuantConv2D1 - Shape: (6, 2, 2, 1), Data: [[[[-127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[ 127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[ 127]\n",
      "   [-127]]\n",
      "\n",
      "  [[-127]\n",
      "   [-127]]]\n",
      "\n",
      "\n",
      " [[[ 127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[ 127]\n",
      "   [-127]]]\n",
      "\n",
      "\n",
      " [[[ 127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[ 127]\n",
      "   [ 127]]\n",
      "\n",
      "  [[-127]\n",
      "   [ 127]]]]\n",
      "Tensor tfl.quantize - Shape: (1, 184, 80, 1), Data: [[[[-52]\n",
      "   [127]\n",
      "   [ 81]\n",
      "   ...\n",
      "   [127]\n",
      "   [ 81]\n",
      "   [ 60]]\n",
      "\n",
      "  [[-52]\n",
      "   [127]\n",
      "   [ 81]\n",
      "   ...\n",
      "   [127]\n",
      "   [ 81]\n",
      "   [-68]]\n",
      "\n",
      "  [[-52]\n",
      "   [127]\n",
      "   [ 81]\n",
      "   ...\n",
      "   [127]\n",
      "   [ 81]\n",
      "   [ 60]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 93]\n",
      "   [-38]\n",
      "   [ 25]\n",
      "   ...\n",
      "   [-38]\n",
      "   [ 25]\n",
      "   [ 60]]\n",
      "\n",
      "  [[ 93]\n",
      "   [-38]\n",
      "   [ 25]\n",
      "   ...\n",
      "   [-38]\n",
      "   [ 25]\n",
      "   [-68]]\n",
      "\n",
      "  [[ 93]\n",
      "   [-38]\n",
      "   [ 25]\n",
      "   ...\n",
      "   [-38]\n",
      "   [ 25]\n",
      "   [ 60]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detail \u001b[38;5;129;01min\u001b[39;00m tensor_details:\n\u001b[0;32m---> 12\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetail[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:926\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index):\n\u001b[1;32m    879\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "# interpreter = tf.lite.Interpreter(model_content=dynamic_range_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get tensor details\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "for detail in tensor_details:\n",
    "    print(f\"Name: {detail['name']}, Index: {detail['index']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "\n",
    "# Extract weights\n",
    "for detail in tensor_details:\n",
    "    tensor = interpreter.tensor(detail['index'])()\n",
    "    print(f\"Tensor {detail['name']} - Shape: {tensor.shape}, Data: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51152"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import time\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"../spectrogram_models_from_notebooks/bnn/hpo\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_bnn_full_int_file = tflite_models_dir/\"bnn_mel_spec_full_int_q.tflite\"\n",
    "tflite_bnn_full_int_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset:\n",
      "Accuracy: 96.09%\n",
      "Recall: 90.89%\n",
      "Precision: 97.50%\n",
      "F1-score: 94.08%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9395347080536413\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9404414092106499\n",
      "\n",
      "Test dataset:\n",
      "Accuracy: 95.19%\n",
      "Recall: 88.21%\n",
      "Precision: 96.88%\n",
      "F1-score: 92.34%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.9222558877595886\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.9209436254661992\n",
      "\n",
      "Time for Test dataset:\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.002 seconds\n",
      "Max: 0.012 seconds\n",
      "Min: 0.002 seconds\n",
      "File size: 49.953 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset:\")\n",
    "predictions = full_int_model_predict(tflite_bnn_full_int_file, x_val_np)\n",
    "evaluate_prediction(y_val_np, predictions)\n",
    "\n",
    "print(\"\\nDevide dataset into 10 non-overlapping patritions and get their mean F1-score\")\n",
    "non_overlap_patritions_f1_scores = get_f1_scores_of_non_overlapping_partitions_full_int_q(tflite_bnn_full_int_file, x_val_np, y_val_np)\n",
    "print(\"Non-overlap mean F1-score: \", np.mean(non_overlap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nGet 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\")\n",
    "bootstrap_patritions_f1_scores = get_f1_scores_of_bootstarping_partitions_full_int_q(tflite_bnn_full_int_file, x_val_np, y_val_np)\n",
    "print(\"Bootstrap mean F1-score: \", np.mean(bootstrap_patritions_f1_scores))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "predictions = full_int_model_predict(tflite_bnn_full_int_file, x_test_np)\n",
    "evaluate_prediction(y_test_np, predictions)\n",
    "\n",
    "print(\"\\nDevide dataset into 10 non-overlapping patritions and get their mean F1-score\")\n",
    "non_overlap_patritions_f1_scores = get_f1_scores_of_non_overlapping_partitions_full_int_q(tflite_bnn_full_int_file, x_test_np, y_test_np)\n",
    "print(\"Non-overlap mean F1-score: \", np.mean(non_overlap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nGet 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\")\n",
    "bootstrap_patritions_f1_scores = get_f1_scores_of_bootstarping_partitions_full_int_q(tflite_bnn_full_int_file, x_test_np, y_test_np)\n",
    "print(\"Bootstrap mean F1-score: \", np.mean(bootstrap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "time_data = []\n",
    "for data_point in x_test_np:\n",
    "    start_time = time.time()\n",
    "    predictions = full_int_model_predict(tflite_bnn_full_int_file, [data_point])\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_data.append(elapsed_time)\n",
    "print(\"\\nTime to make a prediction for a single data point\")\n",
    "print(f\"Mean: {round(np.mean(time_data), 3)} seconds\")\n",
    "print(f\"Max: {round(np.max(time_data), 3)} seconds\")\n",
    "print(f\"Min: {round(np.min(time_data), 3)} seconds\")\n",
    "\n",
    "convert_bytes(get_file_size(tflite_bnn_full_int_file), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that weights from -1 +1 changed to some different numbers in full int quant model. \n",
    "But model was quantized to full int with no losses in f1-score and even better (but weights from -1 and +1 becan -127 +127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
