{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 21:43:57.243830: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-21 21:43:57.283795: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 21:43:57.283836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 21:43:57.285961: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 21:43:57.293200: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-21 21:43:57.294319: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 21:43:58.317961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import larq as lq\n",
    "from helper_functions import (\n",
    "    get_file_size, \n",
    "    convert_bytes\n",
    "    )\n",
    "\n",
    "\n",
    "# Data Pre-Processing\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape the images to the format (28, 28, 1) as the MNIST images are grayscale\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 21:44:00.366382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 21:44:00.366797: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-21 21:44:01.093982: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 24s 24ms/step - loss: 0.6428 - accuracy: 0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f3628326970>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following Larq's documentation model depth and parameters\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model.add(lq.layers.QuantConv2D(32, (3, 3),\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# The second layer has both quantized weights and activations using the Straight-through-estimator sign activation technquie.\n",
    "# Using straight-through-estimator to overcome undifferentiability issues\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# The third layer following the second layer\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# The fourth layer\n",
    "model.add(lq.layers.QuantDense(64, use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# The fifth layer\n",
    "model.add(lq.layers.QuantDense(10, use_bias=False, input_quantizer=\"ste_sign\",kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "#Output layer, multi class classification\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "#Compile and train the network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+sequential stats------------------------------------------------------------------------------------------+\n",
      "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs  32-bit MACs |\n",
      "|                              (bit)                        x 1       x 1    (kB)                          |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d                     -  (-1, 26, 26, 32)      288         0    0.04           0       194688 |\n",
      "| max_pooling2d                    -  (-1, 13, 13, 32)        0         0       0           0            0 |\n",
      "| batch_normalization              -  (-1, 13, 13, 32)        0        64    0.25           0            0 |\n",
      "| quant_conv2d_1                   1  (-1, 11, 11, 64)    18432         0    2.25     2230272            0 |\n",
      "| max_pooling2d_1                  -    (-1, 5, 5, 64)        0         0       0           0            0 |\n",
      "| batch_normalization_1            -    (-1, 5, 5, 64)        0       128    0.50           0            0 |\n",
      "| quant_conv2d_2                   1    (-1, 3, 3, 64)    36864         0    4.50      331776            0 |\n",
      "| batch_normalization_2            -    (-1, 3, 3, 64)        0       128    0.50           0            0 |\n",
      "| flatten                          -         (-1, 576)        0         0       0           0            0 |\n",
      "| quant_dense                      1          (-1, 64)    36864         0    4.50       36864            0 |\n",
      "| batch_normalization_3            -          (-1, 64)        0       128    0.50           0            0 |\n",
      "| quant_dense_1                    1          (-1, 10)      640         0    0.08         640            0 |\n",
      "| batch_normalization_4            -          (-1, 10)        0        20    0.08           0            0 |\n",
      "| activation                       -          (-1, 10)        0         0       0           ?            ? |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                   93088       468   13.19     2599552       194688 |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "+sequential summary----------------------------+\n",
      "| Total params                      93.6 k     |\n",
      "| Trainable params                  93.1 k     |\n",
      "| Non-trainable params              468        |\n",
      "| Model size                        13.19 KiB  |\n",
      "| Model size (8-bit FP weights)     11.82 KiB  |\n",
      "| Float-32 Equivalent               365.45 KiB |\n",
      "| Compression Ratio of Memory       0.04       |\n",
      "| Number of MACs                    2.79 M     |\n",
      "| Ratio of MACs that are binarized  0.9303     |\n",
      "+----------------------------------------------+\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4215 - accuracy: 0.9693\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network\n",
    "lq.models.summary(model)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  spectrogram_models_from_notebooks/bnn/bnn_mnist.keras\n",
      "File size: 1.147 Megabytes\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL_FILE_NAME = \"spectrogram_models_from_notebooks/bnn/bnn_mnist.keras\"\n",
    "model.save(BASE_MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", BASE_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(BASE_MODEL_FILE_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import larq_compute_engine as lce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu0g6o9g1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu0g6o9g1/assets\n",
      "2024-07-21 21:45:57.296710: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpu0g6o9g1\n",
      "2024-07-21 21:45:57.299094: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-07-21 21:45:57.299111: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpu0g6o9g1\n",
      "2024-07-21 21:45:57.307203: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-07-21 21:45:57.369930: E external/org_tensorflow/tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute debug_name which is not in the op definition: Op<name=VarHandleOp; signature= -> resource:resource; attr=container:string,default=\"\"; attr=shared_name:string,default=\"\"; attr=dtype:type; attr=shape:shape; attr=allowed_devices:list(string),default=[]; is_stateful=true> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node Adam/m/batch_normalization/beta}}\n",
      "2024-07-21 21:45:57.373875: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpu0g6o9g1\n",
      "2024-07-21 21:45:57.397538: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 100829 microseconds.\n",
      "2024-07-21 21:45:57.487725: I external/org_tensorflow/tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 0.529 M  ops, equivalently 0.264 M  MACs\n"
     ]
    }
   ],
   "source": [
    "# Convert our Keras model to a TFLite flatbuffer file\n",
    "with open(\"spectrogram_models_from_notebooks/bnn/bnn_mnist.tflite\", \"wb\") as flatbuffer_file:\n",
    "    flatbuffer_bytes = lce.convert_keras_model(model)\n",
    "    flatbuffer_file.write(flatbuffer_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  spectrogram_models_from_notebooks/bnn/bnn_mnist.tflite\n",
      "File size: 162.508 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL_FILE_NAME = \"spectrogram_models_from_notebooks/bnn/bnn_mnist.tflite\"\n",
    "print(\"Model file name: \", BASE_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(BASE_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
