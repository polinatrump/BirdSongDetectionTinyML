{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 15:11:38.263223: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-22 15:11:38.311144: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-22 15:11:38.311175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-22 15:11:38.312191: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-22 15:11:38.320752: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-22 15:11:38.321830: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-22 15:11:39.284723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import larq as lq\n",
    "import larq_compute_engine as lce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "import random\n",
    "tf.random.set_seed(3407)\n",
    "np.random.seed(3407)\n",
    "random.seed(3407)\n",
    "\n",
    "from notebooks.helper_functions import (\n",
    "    evaluate_prediction,\n",
    "    get_file_size, \n",
    "    convert_bytes, \n",
    "    convert_prefetchdataset_to_numpy_arrays,\n",
    "    predict_and_print_full_results,\n",
    "    evaluate_time_of_prediction,\n",
    "    full_int_model_predict,\n",
    "    get_f1_scores_of_non_overlapping_partitions_full_int_q,\n",
    "    get_f1_scores_of_bootstraping_partitions_full_int_q,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11292 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 15:11:48.709926: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-22 15:11:48.710329: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-22 15:11:48.824096: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-09-22 15:11:48.833182: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Found 1393 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Found 1380 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "Classes:  ['non_target' 'target']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.audio_dataset_from_directory(\"../../dataset/training\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "test_dataset = tf.keras.utils.audio_dataset_from_directory(\"../../dataset/testing\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "val_dataset = tf.keras.utils.audio_dataset_from_directory(\"../../dataset/validation\", labels='inferred', sampling_rate=16000, batch_size=32, shuffle=True, seed=3407)\n",
    "\n",
    "label_names = np.array(train_dataset.class_names)\n",
    "print(\"Classes: \", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np, y_train_np = convert_prefetchdataset_to_numpy_arrays(train_dataset, data_type=\"time-series\")\n",
    "x_val_np, y_val_np = convert_prefetchdataset_to_numpy_arrays(val_dataset, data_type=\"time-series\")\n",
    "x_test_np, y_test_np = convert_prefetchdataset_to_numpy_arrays(test_dataset, data_type=\"time-series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes, num_of_layers):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_of_conv_layers = num_of_layers\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        dense_units = hp.Int('1st_dense_units', min_value=4, max_value=32, step=4)\n",
    "        dense_activation = hp.Choice('2nd_dense_activation', values=['softmax', 'sigmoid'])\n",
    "        learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "        # Model architecture\n",
    "        # Tune number of layers\n",
    "        for i in range(self.num_of_conv_layers):\n",
    "            if i == 0:\n",
    "                model.add(lq.layers.QuantConv1D(\n",
    "                    filters=hp.Int(f'filters_{i}', min_value=2, max_value=8, step=2), \n",
    "                    kernel_size=hp.Choice(f'kernel_size_{i}', values=[2, 3, 5]),\n",
    "                    input_shape=self.input_shape,\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "            else:\n",
    "                model.add(lq.layers.QuantConv1D(\n",
    "                    filters=hp.Int(f'filters_{i}', min_value=2, max_value=8, step=2), \n",
    "                    kernel_size=hp.Choice(f'kernel_size_{i}', values=[2, 3, 5]),\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "            model.add(tf.keras.layers.MaxPooling1D(pool_size=hp.Int(f'pull_size_{i}', min_value=4, max_value=10, step=2)))\n",
    "            model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        model.add(lq.layers.QuantDense(\n",
    "            units=dense_units,\n",
    "            kernel_quantizer=\"ste_sign\",\n",
    "            input_quantizer=\"ste_sign\",\n",
    "            kernel_constraint=\"weight_clip\",\n",
    "            use_bias=False\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "        model.add(lq.layers.QuantDense(\n",
    "            units=self.num_classes,\n",
    "            kernel_quantizer=\"ste_sign\",\n",
    "            input_quantizer=\"ste_sign\",\n",
    "            kernel_constraint=\"weight_clip\",\n",
    "            use_bias=False\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "        model.add(tf.keras.layers.Activation(dense_activation))\n",
    "       \n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune 1 conv2d layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 07m 54s]\n",
      "val_accuracy: 0.781521737575531\n",
      "\n",
      "Best val_accuracy So Far: 0.8369565010070801\n",
      "Total elapsed time: 01h 25m 45s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/bnn/bnn_time_series_1_conv2d_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 28\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.0011554054814026313\n",
      "filters_0: 8\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 6\n",
      "Score: 0.8369565010070801\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 12\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.004018615305666302\n",
      "filters_0: 2\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 10\n",
      "Score: 0.8018116056919098\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 28\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.0023880453124178174\n",
      "filters_0: 2\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 8\n",
      "Score: 0.7981884181499481\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 32\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.0016098333118373667\n",
      "filters_0: 8\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 8\n",
      "Score: 0.781521737575531\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 24\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.005739801798904129\n",
      "filters_0: 4\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 8\n",
      "Score: 0.6739130616188049\n"
     ]
    }
   ],
   "source": [
    "input_shape = (48000,1)\n",
    "num_classes = 2\n",
    "\n",
    "num_of_conv_layers = 1\n",
    "tuner_1_layer_cnn = RandomSearch(\n",
    "    CNNHyperModel(input_shape, num_classes, num_of_conv_layers),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    directory='../hpo_tuner/bnn',\n",
    "    project_name='bnn_time_series_1_conv2d_tuning'\n",
    ")\n",
    "tuner_1_layer_cnn.search(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "tuner_1_layer_cnn.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune 2 conv2d layers CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 08m 37s]\n",
      "val_accuracy: 0.8355072438716888\n",
      "\n",
      "Best val_accuracy So Far: 0.8416666686534882\n",
      "Total elapsed time: 01h 23m 58s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/bnn/bnn_time_series_2_conv2d_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 8\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.0038803956106591635\n",
      "filters_0: 8\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 4\n",
      "filters_1: 8\n",
      "kernel_size_1: 3\n",
      "pull_size_1: 6\n",
      "Score: 0.8416666686534882\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 28\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.00032847506986532663\n",
      "filters_0: 6\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 10\n",
      "filters_1: 8\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 6\n",
      "Score: 0.8365942239761353\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 32\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.0030906537787876503\n",
      "filters_0: 2\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 4\n",
      "filters_1: 2\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 8\n",
      "Score: 0.8355072438716888\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 16\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.00570444375162039\n",
      "filters_0: 4\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 6\n",
      "filters_1: 2\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 6\n",
      "Score: 0.8173913061618805\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 20\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.0004731616841237643\n",
      "filters_0: 6\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 8\n",
      "filters_1: 2\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 8\n",
      "Score: 0.803260862827301\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 8\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.004516856601605048\n",
      "filters_0: 2\n",
      "kernel_size_0: 3\n",
      "pull_size_0: 6\n",
      "filters_1: 4\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 8\n",
      "Score: 0.7862319052219391\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 20\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.003886450625081135\n",
      "filters_0: 8\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 6\n",
      "filters_1: 8\n",
      "kernel_size_1: 3\n",
      "pull_size_1: 8\n",
      "Score: 0.7786231935024261\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 4\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.009105451871123885\n",
      "filters_0: 2\n",
      "kernel_size_0: 3\n",
      "pull_size_0: 10\n",
      "filters_1: 6\n",
      "kernel_size_1: 3\n",
      "pull_size_1: 8\n",
      "Score: 0.7753623127937317\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 16\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.0009958468605993623\n",
      "filters_0: 2\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 10\n",
      "filters_1: 8\n",
      "kernel_size_1: 2\n",
      "pull_size_1: 6\n",
      "Score: 0.7547101378440857\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 12\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.001201687537647584\n",
      "filters_0: 2\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 8\n",
      "filters_1: 2\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 6\n",
      "Score: 0.7326087057590485\n"
     ]
    }
   ],
   "source": [
    "num_of_layers = 2\n",
    "tuner_2_layer_cnn = RandomSearch(\n",
    "    CNNHyperModel(input_shape, num_classes, num_of_layers),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='../hpo_tuner/bnn',\n",
    "    project_name='bnn_time_series_2_conv2d_tuning'\n",
    ")\n",
    "tuner_2_layer_cnn.search(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "tuner_2_layer_cnn.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune 3 conv2d layers CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 08m 03s]\n",
      "val_accuracy: 0.8271739184856415\n",
      "\n",
      "Best val_accuracy So Far: 0.8547101318836212\n",
      "Total elapsed time: 01h 26m 28s\n",
      "Results summary\n",
      "Results in ../hpo_tuner/bnn/bnn_time_series_3_conv2d_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 12\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.004770118252590703\n",
      "filters_0: 8\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 4\n",
      "filters_1: 6\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 6\n",
      "filters_2: 2\n",
      "kernel_size_2: 3\n",
      "pull_size_2: 6\n",
      "Score: 0.8547101318836212\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 32\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.002045838206464179\n",
      "filters_0: 2\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 8\n",
      "filters_1: 8\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 8\n",
      "filters_2: 6\n",
      "kernel_size_2: 2\n",
      "pull_size_2: 10\n",
      "Score: 0.8416666686534882\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 8\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.0031380270528399827\n",
      "filters_0: 4\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 8\n",
      "filters_1: 2\n",
      "kernel_size_1: 3\n",
      "pull_size_1: 4\n",
      "filters_2: 8\n",
      "kernel_size_2: 3\n",
      "pull_size_2: 4\n",
      "Score: 0.8304347991943359\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 32\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.00033605693274706155\n",
      "filters_0: 6\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 10\n",
      "filters_1: 4\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 8\n",
      "filters_2: 4\n",
      "kernel_size_2: 5\n",
      "pull_size_2: 6\n",
      "Score: 0.8271739184856415\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 20\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.00908718308658079\n",
      "filters_0: 6\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 4\n",
      "filters_1: 4\n",
      "kernel_size_1: 2\n",
      "pull_size_1: 6\n",
      "filters_2: 2\n",
      "kernel_size_2: 2\n",
      "pull_size_2: 6\n",
      "Score: 0.8032608926296234\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 28\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.00020082699662119925\n",
      "filters_0: 4\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 4\n",
      "filters_1: 6\n",
      "kernel_size_1: 3\n",
      "pull_size_1: 8\n",
      "filters_2: 2\n",
      "kernel_size_2: 2\n",
      "pull_size_2: 8\n",
      "Score: 0.781521737575531\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 24\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.00017533560552392052\n",
      "filters_0: 4\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 6\n",
      "filters_1: 2\n",
      "kernel_size_1: 3\n",
      "pull_size_1: 4\n",
      "filters_2: 2\n",
      "kernel_size_2: 3\n",
      "pull_size_2: 4\n",
      "Score: 0.7507246136665344\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 12\n",
      "2nd_dense_activation: sigmoid\n",
      "learning_rate: 0.004018615305666302\n",
      "filters_0: 2\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 10\n",
      "filters_1: 8\n",
      "kernel_size_1: 2\n",
      "pull_size_1: 8\n",
      "filters_2: 8\n",
      "kernel_size_2: 5\n",
      "pull_size_2: 8\n",
      "Score: 0.7286231815814972\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 28\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.0023880453124178174\n",
      "filters_0: 2\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 8\n",
      "filters_1: 8\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 8\n",
      "filters_2: 8\n",
      "kernel_size_2: 5\n",
      "pull_size_2: 6\n",
      "Score: 0.7155797183513641\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "1st_dense_units: 4\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.0001655876301640272\n",
      "filters_0: 8\n",
      "kernel_size_0: 2\n",
      "pull_size_0: 8\n",
      "filters_1: 4\n",
      "kernel_size_1: 2\n",
      "pull_size_1: 10\n",
      "filters_2: 2\n",
      "kernel_size_2: 3\n",
      "pull_size_2: 8\n",
      "Score: 0.7036232054233551\n"
     ]
    }
   ],
   "source": [
    "num_of_layers = 3\n",
    "tuner_3_layer_cnn = RandomSearch(\n",
    "    CNNHyperModel(input_shape, num_classes, num_of_layers),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='../hpo_tuner/bnn',\n",
    "    project_name='bnn_time_series_3_conv2d_tuning'\n",
    ")\n",
    "tuner_3_layer_cnn.search(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "tuner_3_layer_cnn.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "1st_dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': 'linear'}\n",
      "2nd_dense_activation (Choice)\n",
      "{'default': 'softmax', 'conditions': [], 'values': ['softmax', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "kernel_size_0 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "pull_size_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 10, 'step': 2, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner_1_layer_cnn.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 9\n",
      "1st_dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': 'linear'}\n",
      "2nd_dense_activation (Choice)\n",
      "{'default': 'softmax', 'conditions': [], 'values': ['softmax', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "kernel_size_0 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "pull_size_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 10, 'step': 2, 'sampling': 'linear'}\n",
      "filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "kernel_size_1 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "pull_size_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 10, 'step': 2, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner_2_layer_cnn.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 12\n",
      "1st_dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': 'linear'}\n",
      "2nd_dense_activation (Choice)\n",
      "{'default': 'softmax', 'conditions': [], 'values': ['softmax', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "kernel_size_0 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "pull_size_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 10, 'step': 2, 'sampling': 'linear'}\n",
      "filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "kernel_size_1 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "pull_size_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 10, 'step': 2, 'sampling': 'linear'}\n",
      "filters_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
      "kernel_size_2 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 5], 'ordered': True}\n",
      "pull_size_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 10, 'step': 2, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner_3_layer_cnn.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "1st_dense_units: 12\n",
      "2nd_dense_activation: softmax\n",
      "learning_rate: 0.004770118252590703\n",
      "filters_0: 8\n",
      "kernel_size_0: 5\n",
      "pull_size_0: 4\n",
      "filters_1: 6\n",
      "kernel_size_1: 5\n",
      "pull_size_1: 6\n",
      "filters_2: 2\n",
      "kernel_size_2: 3\n",
      "pull_size_2: 6\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner_3_layer_cnn.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quant_conv1d_6 (QuantConv1  (None, 47996, 8)          40        \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 11999, 8)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 11999, 8)          24        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_conv1d_7 (QuantConv1  (None, 11995, 6)          240       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 1999, 6)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 1999, 6)           18        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_conv1d_8 (QuantConv1  (None, 1997, 2)           36        \n",
      " D)                                                              \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 332, 2)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 332, 2)            6         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 664)               0         \n",
      "                                                                 \n",
      " quant_dense_4 (QuantDense)  (None, 12)                7968      \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 12)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_5 (QuantDense)  (None, 2)                 24        \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 2)                 6         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8398 (32.80 KB)\n",
      "Trainable params: 8338 (32.57 KB)\n",
      "Non-trainable params: 60 (240.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = tf.keras.models.Sequential()\n",
    "\n",
    "# The first layer, only the weights are quantized while activations are left full-precision\n",
    "model_3.add(lq.layers.QuantConv1D(filters=8, \n",
    "                                  kernel_size=5,\n",
    "                                  kernel_quantizer=\"ste_sign\",\n",
    "                                  kernel_constraint=\"weight_clip\",\n",
    "                                  use_bias=False,\n",
    "                                  input_shape=(48000,1)))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(4))\n",
    "model_3.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3.add(lq.layers.QuantConv1D(\n",
    "                    filters=6, \n",
    "                    kernel_size=5,\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(6))\n",
    "model_3.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3.add(lq.layers.QuantConv1D(\n",
    "                    filters=2, \n",
    "                    kernel_size=3,\n",
    "                    input_quantizer=\"ste_sign\",\n",
    "                    kernel_quantizer=\"ste_sign\",\n",
    "                    kernel_constraint=\"weight_clip\",\n",
    "                    use_bias=False\n",
    "                ))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(6))\n",
    "model_3.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_3.add(lq.layers.QuantDense(units=12, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_3.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_3.add(lq.layers.QuantDense(units=2, \n",
    "                                 use_bias=False, \n",
    "                                 input_quantizer=\"ste_sign\",\n",
    "                                 kernel_quantizer=\"ste_sign\",\n",
    "                                 kernel_constraint=\"weight_clip\"))\n",
    "model_3.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model_3.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model_3.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "353/353 [==============================] - 57s 156ms/step - loss: 0.4933 - accuracy: 0.7528\n",
      "Epoch 2/20\n",
      "353/353 [==============================] - 52s 146ms/step - loss: 0.4233 - accuracy: 0.7926\n",
      "Epoch 3/20\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.4041 - accuracy: 0.8012\n",
      "Epoch 4/20\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3959 - accuracy: 0.8094\n",
      "Epoch 5/20\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3936 - accuracy: 0.8109\n",
      "Epoch 6/20\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3828 - accuracy: 0.8162\n",
      "Epoch 7/20\n",
      "353/353 [==============================] - 57s 158ms/step - loss: 0.3883 - accuracy: 0.8151\n",
      "Epoch 8/20\n",
      "353/353 [==============================] - 57s 160ms/step - loss: 0.4011 - accuracy: 0.8092\n",
      "Epoch 9/20\n",
      "353/353 [==============================] - 57s 158ms/step - loss: 0.3955 - accuracy: 0.8116\n",
      "Epoch 10/20\n",
      "353/353 [==============================] - 57s 160ms/step - loss: 0.3832 - accuracy: 0.8215\n",
      "Epoch 11/20\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3785 - accuracy: 0.8216\n",
      "Epoch 12/20\n",
      "353/353 [==============================] - 57s 158ms/step - loss: 0.3846 - accuracy: 0.8162\n",
      "Epoch 13/20\n",
      "353/353 [==============================] - 56s 158ms/step - loss: 0.4100 - accuracy: 0.8031\n",
      "Epoch 14/20\n",
      "353/353 [==============================] - 57s 158ms/step - loss: 0.4010 - accuracy: 0.8085\n",
      "Epoch 15/20\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3900 - accuracy: 0.8109\n",
      "Epoch 16/20\n",
      "353/353 [==============================] - 61s 171ms/step - loss: 0.3900 - accuracy: 0.8143\n",
      "Epoch 17/20\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3962 - accuracy: 0.8099\n",
      "Epoch 18/20\n",
      "353/353 [==============================] - 59s 165ms/step - loss: 0.3846 - accuracy: 0.8162\n",
      "Epoch 19/20\n",
      "353/353 [==============================] - 70s 194ms/step - loss: 0.3906 - accuracy: 0.8115\n",
      "Epoch 20/20\n",
      "353/353 [==============================] - 66s 184ms/step - loss: 0.3871 - accuracy: 0.8127\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 2s 30ms/step - loss: 0.4177 - accuracy: 0.8297\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 2s 32ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 82.97%\n",
      "Recall: 79.66%\n",
      "Precision: 73.01%\n",
      "F1-score: 76.19%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7571307153369615\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7514610553436641\n"
     ]
    }
   ],
   "source": [
    "model_3_20_epochs = tf.keras.models.clone_model(model_3)\n",
    "model_3_20_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.004770118252590703),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 20\n",
    "history = model_3_20_epochs.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_3_20_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_3_20_epochs, x_val_np, y_val_np, model_format=\"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/newname/.venv/lib/python3.9/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 75s 204ms/step - loss: 0.5035 - accuracy: 0.7340\n",
      "Epoch 2/10\n",
      "353/353 [==============================] - 71s 198ms/step - loss: 0.4179 - accuracy: 0.8069\n",
      "Epoch 3/10\n",
      "353/353 [==============================] - 65s 181ms/step - loss: 0.4004 - accuracy: 0.8170\n",
      "Epoch 4/10\n",
      "353/353 [==============================] - 57s 160ms/step - loss: 0.4246 - accuracy: 0.7921\n",
      "Epoch 5/10\n",
      "353/353 [==============================] - 57s 160ms/step - loss: 0.4132 - accuracy: 0.7997\n",
      "Epoch 6/10\n",
      "353/353 [==============================] - 57s 160ms/step - loss: 0.3688 - accuracy: 0.8293\n",
      "Epoch 7/10\n",
      "353/353 [==============================] - 58s 162ms/step - loss: 0.3336 - accuracy: 0.8529\n",
      "Epoch 8/10\n",
      "353/353 [==============================] - 57s 161ms/step - loss: 0.3379 - accuracy: 0.8535\n",
      "Epoch 9/10\n",
      "353/353 [==============================] - 59s 164ms/step - loss: 0.3348 - accuracy: 0.8552\n",
      "Epoch 10/10\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3277 - accuracy: 0.8587\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 2s 33ms/step - loss: 0.4000 - accuracy: 0.8471\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 2s 32ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 84.71%\n",
      "Recall: 62.71%\n",
      "Precision: 89.43%\n",
      "F1-score: 73.72%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7338192155946132\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7439192879798914\n"
     ]
    }
   ],
   "source": [
    "model_3_10_epochs = tf.keras.models.clone_model(model_3)\n",
    "model_3_10_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.004770118252590703),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 10\n",
    "history = model_3_10_epochs.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_3_10_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_3_10_epochs, x_val_np, y_val_np, model_format=\"keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "353/353 [==============================] - 62s 161ms/step - loss: 0.4439 - accuracy: 0.7802\n",
      "Epoch 2/5\n",
      "353/353 [==============================] - 58s 161ms/step - loss: 0.3351 - accuracy: 0.8516\n",
      "Epoch 3/5\n",
      "353/353 [==============================] - 57s 159ms/step - loss: 0.3329 - accuracy: 0.8591\n",
      "Epoch 4/5\n",
      "353/353 [==============================] - 58s 161ms/step - loss: 0.3706 - accuracy: 0.8362\n",
      "Epoch 5/5\n",
      "353/353 [==============================] - 58s 161ms/step - loss: 0.3681 - accuracy: 0.8393\n",
      "Validation dataset accuracy:\n",
      "44/44 [==============================] - 2s 31ms/step - loss: 0.6038 - accuracy: 0.7906\n",
      "Validation dataset:\n",
      "44/44 [==============================] - 2s 31ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 79.06%\n",
      "Recall: 39.41%\n",
      "Precision: 98.41%\n",
      "F1-score: 56.28%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.5561581623457317\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.5595575694428332\n"
     ]
    }
   ],
   "source": [
    "model_3_5_epochs = tf.keras.models.clone_model(model_3)\n",
    "model_3_5_epochs.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.004770118252590703),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "EPOCHS = 5\n",
    "history = model_3_5_epochs.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Validation dataset accuracy:\")\n",
    "val_loss, val_acc = model_3_5_epochs.evaluate(x_val_np, y_val_np)\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    ") = predict_and_print_full_results(model_3_5_epochs, x_val_np, y_val_np, model_format=\"keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:\n",
      "44/44 [==============================] - 1s 32ms/step\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 84.28%\n",
      "Recall: 84.28%\n",
      "Precision: 72.42%\n",
      "F1-score: 77.90%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.780648207060149\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7865660474085666\n",
      "Time of one prediction for Test dataset:\n",
      "Accuracy: 84.28%\n",
      "Recall: 84.28%\n",
      "Precision: 72.42%\n",
      "F1-score: 77.90%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.051 seconds\n",
      "Max: 0.238 seconds\n",
      "Min: 0.045 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    ") = predict_and_print_full_results(model_3_20_epochs, x_test_np, y_test_np, model_format=\"keras\")\n",
    "\n",
    "print(\"Time of one prediction for Test dataset:\")\n",
    "evaluate_time_of_prediction(model_3_20_epochs, x_test_np, y_test_np, model_format=\"keras\", show_prediction_evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_3_conv_layer_model.keras\n",
      "File size: 179.52 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILE_NAME = \"../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_3_conv_layer_model.keras\"\n",
    "model_3_20_epochs.save(MODEL_FILE_NAME)\n",
    "print(\"Model file name: \", MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third model has good f1-score and was small (179 Kb)\n",
    "\n",
    "I will keep this model as the final one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show latent weights of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: quant_conv1d_6\n",
      "Shape: (5, 1, 8)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1. -1.  1. -1. -1. -1. -1.  1. -1. -1.]\n",
      "\n",
      "Layer: quant_conv1d_7\n",
      "Shape: (5, 8, 6)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1. -1. -1. -1.  1.  1.  1.  1. -1. -1.]\n",
      "\n",
      "Layer: quant_conv1d_8\n",
      "Shape: (3, 6, 2)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1. -1.  1.  1.  1.  1.  1.  1. -1. -1.]\n",
      "\n",
      "Layer: quant_dense_4\n",
      "Shape: (664, 12)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [ 1. -1.  1. -1.  1.  1.  1. -1. -1. -1.]\n",
      "\n",
      "Layer: quant_dense_5\n",
      "Shape: (12, 2)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [ 1. -1. -1.  1.  1. -1. -1.  1.  1.  1.]\n",
      "\n",
      "Layer: quant_conv1d_6, Weight shape: (5, 1, 8), Size: 304 bytes\n",
      "Layer: quant_conv1d_7, Weight shape: (5, 8, 6), Size: 1104 bytes\n",
      "Layer: quant_conv1d_8, Weight shape: (3, 6, 2), Size: 288 bytes\n",
      "Layer: quant_dense_4, Weight shape: (664, 12), Size: 32000 bytes\n",
      "Layer: quant_dense_5, Weight shape: (12, 2), Size: 224 bytes\n",
      "Total memory usage: 33920 bytes\n"
     ]
    }
   ],
   "source": [
    "def display_weights(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, lq.layers.QuantConv1D) or isinstance(layer, lq.layers.QuantDense):\n",
    "            weights = layer.get_weights()\n",
    "            if weights:\n",
    "                print(f\"Layer: {layer.name}\")\n",
    "                for weight in weights:\n",
    "                    print(f\"Shape: {weight.shape}\")\n",
    "                    # Print the unique values to see if they are binarized\n",
    "                    unique_values = np.unique(weight)\n",
    "                    print(f\"Unique values: {unique_values}\\n\")\n",
    "                    # Print the first few weights for inspection\n",
    "                    print(f\"First few weights: {weight.flatten()[:10]}\\n\")\n",
    "\n",
    "# Display the weights of the binarized CNN model\n",
    "\n",
    "\n",
    "def model_memory_usage(model):\n",
    "    total_size = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (lq.layers.QuantConv1D, lq.layers.QuantDense)):\n",
    "            weights = layer.get_weights()\n",
    "            for weight in weights:\n",
    "                size = sys.getsizeof(weight)\n",
    "                total_size += size\n",
    "                print(f\"Layer: {layer.name}, Weight shape: {weight.shape}, Size: {size} bytes\")\n",
    "\n",
    "    print(f\"Total memory usage: {total_size} bytes\")\n",
    "\n",
    "# Display the weights of the binarized CNN model\n",
    "display_weights(model_3_20_epochs)\n",
    "\n",
    "# Check the memory usage of the model\n",
    "model_memory_usage(model_3_20_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show binary weights of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with lq.context.quantized_scope(True):\n",
    "    model_3_20_epochs.save(\"../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_3_conv_layer_model_binary_weights.keras\")  # save binarized weights h5\n",
    "    weights = model_3_20_epochs.get_weights()  # get binarized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_weights_model = tf.keras.models.load_model(\"../../models/time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_3_conv_layer_model_binary_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: quant_conv1d_6\n",
      "Shape: (5, 1, 8)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1. -1.  1. -1. -1. -1. -1.  1. -1. -1.]\n",
      "\n",
      "Layer: quant_conv1d_7\n",
      "Shape: (5, 8, 6)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1. -1. -1. -1.  1.  1.  1.  1. -1. -1.]\n",
      "\n",
      "Layer: quant_conv1d_8\n",
      "Shape: (3, 6, 2)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [-1. -1.  1.  1.  1.  1.  1.  1. -1. -1.]\n",
      "\n",
      "Layer: quant_dense_4\n",
      "Shape: (664, 12)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [ 1. -1.  1. -1.  1.  1.  1. -1. -1. -1.]\n",
      "\n",
      "Layer: quant_dense_5\n",
      "Shape: (12, 2)\n",
      "Unique values: [-1.  1.]\n",
      "\n",
      "First few weights: [ 1. -1. -1.  1.  1. -1. -1.  1.  1.  1.]\n",
      "\n",
      "Layer: quant_conv1d_6, Weight shape: (5, 1, 8), Size: 304 bytes\n",
      "Layer: quant_conv1d_7, Weight shape: (5, 8, 6), Size: 1104 bytes\n",
      "Layer: quant_conv1d_8, Weight shape: (3, 6, 2), Size: 288 bytes\n",
      "Layer: quant_dense_4, Weight shape: (664, 12), Size: 32000 bytes\n",
      "Layer: quant_dense_5, Weight shape: (12, 2), Size: 224 bytes\n",
      "Total memory usage: 33920 bytes\n"
     ]
    }
   ],
   "source": [
    "# Display the weights of the binarized CNN model\n",
    "display_weights(binarized_weights_model)\n",
    "\n",
    "# Check the memory usage of the model\n",
    "model_memory_usage(binarized_weights_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_3_conv_layer_model_binary_weights.keras\n",
      "File size: 0.175 Megabytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Model file name: \", \"../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_3_conv_layer_model_binary_weights.keras\")\n",
    "convert_bytes(get_file_size(\"../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_3_conv_layer_model_binary_weights.keras\"), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### larq TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptv5xzbi5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptv5xzbi5/assets\n",
      "2024-07-27 11:28:25.962286: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmptv5xzbi5\n",
      "2024-07-27 11:28:25.974119: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-07-27 11:28:25.974149: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmptv5xzbi5\n",
      "2024-07-27 11:28:25.977605: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-27 11:28:25.994514: I external/org_tensorflow/tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-07-27 11:28:26.004073: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-07-27 11:28:26.163633: E external/org_tensorflow/tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute debug_name which is not in the op definition: Op<name=VarHandleOp; signature= -> resource:resource; attr=container:string,default=\"\"; attr=shared_name:string,default=\"\"; attr=dtype:type; attr=shape:shape; attr=allowed_devices:list(string),default=[]; is_stateful=true> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node Adam/m/batch_normalization_10/beta}}\n",
      "2024-07-27 11:28:26.175201: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmptv5xzbi5\n",
      "2024-07-27 11:28:26.199277: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 237763 microseconds.\n",
      "2024-07-27 11:28:26.239786: I external/org_tensorflow/tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-27 11:28:26.375793: I external/org_tensorflow/tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 10.894 M  ops, equivalently 5.447 M  MACs\n"
     ]
    }
   ],
   "source": [
    "lce_model = lce.convert_keras_model(model_3_20_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check time of prdiction by bnn tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_time of one prediction, s:  0.004089654690917881\n"
     ]
    }
   ],
   "source": [
    "exec_time = []\n",
    "y_pred_all = []\n",
    "for i in range(1, len(x_test_np)):\n",
    "    # print(i)\n",
    "    start_time = time.time()\n",
    "    interpreter = lce.testing.Interpreter(lce_model)\n",
    "    y_pred_prob = interpreter.predict(x_test_np[i-1:i], verbose=0)\n",
    "    y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
    "    y_pred_all.extend(y_pred)\n",
    "    stop_time = time.time() - start_time\n",
    "    # print(stop_time)\n",
    "    exec_time.append(stop_time)\n",
    "print(\"mean_time of one prediction, s: \", sum(exec_time) / len(exec_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.34%\n",
      "Recall: 72.42%\n",
      "Precision: 84.46%\n",
      "F1-score: 77.98%\n"
     ]
    }
   ],
   "source": [
    "evaluate_prediction(y_pred_all, y_test_np[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write model in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42144"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_LITE_LARQ_MODEL_FILE_NAME = \"../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_lq.tflite\"\n",
    "open(TF_LITE_LARQ_MODEL_FILE_NAME, \"wb\").write(lce_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file name:  ../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_lq.tflite\n",
      "File size: 41.156 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "TF_LITE_LARQ_MODEL_FILE_NAME = \"../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_lq.tflite\"\n",
    "print(\"Model file name: \", TF_LITE_LARQ_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(TF_LITE_LARQ_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=TF_LITE_LARQ_MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dont know how to predict with the loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprvzpldqr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprvzpldqr/assets\n",
      "2024-09-22 15:14:04.714870: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-09-22 15:14:04.714957: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-09-22 15:14:04.715235: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmprvzpldqr\n",
      "2024-09-22 15:14:04.722829: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-09-22 15:14:04.722931: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmprvzpldqr\n",
      "2024-09-22 15:14:04.740618: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-09-22 15:14:04.833087: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmprvzpldqr\n",
      "2024-09-22 15:14:04.862306: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 147072 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 25, Total Ops 67, % non-converted = 37.31 %\n",
      " * 25 ARITH ops\n",
      "\n",
      "- arith.constant:   25 occurrences  (f32: 17, i32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 7)\n",
      "  (f32: 3)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 3)\n",
      "  (f32: 3)\n",
      "  (f32: 6)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 84.28%\n",
      "Recall: 84.28%\n",
      "Precision: 72.42%\n",
      "F1-score: 77.90%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.780648207060149\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7671719061395149\n",
      "\n",
      "Time for Test dataset:\n",
      "Accuracy: 84.28%\n",
      "Recall: 84.28%\n",
      "Precision: 72.42%\n",
      "F1-score: 77.90%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.003 seconds\n",
      "Max: 0.009 seconds\n",
      "Min: 0.003 seconds\n",
      "\n",
      "\n",
      "Model file name:  ../../models/time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_tf_lite.tflite\n",
      "File size: 44.512 Kilobytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'44.512 Kilobytes'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    "    ) = predict_and_print_full_results(tflite_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "evaluate_time_of_prediction(tflite_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "TF_LITE_MODEL_FILE_NAME = \"../../models/time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_tf_lite.tflite\"\n",
    "open(TF_LITE_MODEL_FILE_NAME, \"wb\").write(tflite_model)\n",
    "print(\"\\n\")\n",
    "print(\"Model file name: \", TF_LITE_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See tflite.tflite model weights and size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: serving_default_quant_conv1d_6_input:0, Index: 0, Shape: [    1 48000     1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/Squeeze, Index: 1, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/max_pooling1d_6/Squeeze, Index: 2, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D/Squeeze, Index: 3, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/max_pooling1d_7/Squeeze, Index: 4, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D/Squeeze, Index: 5, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/batch_normalization_13/batchnorm/mul, Index: 6, Shape: [ 12 664], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_14/batchnorm/mul, Index: 7, Shape: [ 2 12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D, Index: 8, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D1, Index: 9, Shape: [8 1 5 1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D, Index: 10, Shape: [6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D1, Index: 11, Shape: [6 1 5 8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D, Index: 12, Shape: [2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D1, Index: 13, Shape: [2 1 3 6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_14/batchnorm/sub, Index: 14, Shape: [2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_13/batchnorm/sub, Index: 15, Shape: [12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/sub, Index: 16, Shape: [2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/Rsqrt, Index: 17, Shape: [2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/sub, Index: 18, Shape: [6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/Rsqrt, Index: 19, Shape: [6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/sub, Index: 20, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/Rsqrt, Index: 21, Shape: [8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims_1/ste_sign_18/add/y, Index: 22, Shape: [], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/flatten_2/Const, Index: 23, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/max_pooling1d_6/ExpandDims/dim, Index: 24, Shape: [], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims/dim, Index: 25, Shape: [], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims, Index: 26, Shape: [    1     1 48000     1], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D2, Index: 27, Shape: [    1     1 47996     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/Squeeze1, Index: 28, Shape: [    1 47996     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/max_pooling1d_6/ExpandDims, Index: 29, Shape: [    1 47996     1     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/max_pooling1d_6/MaxPool, Index: 30, Shape: [    1 11999     1     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/mul;sequential_2/max_pooling1d_6/Squeeze;sequential_2/batch_normalization_10/batchnorm/Rsqrt, Index: 31, Shape: [    1 11999     1     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/add_1;sequential_2/max_pooling1d_6/Squeeze;sequential_2/batch_normalization_10/batchnorm/mul;sequential_2/batch_normalization_10/batchnorm/Rsqrt;sequential_2/batch_normalization_10/batchnorm/sub, Index: 32, Shape: [    1 11999     1     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/add_1;sequential_2/max_pooling1d_6/Squeeze;sequential_2/batch_normalization_10/batchnorm/mul;sequential_2/batch_normalization_10/batchnorm/Rsqrt;sequential_2/batch_normalization_10/batchnorm/sub1, Index: 33, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/ste_sign_20/Sign, Index: 34, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/ste_sign_20/add, Index: 35, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/ste_sign_20/Sign_1, Index: 36, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D/ExpandDims, Index: 37, Shape: [    1     1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D2, Index: 38, Shape: [    1     1 11995     6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D/Squeeze1, Index: 39, Shape: [    1 11995     6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/max_pooling1d_7/ExpandDims, Index: 40, Shape: [    1 11995     1     6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/max_pooling1d_7/MaxPool, Index: 41, Shape: [   1 1999    1    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/mul;sequential_2/max_pooling1d_7/Squeeze;sequential_2/batch_normalization_11/batchnorm/Rsqrt, Index: 42, Shape: [   1 1999    1    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/add_1;sequential_2/max_pooling1d_7/Squeeze;sequential_2/batch_normalization_11/batchnorm/mul;sequential_2/batch_normalization_11/batchnorm/Rsqrt;sequential_2/batch_normalization_11/batchnorm/sub, Index: 43, Shape: [   1 1999    1    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/add_1;sequential_2/max_pooling1d_7/Squeeze;sequential_2/batch_normalization_11/batchnorm/mul;sequential_2/batch_normalization_11/batchnorm/Rsqrt;sequential_2/batch_normalization_11/batchnorm/sub1, Index: 44, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/ste_sign_22/Sign, Index: 45, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/ste_sign_22/add, Index: 46, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/ste_sign_22/Sign_1, Index: 47, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D/ExpandDims, Index: 48, Shape: [   1    1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D2, Index: 49, Shape: [   1    1 1997    2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D/Squeeze1, Index: 50, Shape: [   1 1997    2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/max_pooling1d_8/ExpandDims, Index: 51, Shape: [   1 1997    1    2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/max_pooling1d_8/MaxPool, Index: 52, Shape: [  1 332   1   2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/mul;sequential_2/max_pooling1d_8/Squeeze;sequential_2/batch_normalization_12/batchnorm/Rsqrt, Index: 53, Shape: [  1 332   1   2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/add_1;sequential_2/max_pooling1d_8/Squeeze;sequential_2/batch_normalization_12/batchnorm/mul;sequential_2/batch_normalization_12/batchnorm/Rsqrt;sequential_2/batch_normalization_12/batchnorm/sub, Index: 54, Shape: [  1 332   1   2], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/flatten_2/Reshape, Index: 55, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_4/ste_sign_24/Sign, Index: 56, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_4/ste_sign_24/add, Index: 57, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_4/ste_sign_24/Sign_1, Index: 58, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_4/MatMul;sequential_2/batch_normalization_13/batchnorm/mul;sequential_2/batch_normalization_13/batchnorm/add_1, Index: 59, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_5/ste_sign_26/Sign, Index: 60, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_5/ste_sign_26/add, Index: 61, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_5/ste_sign_26/Sign_1, Index: 62, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_5/MatMul;sequential_2/batch_normalization_14/batchnorm/mul;sequential_2/batch_normalization_14/batchnorm/add_1, Index: 63, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: StatefulPartitionedCall:0, Index: 64, Shape: [1 2], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 77, Shape: [5 8], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 78, Shape: [40  6], dtype: <class 'numpy.float32'>\n",
      "Name: Conv_hwcn_weights, Index: 79, Shape: [18  2], dtype: <class 'numpy.float32'>\n",
      "Tensor serving_default_quant_conv1d_6_input:0 - Shape: (1, 48000, 1), Data: [[[ 1.3683300e+05]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 1.7473340e+06]\n",
      "  ...\n",
      "  [-1.5694581e-04]\n",
      "  [ 3.9474112e-03]\n",
      "  [ 5.6498135e-03]]]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/Squeeze - Shape: (3,), Data: [   -1 47996     8]\n",
      "Tensor sequential_2/max_pooling1d_6/Squeeze - Shape: (3,), Data: [   -1 11999     8]\n",
      "Tensor sequential_2/quant_conv1d_7/QuantConv1D/Squeeze - Shape: (3,), Data: [   -1 11995     6]\n",
      "Tensor sequential_2/max_pooling1d_7/Squeeze - Shape: (3,), Data: [  -1 1999    6]\n",
      "Tensor sequential_2/quant_conv1d_8/QuantConv1D/Squeeze - Shape: (3,), Data: [  -1 1997    2]\n",
      "Tensor sequential_2/batch_normalization_13/batchnorm/mul - Shape: (12, 664), Data: [[ 0.01628635 -0.01628635  0.01628635 ...  0.01628635  0.01628635\n",
      "   0.01628635]\n",
      " [-0.00659487  0.00659487 -0.00659487 ... -0.00659487 -0.00659487\n",
      "  -0.00659487]\n",
      " [ 0.00518894 -0.00518894  0.00518894 ...  0.00518894  0.00518894\n",
      "   0.00518894]\n",
      " ...\n",
      " [-0.00625719  0.00625719 -0.00625719 ... -0.00625719 -0.00625719\n",
      "  -0.00625719]\n",
      " [-0.00621951  0.00621951 -0.00621951 ...  0.00621951 -0.00621951\n",
      "  -0.00621951]\n",
      " [-0.00605398  0.00605398 -0.00605398 ... -0.00605398 -0.00605398\n",
      "  -0.00605398]]\n",
      "Tensor sequential_2/batch_normalization_14/batchnorm/mul - Shape: (2, 12), Data: [[ 0.13614629 -0.13614629  0.13614629 -0.13614629  0.13614629 -0.13614629\n",
      "   0.13614629 -0.13614629 -0.13614629 -0.13614629 -0.13614629 -0.13614629]\n",
      " [-0.1415566   0.1415566  -0.1415566   0.1415566   0.1415566   0.1415566\n",
      "  -0.1415566   0.1415566   0.1415566   0.1415566   0.1415566   0.1415566 ]]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D - Shape: (8,), Data: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D1 - Shape: (8, 1, 5, 1), Data: [[[[-1.]\n",
      "   [-1.]\n",
      "   [ 1.]\n",
      "   [-1.]\n",
      "   [-1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [-1.]\n",
      "   [ 1.]\n",
      "   [-1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.]\n",
      "   [ 1.]\n",
      "   [-1.]\n",
      "   [-1.]\n",
      "   [-1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]\n",
      "   [-1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [-1.]\n",
      "   [-1.]\n",
      "   [-1.]\n",
      "   [-1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [-1.]\n",
      "   [-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[-1.]\n",
      "   [ 1.]\n",
      "   [-1.]\n",
      "   [-1.]\n",
      "   [-1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.]\n",
      "   [ 1.]\n",
      "   [-1.]\n",
      "   [ 1.]\n",
      "   [ 1.]]]]\n",
      "Tensor sequential_2/quant_conv1d_7/QuantConv1D - Shape: (6,), Data: [0. 0. 0. 0. 0. 0.]\n",
      "Tensor sequential_2/quant_conv1d_7/QuantConv1D1 - Shape: (6, 1, 5, 8), Data: [[[[-1.  1.  1. -1. -1.  1.  1. -1.]\n",
      "   [-1. -1.  1. -1. -1.  1.  1. -1.]\n",
      "   [-1. -1.  1. -1.  1.  1.  1. -1.]\n",
      "   [-1.  1.  1. -1. -1.  1.  1. -1.]\n",
      "   [-1. -1.  1. -1. -1.  1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1.  1. -1.  1.  1.  1. -1.]\n",
      "   [-1. -1.  1. -1. -1.  1.  1. -1.]\n",
      "   [-1.  1.  1. -1.  1.  1.  1. -1.]\n",
      "   [-1.  1.  1. -1. -1.  1. -1.  1.]\n",
      "   [-1. -1.  1. -1. -1.  1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1.  1. -1. -1.  1.  1. -1.]\n",
      "   [-1. -1.  1. -1.  1. -1. -1. -1.]\n",
      "   [-1.  1.  1. -1. -1.  1.  1. -1.]\n",
      "   [ 1.  1.  1. -1.  1.  1.  1. -1.]\n",
      "   [-1. -1.  1. -1.  1. -1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1.  1. -1. -1.  1.  1. -1.]\n",
      "   [-1.  1.  1. -1. -1.  1.  1. -1.]\n",
      "   [-1. -1.  1. -1.  1. -1.  1. -1.]\n",
      "   [-1.  1.  1. -1.  1.  1.  1. -1.]\n",
      "   [-1.  1.  1. -1. -1.  1.  1. -1.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  1. -1.  1. -1. -1. -1.  1.]\n",
      "   [ 1.  1. -1.  1.  1. -1. -1.  1.]\n",
      "   [ 1.  1. -1.  1.  1. -1. -1.  1.]\n",
      "   [ 1.  1. -1.  1.  1. -1. -1.  1.]\n",
      "   [ 1.  1. -1.  1. -1. -1. -1.  1.]]]\n",
      "\n",
      "\n",
      " [[[ 1. -1. -1.  1. -1. -1. -1. -1.]\n",
      "   [ 1. -1. -1.  1. -1. -1. -1. -1.]\n",
      "   [-1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "   [-1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "   [-1. -1. -1.  1. -1. -1. -1. -1.]]]]\n",
      "Tensor sequential_2/quant_conv1d_8/QuantConv1D - Shape: (2,), Data: [0. 0.]\n",
      "Tensor sequential_2/quant_conv1d_8/QuantConv1D1 - Shape: (2, 1, 3, 6), Data: [[[[-1.  1.  1.  1. -1. -1.]\n",
      "   [ 1.  1.  1.  1. -1. -1.]\n",
      "   [ 1.  1.  1.  1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1.  1.  1.  1. -1.  1.]\n",
      "   [ 1.  1.  1. -1. -1.  1.]\n",
      "   [-1.  1.  1. -1. -1.  1.]]]]\n",
      "Tensor sequential_2/batch_normalization_14/batchnorm/sub - Shape: (2,), Data: [ 0.54461527 -0.543438  ]\n",
      "Tensor sequential_2/batch_normalization_13/batchnorm/sub - Shape: (12,), Data: [ 0.8507903  -0.5991443   0.3623901  -0.5100697   0.35191417 -0.13373257\n",
      "  0.59794366 -0.40409034 -0.66937053  0.1194943  -0.18252568 -0.40676296]\n",
      "Tensor sequential_2/batch_normalization_12/batchnorm/sub - Shape: (2,), Data: [-0.5379994   0.13613987]\n",
      "Tensor sequential_2/batch_normalization_12/batchnorm/Rsqrt - Shape: (2,), Data: [0.1120491  0.18751046]\n",
      "Tensor sequential_2/batch_normalization_11/batchnorm/sub - Shape: (6,), Data: [-0.31114626 -0.8977163  -0.50242513 -0.8260521  -0.65935206 -1.80739   ]\n",
      "Tensor sequential_2/batch_normalization_11/batchnorm/Rsqrt - Shape: (6,), Data: [0.17891118 0.19976586 0.19416805 0.19630384 0.11326481 0.08160101]\n",
      "Tensor sequential_2/batch_normalization_10/batchnorm/sub - Shape: (8,), Data: [-1.1580813   0.00172013 -0.868198   -1.1438594  -0.10782336 -0.79837054\n",
      " -0.8139038  -0.46812284]\n",
      "Tensor sequential_2/batch_normalization_10/batchnorm/Rsqrt - Shape: (8,), Data: [4.851649  4.486884  5.047281  5.203556  2.7617078 4.697924  4.7303677\n",
      " 5.350179 ]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims_1/ste_sign_18/add/y - Shape: (), Data: 0.10000000149011612\n",
      "Tensor sequential_2/flatten_2/Const - Shape: (2,), Data: [ -1 664]\n",
      "Tensor sequential_2/max_pooling1d_6/ExpandDims/dim - Shape: (), Data: 2\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims/dim - Shape: (), Data: -3\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims - Shape: (1, 1, 48000, 1), Data: [[[[-1.1580772 ]\n",
      "   [ 0.00172683]\n",
      "   [-0.86819685]\n",
      "   ...\n",
      "   [-0.76598346]\n",
      "   [-0.7361357 ]\n",
      "   [-0.5161693 ]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detail \u001b[38;5;129;01min\u001b[39;00m tensor_details:\n\u001b[0;32m---> 12\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetail[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:926\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index):\n\u001b[1;32m    879\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../time_series_models_from_notebooks/bnn/hpo/bnn_time_ser_tf_lite.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get tensor details\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "for detail in tensor_details:\n",
    "    print(f\"Name: {detail['name']}, Index: {detail['index']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "\n",
    "# Extract weights\n",
    "for detail in tensor_details:\n",
    "    tensor = interpreter.tensor(detail['index'])()\n",
    "    print(f\"Tensor {detail['name']} - Shape: {tensor.shape}, Data: {tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpx1nbncsu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpx1nbncsu/assets\n",
      "2024-09-22 15:14:44.920166: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-09-22 15:14:44.920230: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-09-22 15:14:44.920467: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpx1nbncsu\n",
      "2024-09-22 15:14:44.924138: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-09-22 15:14:44.924184: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpx1nbncsu\n",
      "2024-09-22 15:14:44.937093: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-09-22 15:14:45.003108: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpx1nbncsu\n",
      "2024-09-22 15:14:45.031485: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 111020 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 25, Total Ops 84, % non-converted = 29.76 %\n",
      " * 25 ARITH ops\n",
      "\n",
      "- arith.constant:   25 occurrences  (f16: 17, i32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 7)\n",
      "  (f32: 3)\n",
      "  (f32: 17)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 3)\n",
      "  (f32: 3)\n",
      "  (f32: 6)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "float16_quant_converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "float16_quant_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "float16_quant_converter.target_spec.supported_types = [tf.float16]\n",
    "float16_quant_model = float16_quant_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset:\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 82.97%\n",
      "Recall: 79.66%\n",
      "Precision: 73.01%\n",
      "F1-score: 76.19%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7571307153369615\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7544811567218843\n",
      "\n",
      "Test dataset:\n",
      "Basic assessment of the whole dataset (without any partitions):\n",
      "Accuracy: 84.35%\n",
      "Recall: 84.50%\n",
      "Precision: 72.47%\n",
      "F1-score: 78.02%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.7820988243440998\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.7873428448662837\n",
      "\n",
      "Time for Test dataset:\n",
      "Accuracy: 84.35%\n",
      "Recall: 84.50%\n",
      "Precision: 72.47%\n",
      "F1-score: 78.02%\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.004 seconds\n",
      "Max: 0.008 seconds\n",
      "Min: 0.003 seconds\n",
      "\n",
      "\n",
      "Model file name:  ../../models/time_series_models_from_notebooks/bnn/hpo/bnn_time_series_float16q.tflite\n",
      "File size: 0.03 Megabytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset:\")\n",
    "(\n",
    "    y_pred_val, \n",
    "    non_overlap_patritions_f1_scores_val, \n",
    "    bootstrap_patritions_f1_scores_val,\n",
    "    ) = predict_and_print_full_results(float16_quant_model, x_val_np, y_val_np, model_format=\"tf_lite\")\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "(\n",
    "    y_pred_test, \n",
    "    non_overlap_patritions_f1_scores_test, \n",
    "    bootstrap_patritions_f1_scores_test,\n",
    "    ) = predict_and_print_full_results(float16_quant_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "evaluate_time_of_prediction(float16_quant_model, x_test_np, y_test_np, model_format=\"tf_lite\")\n",
    "\n",
    "FLOAT16_QUANT_MODEL_FILE_NAME = \"../../models/time_series_models_from_notebooks/bnn/hpo/bnn_time_series_float16q.tflite\"\n",
    "open(FLOAT16_QUANT_MODEL_FILE_NAME, \"wb\").write(float16_quant_model)\n",
    "print(\"\\n\")\n",
    "print(\"Model file name: \", FLOAT16_QUANT_MODEL_FILE_NAME)\n",
    "convert_bytes(get_file_size(FLOAT16_QUANT_MODEL_FILE_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 30.641 Kilobytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'30.641 Kilobytes'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_bytes(get_file_size(FLOAT16_QUANT_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make full int quantization of tflite.tflite model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf_g34mu1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf_g34mu1/assets\n",
      "/home/polina/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-07-27 11:31:28.172221: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-07-27 11:31:28.172263: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-07-27 11:31:28.172428: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpf_g34mu1\n",
      "2024-07-27 11:31:28.176161: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-27 11:31:28.176203: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpf_g34mu1\n",
      "2024-07-27 11:31:28.185280: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-07-27 11:31:28.246406: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpf_g34mu1\n",
      "2024-07-27 11:31:28.269062: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 96634 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 25, Total Ops 67, % non-converted = 37.31 %\n",
      " * 25 ARITH ops\n",
      "\n",
      "- arith.constant:   25 occurrences  (f32: 17, i32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 7)\n",
      "  (f32: 3)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 3)\n",
      "  (f32: 3)\n",
      "  (f32: 6)\n",
      "  (f32: 8)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(x_val_np).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "full_int_converter = tf.lite.TFLiteConverter.from_keras_model(binarized_weights_model)\n",
    "full_int_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "full_int_converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "full_int_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "full_int_converter.inference_input_type = tf.uint8\n",
    "full_int_converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = full_int_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: serving_default_quant_conv1d_6_input:0, Index: 0, Shape: [    1 48000     1], dtype: <class 'numpy.uint8'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims/dim, Index: 1, Shape: [], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/Squeeze, Index: 2, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/max_pooling1d_6/ExpandDims/dim, Index: 3, Shape: [], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/max_pooling1d_6/Squeeze, Index: 4, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D/Squeeze, Index: 5, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/max_pooling1d_7/Squeeze, Index: 6, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D/Squeeze, Index: 7, Shape: [3], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/flatten_2/Const, Index: 8, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/batch_normalization_14/batchnorm/sub, Index: 9, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/batch_normalization_14/batchnorm/mul, Index: 10, Shape: [ 2 12], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_13/batchnorm/sub, Index: 11, Shape: [12], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/batch_normalization_13/batchnorm/mul, Index: 12, Shape: [ 12 664], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/sub, Index: 13, Shape: [2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/Rsqrt, Index: 14, Shape: [2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D, Index: 15, Shape: [2], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D1, Index: 16, Shape: [2 1 3 6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/sub, Index: 17, Shape: [6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/Rsqrt, Index: 18, Shape: [6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D, Index: 19, Shape: [6], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D1, Index: 20, Shape: [6 1 5 8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims_1/ste_sign_18/add/y, Index: 21, Shape: [], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/sub, Index: 22, Shape: [8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/Rsqrt, Index: 23, Shape: [8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D, Index: 24, Shape: [8], dtype: <class 'numpy.int32'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D1, Index: 25, Shape: [8 1 5 1], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.quantize, Index: 26, Shape: [    1 48000     1], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims, Index: 27, Shape: [    1     1 48000     1], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D2, Index: 28, Shape: [    1     1 47996     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_6/QuantConv1D/Squeeze1, Index: 29, Shape: [    1 47996     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/max_pooling1d_6/ExpandDims, Index: 30, Shape: [    1 47996     1     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/max_pooling1d_6/MaxPool, Index: 31, Shape: [    1 11999     1     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/mul;sequential_2/max_pooling1d_6/Squeeze;sequential_2/batch_normalization_10/batchnorm/Rsqrt, Index: 32, Shape: [    1 11999     1     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/add_1;sequential_2/max_pooling1d_6/Squeeze;sequential_2/batch_normalization_10/batchnorm/mul;sequential_2/batch_normalization_10/batchnorm/Rsqrt;sequential_2/batch_normalization_10/batchnorm/sub, Index: 33, Shape: [    1 11999     1     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/add_1;sequential_2/max_pooling1d_6/Squeeze;sequential_2/batch_normalization_10/batchnorm/mul;sequential_2/batch_normalization_10/batchnorm/Rsqrt;sequential_2/batch_normalization_10/batchnorm/sub1, Index: 34, Shape: [    1 11999     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_10/batchnorm/add_1;sequential_2/max_pooling1d_6/Squeeze;sequential_2/batch_normalization_10/batchnorm/mul;sequential_2/batch_normalization_10/batchnorm/Rsqrt;sequential_2/batch_normalization_10/batchnorm/sub11, Index: 35, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/ste_sign_20/Sign, Index: 36, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize1, Index: 37, Shape: [    1 11999     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_7/ste_sign_20/add, Index: 38, Shape: [    1 11999     8], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize, Index: 39, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_7/ste_sign_20/Sign_1, Index: 40, Shape: [    1 11999     8], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize2, Index: 41, Shape: [    1 11999     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D/ExpandDims, Index: 42, Shape: [    1     1 11999     8], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D2, Index: 43, Shape: [    1     1 11995     6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_7/QuantConv1D/Squeeze1, Index: 44, Shape: [    1 11995     6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/max_pooling1d_7/ExpandDims, Index: 45, Shape: [    1 11995     1     6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/max_pooling1d_7/MaxPool, Index: 46, Shape: [   1 1999    1    6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/mul;sequential_2/max_pooling1d_7/Squeeze;sequential_2/batch_normalization_11/batchnorm/Rsqrt, Index: 47, Shape: [   1 1999    1    6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/add_1;sequential_2/max_pooling1d_7/Squeeze;sequential_2/batch_normalization_11/batchnorm/mul;sequential_2/batch_normalization_11/batchnorm/Rsqrt;sequential_2/batch_normalization_11/batchnorm/sub, Index: 48, Shape: [   1 1999    1    6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/add_1;sequential_2/max_pooling1d_7/Squeeze;sequential_2/batch_normalization_11/batchnorm/mul;sequential_2/batch_normalization_11/batchnorm/Rsqrt;sequential_2/batch_normalization_11/batchnorm/sub1, Index: 49, Shape: [   1 1999    6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_11/batchnorm/add_1;sequential_2/max_pooling1d_7/Squeeze;sequential_2/batch_normalization_11/batchnorm/mul;sequential_2/batch_normalization_11/batchnorm/Rsqrt;sequential_2/batch_normalization_11/batchnorm/sub11, Index: 50, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/ste_sign_22/Sign, Index: 51, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize3, Index: 52, Shape: [   1 1999    6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_8/ste_sign_22/add, Index: 53, Shape: [   1 1999    6], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize1, Index: 54, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_conv1d_8/ste_sign_22/Sign_1, Index: 55, Shape: [   1 1999    6], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize4, Index: 56, Shape: [   1 1999    6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D/ExpandDims, Index: 57, Shape: [   1    1 1999    6], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D2, Index: 58, Shape: [   1    1 1997    2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_conv1d_8/QuantConv1D/Squeeze1, Index: 59, Shape: [   1 1997    2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/max_pooling1d_8/ExpandDims, Index: 60, Shape: [   1 1997    1    2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/max_pooling1d_8/MaxPool, Index: 61, Shape: [  1 332   1   2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/mul;sequential_2/max_pooling1d_8/Squeeze;sequential_2/batch_normalization_12/batchnorm/Rsqrt, Index: 62, Shape: [  1 332   1   2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/batch_normalization_12/batchnorm/add_1;sequential_2/max_pooling1d_8/Squeeze;sequential_2/batch_normalization_12/batchnorm/mul;sequential_2/batch_normalization_12/batchnorm/Rsqrt;sequential_2/batch_normalization_12/batchnorm/sub, Index: 63, Shape: [  1 332   1   2], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/flatten_2/Reshape, Index: 64, Shape: [  1 664], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/flatten_2/Reshape1, Index: 65, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_4/ste_sign_24/Sign, Index: 66, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize5, Index: 67, Shape: [  1 664], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_dense_4/ste_sign_24/add, Index: 68, Shape: [  1 664], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize2, Index: 69, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_4/ste_sign_24/Sign_1, Index: 70, Shape: [  1 664], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize6, Index: 71, Shape: [  1 664], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_dense_4/MatMul;sequential_2/batch_normalization_13/batchnorm/mul;sequential_2/batch_normalization_13/batchnorm/add_1, Index: 72, Shape: [ 1 12], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize3, Index: 73, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_5/ste_sign_26/Sign, Index: 74, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize7, Index: 75, Shape: [ 1 12], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_dense_5/ste_sign_26/add, Index: 76, Shape: [ 1 12], dtype: <class 'numpy.int8'>\n",
      "Name: tfl.dequantize4, Index: 77, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: sequential_2/quant_dense_5/ste_sign_26/Sign_1, Index: 78, Shape: [ 1 12], dtype: <class 'numpy.float32'>\n",
      "Name: tfl.quantize8, Index: 79, Shape: [ 1 12], dtype: <class 'numpy.int8'>\n",
      "Name: sequential_2/quant_dense_5/MatMul;sequential_2/batch_normalization_14/batchnorm/mul;sequential_2/batch_normalization_14/batchnorm/add_1, Index: 80, Shape: [1 2], dtype: <class 'numpy.int8'>\n",
      "Name: StatefulPartitionedCall:01, Index: 81, Shape: [1 2], dtype: <class 'numpy.int8'>\n",
      "Name: StatefulPartitionedCall:0, Index: 82, Shape: [1 2], dtype: <class 'numpy.uint8'>\n",
      "Name: , Index: 95, Shape: [    1     1 47996     5], dtype: <class 'numpy.int8'>\n",
      "Name: , Index: 96, Shape: [    1     1 11995    40], dtype: <class 'numpy.int8'>\n",
      "Name: , Index: 97, Shape: [   1    1 1997   18], dtype: <class 'numpy.int8'>\n",
      "Tensor serving_default_quant_conv1d_6_input:0 - Shape: (1, 48000, 1), Data: [[[128]\n",
      "  [ 91]\n",
      "  [212]\n",
      "  ...\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims/dim - Shape: (), Data: -3\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/Squeeze - Shape: (3,), Data: [   -1 47996     8]\n",
      "Tensor sequential_2/max_pooling1d_6/ExpandDims/dim - Shape: (), Data: 2\n",
      "Tensor sequential_2/max_pooling1d_6/Squeeze - Shape: (3,), Data: [   -1 11999     8]\n",
      "Tensor sequential_2/quant_conv1d_7/QuantConv1D/Squeeze - Shape: (3,), Data: [   -1 11995     6]\n",
      "Tensor sequential_2/max_pooling1d_7/Squeeze - Shape: (3,), Data: [  -1 1999    6]\n",
      "Tensor sequential_2/quant_conv1d_8/QuantConv1D/Squeeze - Shape: (3,), Data: [  -1 1997    2]\n",
      "Tensor sequential_2/flatten_2/Const - Shape: (2,), Data: [ -1 664]\n",
      "Tensor sequential_2/batch_normalization_14/batchnorm/sub - Shape: (2,), Data: [ 62298 -62163]\n",
      "Tensor sequential_2/batch_normalization_14/batchnorm/mul - Shape: (2, 12), Data: [[ 122 -122  122 -122  122 -122  122 -122 -122 -122 -122 -122]\n",
      " [-127  127 -127  127  127  127 -127  127  127  127  127  127]]\n",
      "Tensor sequential_2/batch_normalization_13/batchnorm/sub - Shape: (12,), Data: [ 706698 -497671  301015 -423683  292313 -111083  496674 -335652 -556004\n",
      "   99256 -151613 -337872]\n",
      "Tensor sequential_2/batch_normalization_13/batchnorm/mul - Shape: (12, 664), Data: [[ 106 -106  106 ...  106  106  106]\n",
      " [ -43   43  -43 ...  -43  -43  -43]\n",
      " [  34  -34   34 ...   34   34   34]\n",
      " ...\n",
      " [ -41   41  -41 ...  -41  -41  -41]\n",
      " [ -41   41  -41 ...   41  -41  -41]\n",
      " [ -39   39  -39 ...  -39  -39  -39]]\n",
      "Tensor sequential_2/batch_normalization_12/batchnorm/sub - Shape: (2,), Data: [-128  127]\n",
      "Tensor sequential_2/batch_normalization_12/batchnorm/Rsqrt - Shape: (2,), Data: [ 24 127]\n",
      "Tensor sequential_2/quant_conv1d_8/QuantConv1D - Shape: (2,), Data: [0 0]\n",
      "Tensor sequential_2/quant_conv1d_8/QuantConv1D1 - Shape: (2, 1, 3, 6), Data: [[[[-127  127  127  127 -127 -127]\n",
      "   [ 127  127  127  127 -127 -127]\n",
      "   [ 127  127  127  127 -127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127  127  127  127 -127  127]\n",
      "   [ 127  127  127 -127 -127  127]\n",
      "   [-127  127  127 -127 -127  127]]]]\n",
      "Tensor sequential_2/batch_normalization_11/batchnorm/sub - Shape: (6,), Data: [  83    0   56   10   34 -128]\n",
      "Tensor sequential_2/batch_normalization_11/batchnorm/Rsqrt - Shape: (6,), Data: [100 127 120 123  17 -24]\n",
      "Tensor sequential_2/quant_conv1d_7/QuantConv1D - Shape: (6,), Data: [0 0 0 0 0 0]\n",
      "Tensor sequential_2/quant_conv1d_7/QuantConv1D1 - Shape: (6, 1, 5, 8), Data: [[[[-127  127  127 -127 -127  127  127 -127]\n",
      "   [-127 -127  127 -127 -127  127  127 -127]\n",
      "   [-127 -127  127 -127  127  127  127 -127]\n",
      "   [-127  127  127 -127 -127  127  127 -127]\n",
      "   [-127 -127  127 -127 -127  127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127  127  127 -127  127  127  127 -127]\n",
      "   [-127 -127  127 -127 -127  127  127 -127]\n",
      "   [-127  127  127 -127  127  127  127 -127]\n",
      "   [-127  127  127 -127 -127  127 -127  127]\n",
      "   [-127 -127  127 -127 -127  127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127  127 -127 -127  127  127 -127]\n",
      "   [-127 -127  127 -127  127 -127 -127 -127]\n",
      "   [-127  127  127 -127 -127  127  127 -127]\n",
      "   [ 127  127  127 -127  127  127  127 -127]\n",
      "   [-127 -127  127 -127  127 -127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[-127 -127  127 -127 -127  127  127 -127]\n",
      "   [-127  127  127 -127 -127  127  127 -127]\n",
      "   [-127 -127  127 -127  127 -127  127 -127]\n",
      "   [-127  127  127 -127  127  127  127 -127]\n",
      "   [-127  127  127 -127 -127  127  127 -127]]]\n",
      "\n",
      "\n",
      " [[[ 127  127 -127  127 -127 -127 -127  127]\n",
      "   [ 127  127 -127  127  127 -127 -127  127]\n",
      "   [ 127  127 -127  127  127 -127 -127  127]\n",
      "   [ 127  127 -127  127  127 -127 -127  127]\n",
      "   [ 127  127 -127  127 -127 -127 -127  127]]]\n",
      "\n",
      "\n",
      " [[[ 127 -127 -127  127 -127 -127 -127 -127]\n",
      "   [ 127 -127 -127  127 -127 -127 -127 -127]\n",
      "   [-127 -127 -127 -127 -127 -127 -127 -127]\n",
      "   [-127 -127 -127 -127 -127 -127 -127 -127]\n",
      "   [-127 -127 -127  127 -127 -127 -127 -127]]]]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims_1/ste_sign_18/add/y - Shape: (), Data: 127\n",
      "Tensor sequential_2/batch_normalization_10/batchnorm/sub - Shape: (8,), Data: [-128  127  -64 -124  103  -49  -52   24]\n",
      "Tensor sequential_2/batch_normalization_10/batchnorm/Rsqrt - Shape: (8,), Data: [103  86 113 120   4  96  97 127]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D - Shape: (8,), Data: [0 0 0 0 0 0 0 0]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D1 - Shape: (8, 1, 5, 1), Data: [[[[-127]\n",
      "   [-127]\n",
      "   [ 127]\n",
      "   [-127]\n",
      "   [-127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [-127]\n",
      "   [ 127]\n",
      "   [-127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[ 127]\n",
      "   [ 127]\n",
      "   [-127]\n",
      "   [-127]\n",
      "   [-127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [ 127]\n",
      "   [ 127]\n",
      "   [-127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [-127]\n",
      "   [-127]\n",
      "   [-127]\n",
      "   [-127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [-127]\n",
      "   [-127]\n",
      "   [ 127]\n",
      "   [ 127]]]\n",
      "\n",
      "\n",
      " [[[-127]\n",
      "   [ 127]\n",
      "   [-127]\n",
      "   [-127]\n",
      "   [-127]]]\n",
      "\n",
      "\n",
      " [[[ 127]\n",
      "   [ 127]\n",
      "   [-127]\n",
      "   [ 127]\n",
      "   [ 127]]]]\n",
      "Tensor tfl.quantize - Shape: (1, 48000, 1), Data: [[[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]]\n",
      "Tensor sequential_2/quant_conv1d_6/QuantConv1D/ExpandDims - Shape: (1, 1, 48000, 1), Data: [[[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detail \u001b[38;5;129;01min\u001b[39;00m tensor_details:\n\u001b[0;32m---> 12\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetail[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/newname/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:926\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index):\n\u001b[1;32m    879\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "# interpreter = tf.lite.Interpreter(model_content=dynamic_range_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get tensor details\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "for detail in tensor_details:\n",
    "    print(f\"Name: {detail['name']}, Index: {detail['index']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "\n",
    "# Extract weights\n",
    "for detail in tensor_details:\n",
    "    tensor = interpreter.tensor(detail['index'])()\n",
    "    print(f\"Tensor {detail['name']} - Shape: {tensor.shape}, Data: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25776"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import time\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"../time_series_models_from_notebooks/bnn/hpo\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_bnn_full_int_file = tflite_models_dir/\"bnn_time_ser_full_int_q.tflite\"\n",
    "tflite_bnn_full_int_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset:\n",
      "Accuracy: 66.67%\n",
      "Recall: 99.58%\n",
      "Precision: 50.65%\n",
      "F1-score: 67.14%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.6702007752656971\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.6687572000560439\n",
      "\n",
      "Test dataset:\n",
      "Accuracy: 64.54%\n",
      "Recall: 98.47%\n",
      "Precision: 48.08%\n",
      "F1-score: 64.61%\n",
      "\n",
      "Devide dataset into 10 non-overlapping patritions and get their mean F1-score\n",
      "Non-overlap mean F1-score:  0.6443411341243627\n",
      "\n",
      "Get 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\n",
      "Bootstrap mean F1-score:  0.6444100216284128\n",
      "\n",
      "Time for Test dataset:\n",
      "\n",
      "Time to make a prediction for a single data point\n",
      "Mean: 0.003 seconds\n",
      "Max: 0.006 seconds\n",
      "Min: 0.003 seconds\n",
      "File size: 25.172 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation dataset:\")\n",
    "predictions = full_int_model_predict(tflite_bnn_full_int_file, x_val_np)\n",
    "evaluate_prediction(y_val_np, predictions)\n",
    "\n",
    "print(\"\\nDevide dataset into 10 non-overlapping patritions and get their mean F1-score\")\n",
    "non_overlap_patritions_f1_scores = get_f1_scores_of_non_overlapping_partitions_full_int_q(tflite_bnn_full_int_file, x_val_np, y_val_np)\n",
    "print(\"Non-overlap mean F1-score: \", np.mean(non_overlap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nGet 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\")\n",
    "bootstrap_patritions_f1_scores = get_f1_scores_of_bootstraping_partitions_full_int_q(tflite_bnn_full_int_file, x_val_np, y_val_np)\n",
    "print(\"Bootstrap mean F1-score: \", np.mean(bootstrap_patritions_f1_scores))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTest dataset:\")\n",
    "predictions = full_int_model_predict(tflite_bnn_full_int_file, x_test_np)\n",
    "evaluate_prediction(y_test_np, predictions)\n",
    "\n",
    "print(\"\\nDevide dataset into 10 non-overlapping patritions and get their mean F1-score\")\n",
    "non_overlap_patritions_f1_scores = get_f1_scores_of_non_overlapping_partitions_full_int_q(tflite_bnn_full_int_file, x_test_np, y_test_np)\n",
    "print(\"Non-overlap mean F1-score: \", np.mean(non_overlap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nGet 100 bootstrap samples from dataset with 100 samples each and get their mean F1-score\")\n",
    "bootstrap_patritions_f1_scores = get_f1_scores_of_bootstraping_partitions_full_int_q(tflite_bnn_full_int_file, x_test_np, y_test_np)\n",
    "print(\"Bootstrap mean F1-score: \", np.mean(bootstrap_patritions_f1_scores))\n",
    "\n",
    "print(\"\\nTime for Test dataset:\")\n",
    "time_data = []\n",
    "for data_point in x_test_np:\n",
    "    start_time = time.time()\n",
    "    predictions = full_int_model_predict(tflite_bnn_full_int_file, [data_point])\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_data.append(elapsed_time)\n",
    "print(\"\\nTime to make a prediction for a single data point\")\n",
    "print(f\"Mean: {round(np.mean(time_data), 3)} seconds\")\n",
    "print(f\"Max: {round(np.max(time_data), 3)} seconds\")\n",
    "print(f\"Min: {round(np.min(time_data), 3)} seconds\")\n",
    "\n",
    "convert_bytes(get_file_size(tflite_bnn_full_int_file), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that weights from -1 +1 changed to some different numbers in full int quant model. \n",
    "But model was quantized to full int with no losses in f1-score and even better (but weights from -1 and +1 becan -127 +127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
